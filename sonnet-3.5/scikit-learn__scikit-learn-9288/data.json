{"instance_id": "scikit-learn__scikit-learn-9288", "score": "C", "diff": "diff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py\nindex b7fbdf7da..af6a8775d 100644\n--- a/sklearn/cluster/k_means_.py\n+++ b/sklearn/cluster/k_means_.py\n@@ -360,41 +360,24 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',\n     else:\n         raise ValueError(\"Algorithm must be 'auto', 'full' or 'elkan', got\"\n                          \" %s\" % str(algorithm))\n-    if effective_n_jobs(n_jobs) == 1:\n-        # For a single thread, less memory is needed if we just store one set\n-        # of the best results (as opposed to one set per run per thread).\n-        for it in range(n_init):\n-            # run a k-means once\n-            labels, inertia, centers, n_iter_ = kmeans_single(\n-                X, sample_weight, n_clusters, max_iter=max_iter, init=init,\n-                verbose=verbose, precompute_distances=precompute_distances,\n-                tol=tol, x_squared_norms=x_squared_norms,\n-                random_state=random_state)\n-            # determine if these results are the best so far\n-            if best_inertia is None or inertia < best_inertia:\n-                best_labels = labels.copy()\n-                best_centers = centers.copy()\n-                best_inertia = inertia\n-                best_n_iter = n_iter_\n-    else:\n-        # parallelisation of k-means runs\n-        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n-        results = Parallel(n_jobs=n_jobs, verbose=0)(\n-            delayed(kmeans_single)(X, sample_weight, n_clusters,\n-                                   max_iter=max_iter, init=init,\n-                                   verbose=verbose, tol=tol,\n-                                   precompute_distances=precompute_distances,\n-                                   x_squared_norms=x_squared_norms,\n-                                   # Change seed to ensure variety\n-                                   random_state=seed)\n-            for seed in seeds)\n-        # Get results with the lowest inertia\n-        labels, inertia, centers, n_iters = zip(*results)\n-        best = np.argmin(inertia)\n-        best_labels = labels[best]\n-        best_inertia = inertia[best]\n-        best_centers = centers[best]\n-        best_n_iter = n_iters[best]\n+    # Use the same implementation for both parallel and non-parallel cases\n+    seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n+    results = Parallel(n_jobs=n_jobs, verbose=0)(\n+        delayed(kmeans_single)(X, sample_weight, n_clusters,\n+                               max_iter=max_iter, init=init,\n+                               verbose=verbose, tol=tol,\n+                               precompute_distances=precompute_distances,\n+                               x_squared_norms=x_squared_norms,\n+                               # Change seed to ensure variety\n+                               random_state=seed)\n+        for seed in seeds)\n+    # Get results with the lowest inertia\n+    labels, inertia, centers, n_iters = zip(*results)\n+    best = np.argmin(inertia)\n+    best_labels = labels[best]\n+    best_inertia = inertia[best]\n+    best_centers = centers[best]\n+    best_n_iter = n_iters[best]\n \n     if not sp.issparse(X):\n         if not copy_x:\n", "gold_standard_diff": "diff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst\nindex 7be27894abe0f..0e4cee72c4c1e 100644\n--- a/doc/whats_new/v0.22.rst\n+++ b/doc/whats_new/v0.22.rst\n@@ -26,6 +26,8 @@ random sampling procedures.\n \n - :class:`linear_model.Ridge` when `X` is sparse. |Fix|\n \n+- :class:`cluster.KMeans` when `n_jobs=1`. |Fix|\n+\n Details are listed in the changelog below.\n \n (While we are trying to better inform users by providing this information, we\n@@ -283,6 +285,10 @@ Changelog\n   match `spectral_clustering`.\n   :pr:`13726` by :user:`Shuzhe Xiao <fdas3213>`.\n \n+- |Fix| Fixed a bug where :class:`cluster.KMeans` produced inconsistent results\n+  between `n_jobs=1` and `n_jobs>1` due to the handling of the random state.\n+  :pr:`9288` by :user:`Bryan Yang <bryanyang0528>`.\n+\n :mod:`sklearn.feature_selection`\n ................................\n \ndiff --git a/sklearn/cluster/k_means_.py b/sklearn/cluster/k_means_.py\nindex b7fbdf7da3ad1..4a76a40cc87c1 100644\n--- a/sklearn/cluster/k_means_.py\n+++ b/sklearn/cluster/k_means_.py\n@@ -360,16 +360,18 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',\n     else:\n         raise ValueError(\"Algorithm must be 'auto', 'full' or 'elkan', got\"\n                          \" %s\" % str(algorithm))\n+\n+    seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n     if effective_n_jobs(n_jobs) == 1:\n         # For a single thread, less memory is needed if we just store one set\n         # of the best results (as opposed to one set per run per thread).\n-        for it in range(n_init):\n+        for seed in seeds:\n             # run a k-means once\n             labels, inertia, centers, n_iter_ = kmeans_single(\n                 X, sample_weight, n_clusters, max_iter=max_iter, init=init,\n                 verbose=verbose, precompute_distances=precompute_distances,\n                 tol=tol, x_squared_norms=x_squared_norms,\n-                random_state=random_state)\n+                random_state=seed)\n             # determine if these results are the best so far\n             if best_inertia is None or inertia < best_inertia:\n                 best_labels = labels.copy()\n@@ -378,7 +380,6 @@ def k_means(X, n_clusters, sample_weight=None, init='k-means++',\n                 best_n_iter = n_iter_\n     else:\n         # parallelisation of k-means runs\n-        seeds = random_state.randint(np.iinfo(np.int32).max, size=n_init)\n         results = Parallel(n_jobs=n_jobs, verbose=0)(\n             delayed(kmeans_single)(X, sample_weight, n_clusters,\n                                    max_iter=max_iter, init=init,\ndiff --git a/sklearn/cluster/tests/test_k_means.py b/sklearn/cluster/tests/test_k_means.py\nindex 362b0a9145fca..2b3d2a0642ba7 100644\n--- a/sklearn/cluster/tests/test_k_means.py\n+++ b/sklearn/cluster/tests/test_k_means.py\n@@ -951,3 +951,13 @@ def test_minibatch_kmeans_partial_fit_int_data():\n     km = MiniBatchKMeans(n_clusters=2)\n     km.partial_fit(X)\n     assert km.cluster_centers_.dtype.kind == \"f\"\n+\n+\n+def test_result_of_kmeans_equal_in_diff_n_jobs():\n+    # PR 9288\n+    rnd = np.random.RandomState(0)\n+    X = rnd.normal(size=(50, 10))\n+\n+    result_1 = KMeans(n_clusters=3, random_state=0, n_jobs=1).fit(X).labels_\n+    result_2 = KMeans(n_clusters=3, random_state=0, n_jobs=2).fit(X).labels_\n+    assert_array_equal(result_1, result_2)\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/9288"}