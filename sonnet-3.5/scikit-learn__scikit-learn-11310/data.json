{"instance_id": "scikit-learn__scikit-learn-11310", "score": "C", "diff": "diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\nindex 99d6096af..e123620af 100644\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -5,6 +5,8 @@ parameters of an estimator.\n from __future__ import print_function\n from __future__ import division\n \n+import time\n+\n # Author: Alexandre Gramfort <alexandre.gramfort@inria.fr>,\n #         Gael Varoquaux <gael.varoquaux@normalesup.org>\n #         Andreas Mueller <amueller@ais.uni-bonn.de>\n@@ -405,7 +407,14 @@ class _CVScoreTuple (namedtuple('_CVScoreTuple',\n \n class BaseSearchCV(six.with_metaclass(ABCMeta, BaseEstimator,\n                                       MetaEstimatorMixin)):\n-    \"\"\"Base class for hyper parameter search with cross-validation.\"\"\"\n+    \"\"\"Base class for hyper parameter search with cross-validation.\n+\n+    Attributes\n+    ----------\n+    refit_time_ : float\n+        Seconds used for refitting the best model on the whole dataset.\n+        This is present only if ``refit`` is not False.\n+    \"\"\"\n \n     @abstractmethod\n     def __init__(self, estimator, scoring=None,\n@@ -766,10 +775,13 @@ class BaseSearchCV(six.with_metaclass(ABCMeta, BaseEstimator,\n         if self.refit:\n             self.best_estimator_ = clone(base_estimator).set_params(\n                 **self.best_params_)\n+            refit_start_time = time.time()\n             if y is not None:\n                 self.best_estimator_.fit(X, y, **fit_params)\n             else:\n                 self.best_estimator_.fit(X, **fit_params)\n+            refit_end_time = time.time()\n+            self.refit_time_ = refit_end_time - refit_start_time\n \n         # Store the only scorer not as a dict for single metric evaluation\n         self.scorer_ = scorers if self.multimetric_ else scorers['score']\n@@ -821,6 +833,12 @@ class GridSearchCV(BaseSearchCV):\n \n     Read more in the :ref:`User Guide <grid_search>`.\n \n+    Attributes\n+    ----------\n+    refit_time_ : float\n+        Seconds used for refitting the best model on the whole dataset.\n+        This is present only if ``refit`` is not False.\n+\n     Parameters\n     ----------\n     estimator : estimator object.\n@@ -1151,6 +1169,12 @@ class RandomizedSearchCV(BaseSearchCV):\n \n     Read more in the :ref:`User Guide <randomized_parameter_search>`.\n \n+    Attributes\n+    ----------\n+    refit_time_ : float\n+        Seconds used for refitting the best model on the whole dataset.\n+        This is present only if ``refit`` is not False.\n+\n     Parameters\n     ----------\n     estimator : estimator object.\n", "gold_standard_diff": "diff --git a/doc/whats_new/v0.20.rst b/doc/whats_new/v0.20.rst\nindex 32b4ef3098263..b5a43b0b8fc3b 100644\n--- a/doc/whats_new/v0.20.rst\n+++ b/doc/whats_new/v0.20.rst\n@@ -253,6 +253,13 @@ Model evaluation and meta-estimators\n   return estimators fitted on each split. :issue:`9686` by :user:`Aur\u00e9lien Bellet\n   <bellet>`.\n \n+- New ``refit_time_`` attribute will be stored in\n+  :class:`model_selection.GridSearchCV` and\n+  :class:`model_selection.RandomizedSearchCV` if ``refit`` is set to ``True``.\n+  This will allow measuring the complete time it takes to perform\n+  hyperparameter optimization and refitting the best model on the whole\n+  dataset. :issue:`11310` by :user:`Matthias Feurer <mfeurer>`.\n+\n Decomposition and manifold learning\n \n - Speed improvements for both 'exact' and 'barnes_hut' methods in\ndiff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\nindex 99d6096af73db..a339b9b167634 100644\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -17,6 +17,7 @@\n from functools import partial, reduce\n from itertools import product\n import operator\n+import time\n import warnings\n \n import numpy as np\n@@ -766,10 +767,13 @@ def _store(key_name, array, weights=None, splits=False, rank=False):\n         if self.refit:\n             self.best_estimator_ = clone(base_estimator).set_params(\n                 **self.best_params_)\n+            refit_start_time = time.time()\n             if y is not None:\n                 self.best_estimator_.fit(X, y, **fit_params)\n             else:\n                 self.best_estimator_.fit(X, **fit_params)\n+            refit_end_time = time.time()\n+            self.refit_time_ = refit_end_time - refit_start_time\n \n         # Store the only scorer not as a dict for single metric evaluation\n         self.scorer_ = scorers if self.multimetric_ else scorers['score']\n@@ -1076,6 +1080,11 @@ class GridSearchCV(BaseSearchCV):\n     n_splits_ : int\n         The number of cross-validation splits (folds/iterations).\n \n+    refit_time_ : float\n+        Seconds used for refitting the best model on the whole dataset.\n+\n+        This is present only if ``refit`` is not False.\n+\n     Notes\n     ------\n     The parameters selected are those that maximize the score of the left out\n@@ -1387,6 +1396,11 @@ class RandomizedSearchCV(BaseSearchCV):\n     n_splits_ : int\n         The number of cross-validation splits (folds/iterations).\n \n+    refit_time_ : float\n+        Seconds used for refitting the best model on the whole dataset.\n+\n+        This is present only if ``refit`` is not False.\n+\n     Notes\n     -----\n     The parameters selected are those that maximize the score of the held-out\ndiff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py\nindex f436c7b55cf36..0b7b0338f9ada 100644\n--- a/sklearn/model_selection/tests/test_search.py\n+++ b/sklearn/model_selection/tests/test_search.py\n@@ -26,6 +26,7 @@\n from sklearn.utils.testing import assert_array_equal\n from sklearn.utils.testing import assert_array_almost_equal\n from sklearn.utils.testing import assert_almost_equal\n+from sklearn.utils.testing import assert_greater_equal\n from sklearn.utils.testing import ignore_warnings\n from sklearn.utils.mocking import CheckingClassifier, MockDataFrame\n \n@@ -1172,6 +1173,10 @@ def test_search_cv_timing():\n             assert_true(search.cv_results_[key][0] == 0.0)\n             assert_true(np.all(search.cv_results_[key] < 1))\n \n+        assert_true(hasattr(search, \"refit_time_\"))\n+        assert_true(isinstance(search.refit_time_, float))\n+        assert_greater_equal(search.refit_time_, 0)\n+\n \n def test_grid_search_correct_score_results():\n     # test that correct scores are used\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/11310"}