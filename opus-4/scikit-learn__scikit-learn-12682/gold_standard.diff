From efe7a274d8573b8cd5f85d86a97b9a275c98494d Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Tue, 27 Nov 2018 09:28:05 +0100
Subject: [PATCH 01/18] SparseCoder passes max_iter to LassoLarse

---
 doc/whats_new/v0.21.rst                | 8 ++++++++
 sklearn/decomposition/dict_learning.py | 2 +-
 2 files changed, 9 insertions(+), 1 deletion(-)

diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst
index 4d472a0bb9835..d394964517c7b 100644
--- a/doc/whats_new/v0.21.rst
+++ b/doc/whats_new/v0.21.rst
@@ -22,6 +22,7 @@ random sampling procedures.
 
 - Decision trees and derived ensembles when both `max_depth` and
   `max_leaf_nodes` are set. |Fix|
+- :class:`decomposition.SparseCoder` with `algorithm='lasso_lars'` |Fix|
 - :class:`linear_model.LogisticRegression` and
   :class:`linear_model.LogisticRegressionCV` with 'saga' solver. |Fix|
 
@@ -55,6 +56,13 @@ Support for Python 3.4 and below has been officially dropped.
   to set and that scales better, by :user:`Shane <espg>`,
   :user:`Adrin Jalali <adrinjalali>`, and :user:`Erich Schubert <kno10>`.
 
+:mod:`slkearn.decomposition`
+............................
+
+- |Fix| :class:`decomposition.SparseCoder` now passes `max_iter` to the
+  underlying :class:`linear_model.LassoLars` when algorithm is set to
+  `lasso_lars`. :issue:`12650` by user:`Adrin Jalali <adrinjalali>`.
+
 :mod:`sklearn.linear_model`
 ...........................
 
diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index 65ae605b6c19b..858f936f54aa5 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -119,7 +119,7 @@ def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',
             lasso_lars = LassoLars(alpha=alpha, fit_intercept=False,
                                    verbose=verbose, normalize=False,
                                    precompute=gram, fit_path=False,
-                                   positive=positive)
+                                   positive=positive, max_iter=max_iter)
             lasso_lars.fit(dictionary.T, X.T, Xy=cov)
             new_code = lasso_lars.coef_
         finally:

From 75df47a41510592e142289a74d61b51fb76a5a7c Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Wed, 28 Nov 2018 15:03:24 +0100
Subject: [PATCH 02/18] expose methods' max_iter as transform_max_iter

---
 sklearn/decomposition/dict_learning.py | 47 ++++++++++++++++----------
 1 file changed, 29 insertions(+), 18 deletions(-)

diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index 858f936f54aa5..e2afaa5535371 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -326,6 +326,7 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',
             init=init[this_slice] if init is not None else None,
             max_iter=max_iter,
             check_input=False,
+            verbose=verbose,
             positive=positive)
         for this_slice in slices)
     for this_slice, this_view in zip(slices, code_views):
@@ -571,7 +572,8 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
 
         # Update code
         code = sparse_encode(X, dictionary, algorithm=method, alpha=alpha,
-                             init=code, n_jobs=n_jobs, positive=positive_code)
+                             init=code, n_jobs=n_jobs, positive=positive_code,
+                             max_iter=max_iter, verbose=verbose)
         # Update dictionary
         dictionary, residuals = _update_dict(dictionary.T, X.T, code.T,
                                              verbose=verbose, return_r2=True,
@@ -605,10 +607,11 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
 def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
                          return_code=True, dict_init=None, callback=None,
                          batch_size=3, verbose=False, shuffle=True,
-                         n_jobs=None, method='lars', iter_offset=0,
-                         random_state=None, return_inner_stats=False,
-                         inner_stats=None, return_n_iter=False,
-                         positive_dict=False, positive_code=False):
+                         n_jobs=None, method='lars', method_max_iter=1000,
+                         iter_offset=0, random_state=None,
+                         return_inner_stats=False, inner_stats=None,
+                         return_n_iter=False, positive_dict=False,
+                         positive_code=False):
     """Solves a dictionary learning matrix factorization problem online.
 
     Finds the best dictionary and the corresponding sparse code for
@@ -797,7 +800,8 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
         this_code = sparse_encode(this_X, dictionary.T, algorithm=method,
                                   alpha=alpha, n_jobs=n_jobs,
                                   check_input=False,
-                                  positive=positive_code).T
+                                  positive=positive_code,
+                                  max_iter=method_max_iter, verbose=verbose).T
 
         # Update the auxiliary variables
         if ii < batch_size - 1:
@@ -834,7 +838,8 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
             print('|', end=' ')
         code = sparse_encode(X, dictionary.T, algorithm=method, alpha=alpha,
                              n_jobs=n_jobs, check_input=False,
-                             positive=positive_code)
+                             positive=positive_code, max_iter=method_max_iter,
+                             verbose=verbose)
         if verbose > 1:
             dt = (time.time() - t0)
             print('done (total time: % 3is, % 4.1fmn)' % (dt, dt / 60))
@@ -855,12 +860,14 @@ class SparseCodingMixin(TransformerMixin):
     def _set_sparse_coding_params(self, n_components,
                                   transform_algorithm='omp',
                                   transform_n_nonzero_coefs=None,
-                                  transform_alpha=None, split_sign=False,
+                                  transform_alpha=None,
+                                  transform_max_iter=1000, split_sign=False,
                                   n_jobs=None, positive_code=False):
         self.n_components = n_components
         self.transform_algorithm = transform_algorithm
         self.transform_n_nonzero_coefs = transform_n_nonzero_coefs
         self.transform_alpha = transform_alpha
+        self.transform_max_iter = transform_max_iter
         self.split_sign = split_sign
         self.n_jobs = n_jobs
         self.positive_code = positive_code
@@ -890,8 +897,8 @@ def transform(self, X):
         code = sparse_encode(
             X, self.components_, algorithm=self.transform_algorithm,
             n_nonzero_coefs=self.transform_n_nonzero_coefs,
-            alpha=self.transform_alpha, n_jobs=self.n_jobs,
-            positive=self.positive_code)
+            alpha=self.transform_alpha, max_iter=self.transform_max_iter,
+            n_jobs=self.n_jobs, positive=self.positive_code)
 
         if self.split_sign:
             # feature vector is split into a positive and negative side
@@ -982,11 +989,13 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
 
     def __init__(self, dictionary, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 split_sign=False, n_jobs=None, positive_code=False):
+                 transform_max_iter=1000, split_sign=False, n_jobs=None,
+                 positive_code=False):
         self._set_sparse_coding_params(dictionary.shape[0],
                                        transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, split_sign, n_jobs,
+                                       transform_alpha, transform_max_iter,
+                                       split_sign, n_jobs,
                                        positive_code)
         self.components_ = dictionary
 
@@ -1147,8 +1156,8 @@ def __init__(self, n_components=None, alpha=1, max_iter=1000, tol=1e-8,
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, split_sign, n_jobs,
-                                       positive_code)
+                                       transform_alpha, max_iter, split_sign,
+                                       n_jobs, positive_code)
         self.alpha = alpha
         self.max_iter = max_iter
         self.tol = tol
@@ -1331,13 +1340,13 @@ def __init__(self, n_components=None, alpha=1, n_iter=1000,
                  fit_algorithm='lars', n_jobs=None, batch_size=3,
                  shuffle=True, dict_init=None, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 verbose=False, split_sign=False, random_state=None,
-                 positive_code=False, positive_dict=False):
+                 transform_max_iter=1000, verbose=False, split_sign=False,
+                 random_state=None, positive_code=False, positive_dict=False):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, split_sign, n_jobs,
-                                       positive_code)
+                                       transform_alpha, transform_max_iter,
+                                       split_sign, n_jobs, positive_code)
         self.alpha = alpha
         self.n_iter = n_iter
         self.fit_algorithm = fit_algorithm
@@ -1372,6 +1381,7 @@ def fit(self, X, y=None):
             X, self.n_components, self.alpha,
             n_iter=self.n_iter, return_code=False,
             method=self.fit_algorithm,
+            method_max_iter=self.transform_max_iter,
             n_jobs=self.n_jobs, dict_init=self.dict_init,
             batch_size=self.batch_size, shuffle=self.shuffle,
             verbose=self.verbose, random_state=random_state,
@@ -1421,6 +1431,7 @@ def partial_fit(self, X, y=None, iter_offset=None):
         U, (A, B) = dict_learning_online(
             X, self.n_components, self.alpha,
             n_iter=self.n_iter, method=self.fit_algorithm,
+            method_max_iter=self.transform_max_iter,
             n_jobs=self.n_jobs, dict_init=dict_init,
             batch_size=len(X), shuffle=False,
             verbose=self.verbose, return_code=False,

From 43bfe37f6cc48e3d7eea710749f814589a5c99b8 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Wed, 28 Nov 2018 16:37:32 +0100
Subject: [PATCH 03/18] add a test

---
 .../decomposition/tests/test_dict_learning.py | 49 +++++++++++++++++++
 1 file changed, 49 insertions(+)

diff --git a/sklearn/decomposition/tests/test_dict_learning.py b/sklearn/decomposition/tests/test_dict_learning.py
index fd2937ed8f25d..8d516c67f7c1d 100644
--- a/sklearn/decomposition/tests/test_dict_learning.py
+++ b/sklearn/decomposition/tests/test_dict_learning.py
@@ -57,6 +57,55 @@ def test_dict_learning_overcomplete():
     assert dico.components_.shape == (n_components, n_features)
 
 
+def test_max_iter():
+    def ricker_function(resolution, center, width):
+        """Discrete sub-sampled Ricker (Mexican hat) wavelet"""
+        x = np.linspace(0, resolution - 1, resolution)
+        x = ((2 / ((np.sqrt(3 * width) * np.pi ** 1 / 4)))
+             * (1 - ((x - center) ** 2 / width ** 2))
+             * np.exp((-(x - center) ** 2) / (2 * width ** 2)))
+        return x
+
+    def ricker_matrix(width, resolution, n_components):
+        """Dictionary of Ricker (Mexican hat) wavelets"""
+        centers = np.linspace(0, resolution - 1, n_components)
+        D = np.empty((n_components, resolution))
+        for i, center in enumerate(centers):
+            D[i] = ricker_function(resolution, center, width)
+        D /= np.sqrt(np.sum(D ** 2, axis=1))[:, np.newaxis]
+        return D
+
+    transform_algorithm = 'lasso_cd'
+    resolution = 1024
+    subsampling = 3  # subsampling factor
+    width = 100
+    n_components = resolution // subsampling
+
+    # Compute a wavelet dictionary
+    D_multi = np.r_[tuple(ricker_matrix(width=w, resolution=resolution,
+                          n_components=n_components // 5)
+                          for w in (10, 50, 100, 500, 1000))]
+
+    X = np.linspace(0, resolution - 1, resolution)
+    first_quarter = X < resolution / 4
+    X[first_quarter] = 3.
+    X[np.logical_not(first_quarter)] = -1.
+    X = X.reshape(1, -1)
+
+    # check that the underlying model fails to converge
+    with pytest.warns(ConvergenceWarning):
+        model = SparseCoder(D_multi, transform_algorithm=transform_algorithm,
+                            transform_max_iter=1)
+        model.fit_transform(X)
+
+    # check that the underlying model converges w/o warnings
+    with pytest.warns(None) as record:
+        model = SparseCoder(D_multi, transform_algorithm=transform_algorithm,
+                            transform_max_iter=2000)
+        model.fit_transform(X)
+    assert not record.list
+
+
 # positive lars deprecated 0.22
 @pytest.mark.filterwarnings('ignore::DeprecationWarning')
 @pytest.mark.parametrize("transform_algorithm", [

From 7dce627c3f9d5e366e3fa5bf16467f2f60454313 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Wed, 28 Nov 2018 16:43:32 +0100
Subject: [PATCH 04/18] remove extra var

---
 sklearn/decomposition/tests/test_dict_learning.py | 1 -
 1 file changed, 1 deletion(-)

diff --git a/sklearn/decomposition/tests/test_dict_learning.py b/sklearn/decomposition/tests/test_dict_learning.py
index 8d516c67f7c1d..06151b9067950 100644
--- a/sklearn/decomposition/tests/test_dict_learning.py
+++ b/sklearn/decomposition/tests/test_dict_learning.py
@@ -78,7 +78,6 @@ def ricker_matrix(width, resolution, n_components):
     transform_algorithm = 'lasso_cd'
     resolution = 1024
     subsampling = 3  # subsampling factor
-    width = 100
     n_components = resolution // subsampling
 
     # Compute a wavelet dictionary

From 5f6882a336c2d97c38a473fc6149896dba383211 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Thu, 29 Nov 2018 12:08:39 +0100
Subject: [PATCH 05/18] pass tests

---
 sklearn/decomposition/dict_learning.py | 26 +++++++++++++++++++++-----
 1 file changed, 21 insertions(+), 5 deletions(-)

diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index e2afaa5535371..f8fb63f0e4843 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -672,6 +672,10 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
         Lasso solution (linear_model.Lasso). Lars will be faster if
         the estimated components are sparse.
 
+    method_max_iter : int, optional (default=1000)
+        It is passed to the underlying `method` as their `max_iter`
+        parameter.
+
     iter_offset : int, default 0
         Number of previous iterations completed on the dictionary used for
         initialization.
@@ -956,6 +960,10 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
         the reconstruction error targeted. In this case, it overrides
         `n_nonzero_coefs`.
 
+    transform_max_iter : int, optional (default=1000)
+        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
+        `transform_max_iter` is passed to the underlying transformer.
+
     split_sign : bool, False by default
         Whether to split the sparse feature vector into the concatenation of
         its negative part and its positive part. This can improve the
@@ -1086,6 +1094,10 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
         the reconstruction error targeted. In this case, it overrides
         `n_nonzero_coefs`.
 
+    transform_max_iter : int, optional (default=1000)
+        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
+        `transform_max_iter` is passed to the underlying transformer.
+
     n_jobs : int or None, optional (default=None)
         Number of parallel jobs to run.
         ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
@@ -1150,14 +1162,14 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
     def __init__(self, n_components=None, alpha=1, max_iter=1000, tol=1e-8,
                  fit_algorithm='lars', transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 n_jobs=None, code_init=None, dict_init=None, verbose=False,
-                 split_sign=False, random_state=None,
-                 positive_code=False, positive_dict=False):
+                 transform_max_iter=1000, n_jobs=None, code_init=None,
+                 dict_init=None, verbose=False, split_sign=False,
+                 random_state=None, positive_code=False, positive_dict=False):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, max_iter, split_sign,
-                                       n_jobs, positive_code)
+                                       transform_alpha, transform_max_iter,
+                                       split_sign, n_jobs, positive_code)
         self.alpha = alpha
         self.max_iter = max_iter
         self.tol = tol
@@ -1281,6 +1293,10 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
         the reconstruction error targeted. In this case, it overrides
         `n_nonzero_coefs`.
 
+    transform_max_iter : int, optional (default=1000)
+        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
+        `transform_max_iter` is passed to the underlying transformer.
+
     verbose : bool, optional (default: False)
         To control the verbosity of the procedure.
 

From d9ba9efe70c09f556a67b358e9cffb143e28c33d Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Mon, 3 Dec 2018 17:41:28 +0100
Subject: [PATCH 06/18] add method_max_iter to dic_learning as well

---
 sklearn/decomposition/dict_learning.py | 13 +++++++++----
 1 file changed, 9 insertions(+), 4 deletions(-)

diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index f8fb63f0e4843..1e5ac80830084 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -418,9 +418,9 @@ def _update_dict(dictionary, Y, code, verbose=False, return_r2=False,
 
 
 def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
-                  method='lars', n_jobs=None, dict_init=None, code_init=None,
-                  callback=None, verbose=False, random_state=None,
-                  return_n_iter=False, positive_dict=False,
+                  method='lars', method_max_iter=1000, n_jobs=None,
+                  dict_init=None, code_init=None, callback=None, verbose=False,
+                  random_state=None, return_n_iter=False, positive_dict=False,
                   positive_code=False):
     """Solves a dictionary learning matrix factorization problem.
 
@@ -459,6 +459,10 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
         Lasso solution (linear_model.Lasso). Lars will be faster if
         the estimated components are sparse.
 
+    method_max_iter : int, optional (default=1000)
+        It is passed to the underlying `method` as their `max_iter`
+        parameter.
+
     n_jobs : int or None, optional (default=None)
         Number of parallel jobs to run.
         ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
@@ -573,7 +577,7 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
         # Update code
         code = sparse_encode(X, dictionary, algorithm=method, alpha=alpha,
                              init=code, n_jobs=n_jobs, positive=positive_code,
-                             max_iter=max_iter, verbose=verbose)
+                             max_iter=method_max_iter, verbose=verbose)
         # Update dictionary
         dictionary, residuals = _update_dict(dictionary.T, X.T, code.T,
                                              verbose=verbose, return_r2=True,
@@ -1207,6 +1211,7 @@ def fit(self, X, y=None):
             X, n_components, self.alpha,
             tol=self.tol, max_iter=self.max_iter,
             method=self.fit_algorithm,
+            method_max_iter=self.transform_max_iter,
             n_jobs=self.n_jobs,
             code_init=self.code_init,
             dict_init=self.dict_init,

From 1d2bd30a0567aedfd9532a74f101e78f96cabedc Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Mon, 3 Dec 2018 17:52:00 +0100
Subject: [PATCH 07/18] include all changes in the whats_new

---
 doc/whats_new/v0.21.rst | 13 ++++++++++---
 1 file changed, 10 insertions(+), 3 deletions(-)

diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst
index d394964517c7b..b8bf8aa7b23e9 100644
--- a/doc/whats_new/v0.21.rst
+++ b/doc/whats_new/v0.21.rst
@@ -59,9 +59,16 @@ Support for Python 3.4 and below has been officially dropped.
 :mod:`slkearn.decomposition`
 ............................
 
-- |Fix| :class:`decomposition.SparseCoder` now passes `max_iter` to the
-  underlying :class:`linear_model.LassoLars` when algorithm is set to
-  `lasso_lars`. :issue:`12650` by user:`Adrin Jalali <adrinjalali>`.
+- |Fix| `sparse_encode()` now passes the `max_iter` to the underlying
+  `LassoLarse` when `algorithm='lasso_lars'`. :issue:`12650` by user:`Adrin
+  Jalali <adrinjalali>`.
+- |Enhancement| `dict_learning()` and `dict_learning_online()` now accept
+  `method_max_iter` and pass it to `sparse_encode`. :issue:`12650` by
+  user:`Adrin Jalali <adrinjalali>`.
+- |Enhancement| `SparseCoder`, `DictionaryLearning`, and
+  `MiniBatchDictionaryLearning` now take a `transform_max_iter` parameter and
+  pass it to either `dict_learning()` or `sparse_encode()`. :issue:`12650` by
+  user:`Adrin Jalali <adrinjalali>`.
 
 :mod:`sklearn.linear_model`
 ...........................

From b7cebac2f38b6371c0e297e008b3600e52250939 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Fri, 7 Dec 2018 11:38:49 +0100
Subject: [PATCH 08/18] fix/improve the whats_new entries

---
 doc/whats_new/v0.21.rst | 28 +++++++++++++++++++---------
 1 file changed, 19 insertions(+), 9 deletions(-)

diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst
index b8bf8aa7b23e9..6c7fcd60f02a0 100644
--- a/doc/whats_new/v0.21.rst
+++ b/doc/whats_new/v0.21.rst
@@ -22,6 +22,12 @@ random sampling procedures.
 
 - Decision trees and derived ensembles when both `max_depth` and
   `max_leaf_nodes` are set. |Fix|
+- :func:`decomposition.sparse_encode()` with `algorithm='lasso_lars'` |Fix|
+- :func:`decomposition.dict_learning()` and
+  :func:`decomposition.dict_learning_online()` |Fix|
+- :class:`decomposition.SparseCoder`,
+  :class:`decomposition.DictionaryLearning`, and
+  :class:`decomposition.MiniBatchDictionaryLearning` |Fix|
 - :class:`decomposition.SparseCoder` with `algorithm='lasso_lars'` |Fix|
 - :class:`linear_model.LogisticRegression` and
   :class:`linear_model.LogisticRegressionCV` with 'saga' solver. |Fix|
@@ -59,16 +65,20 @@ Support for Python 3.4 and below has been officially dropped.
 :mod:`slkearn.decomposition`
 ............................
 
-- |Fix| `sparse_encode()` now passes the `max_iter` to the underlying
-  `LassoLarse` when `algorithm='lasso_lars'`. :issue:`12650` by user:`Adrin
-  Jalali <adrinjalali>`.
-- |Enhancement| `dict_learning()` and `dict_learning_online()` now accept
-  `method_max_iter` and pass it to `sparse_encode`. :issue:`12650` by
-  user:`Adrin Jalali <adrinjalali>`.
-- |Enhancement| `SparseCoder`, `DictionaryLearning`, and
-  `MiniBatchDictionaryLearning` now take a `transform_max_iter` parameter and
-  pass it to either `dict_learning()` or `sparse_encode()`. :issue:`12650` by
+- |Fix| :func:`decomposition.sparse_encode()` now passes the `max_iter` to the
+  underlying `LassoLarse` when `algorithm='lasso_lars'`. :issue:`12650` by
   user:`Adrin Jalali <adrinjalali>`.
+- |Enhancement| :func:`decomposition.dict_learning()` and
+  :func:`decomposition.dict_learning_online()` now accept `method_max_iter` and
+  pass it to `sparse_encode`. :issue:`12650` by user:`Adrin Jalali
+  <adrinjalali>`.
+- |Enhancement| :class:`decomposition.SparseCoder`,
+  :class:`decomposition.DictionaryLearning`, and
+  :class:`decomposition.MiniBatchDictionaryLearning` now take a
+  `transform_max_iter` parameter and pass it to either
+  :func:`decomposition.dict_learning()` or
+  :func:`decomposition.sparse_encode()`. :issue:`12650` by user:`Adrin Jalali
+  <adrinjalali>`.
 
 :mod:`sklearn.linear_model`
 ...........................

From fcff14a010e8f5191d166b31599c4c4f4ad17d25 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Wed, 16 Jan 2019 16:27:05 +0100
Subject: [PATCH 09/18] fix paranthesis issue

---
 doc/whats_new/v0.21.rst                           | 5 +----
 examples/decomposition/plot_sparse_coding.py      | 2 +-
 sklearn/decomposition/tests/test_dict_learning.py | 2 +-
 3 files changed, 3 insertions(+), 6 deletions(-)

diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst
index 55ea0ddb41634..1dc0792e60a0f 100644
--- a/doc/whats_new/v0.21.rst
+++ b/doc/whats_new/v0.21.rst
@@ -20,9 +20,6 @@ random sampling procedures.
 - :class:`linear_model.BayesianRidge` |Fix|
 - Decision trees and derived ensembles when both `max_depth` and
   `max_leaf_nodes` are set. |Fix|
-- :func:`decomposition.sparse_encode()` with `algorithm='lasso_lars'` |Fix|
-- :func:`decomposition.dict_learning()` and
-  :func:`decomposition.dict_learning_online()` |Fix|
 - :class:`decomposition.SparseCoder`,
   :class:`decomposition.DictionaryLearning`, and
   :class:`decomposition.MiniBatchDictionaryLearning` |Fix|
@@ -69,7 +66,7 @@ Support for Python 3.4 and below has been officially dropped.
 ............................
 
 - |Fix| :func:`decomposition.sparse_encode()` now passes the `max_iter` to the
-  underlying `LassoLarse` when `algorithm='lasso_lars'`. :issue:`12650` by
+  underlying `LassoLars` when `algorithm='lasso_lars'`. :issue:`12650` by
   user:`Adrin Jalali <adrinjalali>`.
 - |Enhancement| :func:`decomposition.dict_learning()` and
   :func:`decomposition.dict_learning_online()` now accept `method_max_iter` and
diff --git a/examples/decomposition/plot_sparse_coding.py b/examples/decomposition/plot_sparse_coding.py
index 14cab33743730..fadec3dd8f8d4 100644
--- a/examples/decomposition/plot_sparse_coding.py
+++ b/examples/decomposition/plot_sparse_coding.py
@@ -27,7 +27,7 @@
 def ricker_function(resolution, center, width):
     """Discrete sub-sampled Ricker (Mexican hat) wavelet"""
     x = np.linspace(0, resolution - 1, resolution)
-    x = ((2 / ((np.sqrt(3 * width) * np.pi ** 1 / 4)))
+    x = ((2 / (np.sqrt(3 * width) * np.pi ** .25))
          * (1 - ((x - center) ** 2 / width ** 2))
          * np.exp((-(x - center) ** 2) / (2 * width ** 2)))
     return x
diff --git a/sklearn/decomposition/tests/test_dict_learning.py b/sklearn/decomposition/tests/test_dict_learning.py
index 3ff0ac96f8022..730a637c7028d 100644
--- a/sklearn/decomposition/tests/test_dict_learning.py
+++ b/sklearn/decomposition/tests/test_dict_learning.py
@@ -61,7 +61,7 @@ def test_max_iter():
     def ricker_function(resolution, center, width):
         """Discrete sub-sampled Ricker (Mexican hat) wavelet"""
         x = np.linspace(0, resolution - 1, resolution)
-        x = ((2 / ((np.sqrt(3 * width) * np.pi ** 1 / 4)))
+        x = ((2 / (np.sqrt(3 * width) * np.pi ** .25))
              * (1 - ((x - center) ** 2 / width ** 2))
              * np.exp((-(x - center) ** 2) / (2 * width ** 2)))
         return x

From e6db55b338955be46cf37f21e52efccd787dc2f2 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Wed, 16 Jan 2019 16:33:11 +0100
Subject: [PATCH 10/18] less ()

---
 examples/decomposition/plot_sparse_coding.py      | 4 ++--
 sklearn/decomposition/tests/test_dict_learning.py | 4 ++--
 2 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/examples/decomposition/plot_sparse_coding.py b/examples/decomposition/plot_sparse_coding.py
index fadec3dd8f8d4..2dcc3c02e1abb 100644
--- a/examples/decomposition/plot_sparse_coding.py
+++ b/examples/decomposition/plot_sparse_coding.py
@@ -28,8 +28,8 @@ def ricker_function(resolution, center, width):
     """Discrete sub-sampled Ricker (Mexican hat) wavelet"""
     x = np.linspace(0, resolution - 1, resolution)
     x = ((2 / (np.sqrt(3 * width) * np.pi ** .25))
-         * (1 - ((x - center) ** 2 / width ** 2))
-         * np.exp((-(x - center) ** 2) / (2 * width ** 2)))
+         * (1 - (x - center) ** 2 / width ** 2)
+         * np.exp(-(x - center) ** 2 / (2 * width ** 2)))
     return x
 
 
diff --git a/sklearn/decomposition/tests/test_dict_learning.py b/sklearn/decomposition/tests/test_dict_learning.py
index 730a637c7028d..e97132511e9ef 100644
--- a/sklearn/decomposition/tests/test_dict_learning.py
+++ b/sklearn/decomposition/tests/test_dict_learning.py
@@ -62,8 +62,8 @@ def ricker_function(resolution, center, width):
         """Discrete sub-sampled Ricker (Mexican hat) wavelet"""
         x = np.linspace(0, resolution - 1, resolution)
         x = ((2 / (np.sqrt(3 * width) * np.pi ** .25))
-             * (1 - ((x - center) ** 2 / width ** 2))
-             * np.exp((-(x - center) ** 2) / (2 * width ** 2)))
+             * (1 - (x - center) ** 2 / width ** 2)
+             * np.exp(-(x - center) ** 2 / (2 * width ** 2)))
         return x
 
     def ricker_matrix(width, resolution, n_components):

From de72daaacb7a245971382d75aac8c60139091d12 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Fri, 1 Mar 2019 14:44:25 +0100
Subject: [PATCH 11/18] add me in _contributors.rst

---
 doc/whats_new/_contributors.rst | 2 ++
 doc/whats_new/v0.21.rst         | 8 +++-----
 2 files changed, 5 insertions(+), 5 deletions(-)

diff --git a/doc/whats_new/_contributors.rst b/doc/whats_new/_contributors.rst
index 270df1fb837fc..1a7f04b691565 100644
--- a/doc/whats_new/_contributors.rst
+++ b/doc/whats_new/_contributors.rst
@@ -169,3 +169,5 @@
 .. _Roman Yurchak: https://github.com/rth
 
 .. _Hanmin Qin: https://github.com/qinhanmin2014
+
+.. _Adrin Jalali: https://github.com/adrinjalali
diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst
index b22614b4a4043..5ee61df4dcd1e 100644
--- a/doc/whats_new/v0.21.rst
+++ b/doc/whats_new/v0.21.rst
@@ -99,18 +99,16 @@ Support for Python 3.4 and below has been officially dropped.
 
 - |Fix| :func:`decomposition.sparse_encode()` now passes the `max_iter` to the
   underlying `LassoLars` when `algorithm='lasso_lars'`. :issue:`12650` by
-  user:`Adrin Jalali <adrinjalali>`.
+  `Adrin Jalali`_.
 - |Enhancement| :func:`decomposition.dict_learning()` and
   :func:`decomposition.dict_learning_online()` now accept `method_max_iter` and
-  pass it to `sparse_encode`. :issue:`12650` by user:`Adrin Jalali
-  <adrinjalali>`.
+  pass it to `sparse_encode`. :issue:`12650` by `Adrin Jalali`_.
 - |Enhancement| :class:`decomposition.SparseCoder`,
   :class:`decomposition.DictionaryLearning`, and
   :class:`decomposition.MiniBatchDictionaryLearning` now take a
   `transform_max_iter` parameter and pass it to either
   :func:`decomposition.dict_learning()` or
-  :func:`decomposition.sparse_encode()`. :issue:`12650` by user:`Adrin Jalali
-  <adrinjalali>`.
+  :func:`decomposition.sparse_encode()`. :issue:`12650` by `Adrin Jalali`_.
   
 :mod:`sklearn.discriminant_analysis`
 ....................................

From 0dd6a2c007fe462913fcd22ff14d675fca87f5e2 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Wed, 6 Mar 2019 13:38:39 +0100
Subject: [PATCH 12/18] add parameter at the end

---
 sklearn/decomposition/dict_learning.py | 106 ++++++++++++++-----------
 1 file changed, 58 insertions(+), 48 deletions(-)

diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index 6ea4325ba8d66..77756b4ebff2b 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -416,10 +416,10 @@ def _update_dict(dictionary, Y, code, verbose=False, return_r2=False,
 
 
 def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
-                  method='lars', method_max_iter=1000, n_jobs=None,
-                  dict_init=None, code_init=None, callback=None, verbose=False,
-                  random_state=None, return_n_iter=False, positive_dict=False,
-                  positive_code=False):
+                  method='lars', n_jobs=None, dict_init=None, code_init=None,
+                  callback=None, verbose=False, random_state=None,
+                  return_n_iter=False, positive_dict=False,
+                  positive_code=False, method_max_iter=1000):
     """Solves a dictionary learning matrix factorization problem.
 
     Finds the best dictionary and the corresponding sparse code for
@@ -457,10 +457,6 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
         Lasso solution (linear_model.Lasso). Lars will be faster if
         the estimated components are sparse.
 
-    method_max_iter : int, optional (default=1000)
-        It is passed to the underlying `method` as their `max_iter`
-        parameter.
-
     n_jobs : int or None, optional (default=None)
         Number of parallel jobs to run.
         ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
@@ -498,6 +494,12 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
 
         .. versionadded:: 0.20
 
+    method_max_iter : int, optional (default=1000)
+        It is passed to the underlying ``method`` as their ``max_iter``
+        parameter.
+
+        .. versionadded:: 0.21
+
     Returns
     -------
     code : array of shape (n_samples, n_components)
@@ -609,11 +611,11 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
 def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
                          return_code=True, dict_init=None, callback=None,
                          batch_size=3, verbose=False, shuffle=True,
-                         n_jobs=None, method='lars', method_max_iter=1000,
-                         iter_offset=0, random_state=None,
-                         return_inner_stats=False, inner_stats=None,
-                         return_n_iter=False, positive_dict=False,
-                         positive_code=False):
+                         n_jobs=None, method='lars', iter_offset=0,
+                         random_state=None, return_inner_stats=False,
+                         inner_stats=None, return_n_iter=False,
+                         positive_dict=False, positive_code=False,
+                         method_max_iter=1000):
     """Solves a dictionary learning matrix factorization problem online.
 
     Finds the best dictionary and the corresponding sparse code for
@@ -674,10 +676,6 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
         Lasso solution (linear_model.Lasso). Lars will be faster if
         the estimated components are sparse.
 
-    method_max_iter : int, optional (default=1000)
-        It is passed to the underlying `method` as their `max_iter`
-        parameter.
-
     iter_offset : int, default 0
         Number of previous iterations completed on the dictionary used for
         initialization.
@@ -714,6 +712,12 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
 
         .. versionadded:: 0.20
 
+    method_max_iter : int, optional (default=1000)
+        It is passed to the underlying ``method`` as their ``max_iter``
+        parameter.
+
+        .. versionadded:: 0.21
+
     Returns
     -------
     code : array of shape (n_samples, n_components),
@@ -866,9 +870,9 @@ class SparseCodingMixin(TransformerMixin):
     def _set_sparse_coding_params(self, n_components,
                                   transform_algorithm='omp',
                                   transform_n_nonzero_coefs=None,
-                                  transform_alpha=None,
-                                  transform_max_iter=1000, split_sign=False,
-                                  n_jobs=None, positive_code=False):
+                                  transform_alpha=None, split_sign=False,
+                                  n_jobs=None, positive_code=False,
+                                  transform_max_iter=1000):
         self.n_components = n_components
         self.transform_algorithm = transform_algorithm
         self.transform_n_nonzero_coefs = transform_n_nonzero_coefs
@@ -962,10 +966,6 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
         the reconstruction error targeted. In this case, it overrides
         `n_nonzero_coefs`.
 
-    transform_max_iter : int, optional (default=1000)
-        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
-        `transform_max_iter` is passed to the underlying transformer.
-
     split_sign : bool, False by default
         Whether to split the sparse feature vector into the concatenation of
         its negative part and its positive part. This can improve the
@@ -982,6 +982,12 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
 
         .. versionadded:: 0.20
 
+    transform_max_iter : int, optional (default=1000)
+        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
+        `transform_max_iter` is passed to the underlying transformer.
+
+        .. versionadded:: 0.21
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
@@ -999,14 +1005,13 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
 
     def __init__(self, dictionary, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 transform_max_iter=1000, split_sign=False, n_jobs=None,
-                 positive_code=False):
+                 split_sign=False, n_jobs=None, positive_code=False,
+                 transform_max_iter=1000):
         self._set_sparse_coding_params(dictionary.shape[0],
                                        transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, transform_max_iter,
-                                       split_sign, n_jobs,
-                                       positive_code)
+                                       transform_alpha, split_sign, n_jobs,
+                                       positive_code, transform_max_iter)
         self.components_ = dictionary
 
     def fit(self, X, y=None):
@@ -1096,10 +1101,6 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
         the reconstruction error targeted. In this case, it overrides
         `n_nonzero_coefs`.
 
-    transform_max_iter : int, optional (default=1000)
-        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
-        `transform_max_iter` is passed to the underlying transformer.
-
     n_jobs : int or None, optional (default=None)
         Number of parallel jobs to run.
         ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.
@@ -1136,6 +1137,12 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
 
         .. versionadded:: 0.20
 
+    transform_max_iter : int, optional (default=1000)
+        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
+        `transform_max_iter` is passed to the underlying transformer.
+
+        .. versionadded:: 0.21
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
@@ -1164,14 +1171,14 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
     def __init__(self, n_components=None, alpha=1, max_iter=1000, tol=1e-8,
                  fit_algorithm='lars', transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 transform_max_iter=1000, n_jobs=None, code_init=None,
-                 dict_init=None, verbose=False, split_sign=False,
-                 random_state=None, positive_code=False, positive_dict=False):
+                 n_jobs=None, code_init=None, dict_init=None, verbose=False,
+                 split_sign=False, random_state=None, positive_code=False,
+                 positive_dict=False, transform_max_iter=1000):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, transform_max_iter,
-                                       split_sign, n_jobs, positive_code)
+                                       transform_alpha, split_sign, n_jobs,
+                                       positive_code, transform_max_iter)
         self.alpha = alpha
         self.max_iter = max_iter
         self.tol = tol
@@ -1296,10 +1303,6 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
         the reconstruction error targeted. In this case, it overrides
         `n_nonzero_coefs`.
 
-    transform_max_iter : int, optional (default=1000)
-        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
-        `transform_max_iter` is passed to the underlying transformer.
-
     verbose : bool, optional (default: False)
         To control the verbosity of the procedure.
 
@@ -1324,6 +1327,12 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
 
         .. versionadded:: 0.20
 
+    transform_max_iter : int, optional (default=1000)
+        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
+        `transform_max_iter` is passed to the underlying transformer.
+
+        .. versionadded:: 0.21
+
     Attributes
     ----------
     components_ : array, [n_components, n_features]
@@ -1356,16 +1365,17 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
 
     """
     def __init__(self, n_components=None, alpha=1, n_iter=1000,
-                 fit_algorithm='lars', n_jobs=None, batch_size=3,
-                 shuffle=True, dict_init=None, transform_algorithm='omp',
+                 fit_algorithm='lars', n_jobs=None, batch_size=3, shuffle=True,
+                 dict_init=None, transform_algorithm='omp',
                  transform_n_nonzero_coefs=None, transform_alpha=None,
-                 transform_max_iter=1000, verbose=False, split_sign=False,
-                 random_state=None, positive_code=False, positive_dict=False):
+                 verbose=False, split_sign=False, random_state=None,
+                 positive_code=False, positive_dict=False,
+                 transform_max_iter=1000):
 
         self._set_sparse_coding_params(n_components, transform_algorithm,
                                        transform_n_nonzero_coefs,
-                                       transform_alpha, transform_max_iter,
-                                       split_sign, n_jobs, positive_code)
+                                       transform_alpha, split_sign, n_jobs,
+                                       positive_code, transform_max_iter)
         self.alpha = alpha
         self.n_iter = n_iter
         self.fit_algorithm = fit_algorithm

From 2e722b78add12a6af24bf9fe75707284def8e8e5 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Thu, 25 Apr 2019 10:49:54 +0200
Subject: [PATCH 13/18] update docstring

---
 sklearn/decomposition/dict_learning.py | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index 77756b4ebff2b..8de4676d1b792 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -983,8 +983,8 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
         .. versionadded:: 0.20
 
     transform_max_iter : int, optional (default=1000)
-        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
-        `transform_max_iter` is passed to the underlying transformer.
+        Maximum number of iterations to perform if `algorithm='lasso_cd'` or
+        `lasso_cd`.
 
         .. versionadded:: 0.21
 

From 4f28dbd0c426f751aebcf116b6fe60d28721f68b Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Thu, 25 Apr 2019 12:57:54 +0200
Subject: [PATCH 14/18] empty commit


From 3829ef44bdc3192f529e9e74cb94458e47e21607 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Fri, 26 Apr 2019 11:57:37 +0200
Subject: [PATCH 15/18] unifying the docstrings for max_iter

---
 sklearn/decomposition/dict_learning.py | 22 +++++++++++-----------
 1 file changed, 11 insertions(+), 11 deletions(-)

diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index 8de4676d1b792..600be0028834d 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -65,7 +65,8 @@ def _sparse_encode(X, dictionary, gram, cov=None, algorithm='lasso_lars',
         `algorithm='lasso_cd'`.
 
     max_iter : int, 1000 by default
-        Maximum number of iterations to perform if `algorithm='lasso_cd'`.
+        Maximum number of iterations to perform if `algorithm='lasso_cd'` or
+        `lasso_lars`.
 
     copy_cov : boolean, optional
         Whether to copy the precomputed covariance matrix; if False, it may be
@@ -241,7 +242,8 @@ def sparse_encode(X, dictionary, gram=None, cov=None, algorithm='lasso_lars',
         `algorithm='lasso_cd'`.
 
     max_iter : int, 1000 by default
-        Maximum number of iterations to perform if `algorithm='lasso_cd'`.
+        Maximum number of iterations to perform if `algorithm='lasso_cd'` or
+        `lasso_lars`.
 
     n_jobs : int or None, optional (default=None)
         Number of parallel jobs to run.
@@ -495,8 +497,7 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
         .. versionadded:: 0.20
 
     method_max_iter : int, optional (default=1000)
-        It is passed to the underlying ``method`` as their ``max_iter``
-        parameter.
+        Maximum number of iterations to perform.
 
         .. versionadded:: 0.21
 
@@ -713,8 +714,7 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
         .. versionadded:: 0.20
 
     method_max_iter : int, optional (default=1000)
-        It is passed to the underlying ``method`` as their ``max_iter``
-        parameter.
+        Maximum number of iterations to perform in each ``sparse_encode`` step.
 
         .. versionadded:: 0.21
 
@@ -984,7 +984,7 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
 
     transform_max_iter : int, optional (default=1000)
         Maximum number of iterations to perform if `algorithm='lasso_cd'` or
-        `lasso_cd`.
+        `lasso_lars`.
 
         .. versionadded:: 0.21
 
@@ -1138,8 +1138,8 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
         .. versionadded:: 0.20
 
     transform_max_iter : int, optional (default=1000)
-        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
-        `transform_max_iter` is passed to the underlying transformer.
+        Maximum number of iterations to perform if `algorithm='lasso_cd'` or
+        `lasso_lars`.
 
         .. versionadded:: 0.21
 
@@ -1328,8 +1328,8 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
         .. versionadded:: 0.20
 
     transform_max_iter : int, optional (default=1000)
-        If `algorithm='lasso_lars'` or `algorithm='lasso_cd'`,
-        `transform_max_iter` is passed to the underlying transformer.
+        Maximum number of iterations to perform if `algorithm='lasso_cd'` or
+        `lasso_lars`.
 
         .. versionadded:: 0.21
 

From e4a4f2d17d2576fd68d004090a0770c4698d4f03 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Thu, 2 May 2019 18:01:21 +0200
Subject: [PATCH 16/18] apply Thomas's comment

---
 sklearn/decomposition/dict_learning.py | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index 600be0028834d..830e86d188b9c 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -644,7 +644,7 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
         Sparsity controlling parameter.
 
     n_iter : int,
-        Number of iterations to perform.
+        Number of mini-batch iterations to perform.
 
     return_code : boolean,
         Whether to also return the code U or just the dictionary V.
@@ -714,7 +714,7 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
         .. versionadded:: 0.20
 
     method_max_iter : int, optional (default=1000)
-        Maximum number of iterations to perform in each ``sparse_encode`` step.
+        Maximum number of iterations to perform when solving the lasso problem.
 
         .. versionadded:: 0.21
 

From 0c49d1845e450400442d81f702be6cf9a70693ba Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Thu, 2 May 2019 18:30:38 +0200
Subject: [PATCH 17/18] move to 0.22

---
 doc/whats_new/v0.21.rst                | 17 -----------------
 doc/whats_new/v0.22.rst                | 25 +++++++++++++++++++++++--
 sklearn/decomposition/dict_learning.py | 10 +++++-----
 3 files changed, 28 insertions(+), 24 deletions(-)

diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst
index 89e9ac08d6780..bf18d8350646e 100644
--- a/doc/whats_new/v0.21.rst
+++ b/doc/whats_new/v0.21.rst
@@ -24,10 +24,6 @@ random sampling procedures.
 - :class:`linear_model.BayesianRidge` |Fix|
 - Decision trees and derived ensembles when both `max_depth` and
   `max_leaf_nodes` are set. |Fix|
-- :class:`decomposition.SparseCoder`,
-  :class:`decomposition.DictionaryLearning`, and
-  :class:`decomposition.MiniBatchDictionaryLearning` |Fix|
-- :class:`decomposition.SparseCoder` with `algorithm='lasso_lars'` |Fix|
 - :class:`linear_model.LogisticRegression` and
   :class:`linear_model.LogisticRegressionCV` with 'saga' solver. |Fix|
 - :class:`ensemble.GradientBoostingClassifier` |Fix|
@@ -160,19 +156,6 @@ Support for Python 3.4 and below has been officially dropped.
   the default value is used.
   :pr:`12988` by :user:`Zijie (ZJ) Poh <zjpoh>`.
 
-- |Fix| :func:`decomposition.sparse_encode()` now passes the `max_iter` to the
-  underlying `LassoLars` when `algorithm='lasso_lars'`. :issue:`12650` by
-  `Adrin Jalali`_.
-- |Enhancement| :func:`decomposition.dict_learning()` and
-  :func:`decomposition.dict_learning_online()` now accept `method_max_iter` and
-  pass it to `sparse_encode`. :issue:`12650` by `Adrin Jalali`_.
-- |Enhancement| :class:`decomposition.SparseCoder`,
-  :class:`decomposition.DictionaryLearning`, and
-  :class:`decomposition.MiniBatchDictionaryLearning` now take a
-  `transform_max_iter` parameter and pass it to either
-  :func:`decomposition.dict_learning()` or
-  :func:`decomposition.sparse_encode()`. :issue:`12650` by `Adrin Jalali`_.
-  
 :mod:`sklearn.discriminant_analysis`
 ....................................
 
diff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst
index ba94680c4efc3..c04d59c3b63b5 100644
--- a/doc/whats_new/v0.22.rst
+++ b/doc/whats_new/v0.22.rst
@@ -17,8 +17,11 @@ parameters, may produce different models from the previous version. This often
 occurs due to changes in the modelling logic (bug fixes or enhancements), or in
 random sampling procedures.
 
-..
-    TO FILL IN AS WE GO
+- :class:`decomposition.SparseCoder`,
+  :class:`decomposition.DictionaryLearning`, and
+  :class:`decomposition.MiniBatchDictionaryLearning` |Fix|
+- :class:`decomposition.SparseCoder` with `algorithm='lasso_lars'` |Fix|
+
 
 Details are listed in the changelog below.
 
@@ -39,6 +42,24 @@ Changelog
     :pr:`123456` by :user:`Joe Bloggs <joeongithub>`.
     where 123456 is the *pull request* number, not the issue number.
 
+:mod:`sklearn.decomposition`
+............................
+
+- |Fix| :func:`decomposition.sparse_encode()` now passes the `max_iter` to the
+  underlying `LassoLars` when `algorithm='lasso_lars'`. :issue:`12650` by
+  `Adrin Jalali`_.
+
+- |Enhancement| :func:`decomposition.dict_learning()` and
+  :func:`decomposition.dict_learning_online()` now accept `method_max_iter` and
+  pass it to `sparse_encode`. :issue:`12650` by `Adrin Jalali`_.
+
+- |Enhancement| :class:`decomposition.SparseCoder`,
+  :class:`decomposition.DictionaryLearning`, and
+  :class:`decomposition.MiniBatchDictionaryLearning` now take a
+  `transform_max_iter` parameter and pass it to either
+  :func:`decomposition.dict_learning()` or
+  :func:`decomposition.sparse_encode()`. :issue:`12650` by `Adrin Jalali`_.
+
 Changes to estimator checks
 ---------------------------
 
diff --git a/sklearn/decomposition/dict_learning.py b/sklearn/decomposition/dict_learning.py
index a5ea12838838a..ab9722f43821d 100644
--- a/sklearn/decomposition/dict_learning.py
+++ b/sklearn/decomposition/dict_learning.py
@@ -499,7 +499,7 @@ def dict_learning(X, n_components, alpha, max_iter=100, tol=1e-8,
     method_max_iter : int, optional (default=1000)
         Maximum number of iterations to perform.
 
-        .. versionadded:: 0.21
+        .. versionadded:: 0.22
 
     Returns
     -------
@@ -716,7 +716,7 @@ def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,
     method_max_iter : int, optional (default=1000)
         Maximum number of iterations to perform when solving the lasso problem.
 
-        .. versionadded:: 0.21
+        .. versionadded:: 0.22
 
     Returns
     -------
@@ -986,7 +986,7 @@ class SparseCoder(BaseEstimator, SparseCodingMixin):
         Maximum number of iterations to perform if `algorithm='lasso_cd'` or
         `lasso_lars`.
 
-        .. versionadded:: 0.21
+        .. versionadded:: 0.22
 
     Attributes
     ----------
@@ -1141,7 +1141,7 @@ class DictionaryLearning(BaseEstimator, SparseCodingMixin):
         Maximum number of iterations to perform if `algorithm='lasso_cd'` or
         `lasso_lars`.
 
-        .. versionadded:: 0.21
+        .. versionadded:: 0.22
 
     Attributes
     ----------
@@ -1331,7 +1331,7 @@ class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):
         Maximum number of iterations to perform if `algorithm='lasso_cd'` or
         `lasso_lars`.
 
-        .. versionadded:: 0.21
+        .. versionadded:: 0.22
 
     Attributes
     ----------

From 2bb0ea8a60848afbbaaf8207ff3464f8e294f114 Mon Sep 17 00:00:00 2001
From: adrinjalali <adrin.jalali@gmail.com>
Date: Thu, 27 Jun 2019 11:18:25 +0200
Subject: [PATCH 18/18] remove extra line

---
 doc/whats_new/v0.22.rst | 1 -
 1 file changed, 1 deletion(-)

diff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst
index 9841500d526a1..390ad6b40cfc6 100644
--- a/doc/whats_new/v0.22.rst
+++ b/doc/whats_new/v0.22.rst
@@ -151,7 +151,6 @@ Miscellaneous
 - |Fix| Port `lobpcg` from SciPy which implement some bug fixes but only
   available in 1.3+.
   :pr:`14195` by :user:`Guillaume Lemaitre <glemaitre>`.
->>>>>>> upstream/master
 
 Changes to estimator checks
 ---------------------------
