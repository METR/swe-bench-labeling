{"instance_id": "scikit-learn__scikit-learn-14710", "score": "C", "diff": "diff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex ad6a5a8ca..3170e4000 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -426,11 +426,15 @@ class BaseHistGradientBoosting(BaseEstimator, ABC):\n \n         Scores are computed on validation data or on training data.\n         \"\"\"\n+        if hasattr(self, 'classes_'):\n+            y_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n \n         if self._use_validation_data:\n+            if hasattr(self, 'classes_'):\n+                y_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\n             )\n", "gold_standard_diff": "From a0f6fa6267a0e7feee1ed21c77a9a41cbb79bca5 Mon Sep 17 00:00:00 2001\nFrom: Guillaume Lemaitre <g.lemaitre58@gmail.com>\nDate: Wed, 21 Aug 2019 18:28:57 +0200\nSubject: [PATCH 1/3] FIX encode target for scoring when using early stopping\n in HistGradientBoostingClassifier\n\n---\n doc/whats_new/v0.22.rst                                  | 3 +++\n .../_hist_gradient_boosting/gradient_boosting.py         | 5 ++++-\n .../tests/test_gradient_boosting.py                      | 9 +++++++++\n 3 files changed, 16 insertions(+), 1 deletion(-)\n\ndiff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst\nindex e1aa1cd8641f5..e6185949ffd87 100644\n--- a/doc/whats_new/v0.22.rst\n+++ b/doc/whats_new/v0.22.rst\n@@ -132,6 +132,9 @@ Changelog\n     method for both estimators. :pr:`13769` by `Nicolas Hug`_.\n   - |Fix| Estimators now bin the training and validation data separately to\n     avoid any data leak. :pr:`13933` by `Nicolas Hug`_.\n+  - |Fix| Targets are encoded before to compute score when using early stopping\n+    to avoid inconsistent target data types.\n+    :pr:`14710` by :user:`Guillaume Lemaitre <glemaitre>`.\n \n   Note that pickles from 0.21 will not work in 0.22.\n \ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex ad6a5a8ca381b..3f7d20a1e919f 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -248,7 +248,6 @@ def fit(self, X, y):\n                     (X_binned_small_train,\n                      y_small_train) = self._get_small_trainset(\n                         X_binned_train, y_train, self._small_trainset_seed)\n-\n                     self._check_early_stopping_scorer(\n                         X_binned_small_train, y_small_train,\n                         X_binned_val, y_val,\n@@ -426,11 +425,15 @@ def _check_early_stopping_scorer(self, X_binned_small_train, y_small_train,\n \n         Scores are computed on validation data or on training data.\n         \"\"\"\n+        if hasattr(self, 'classes_'):\n+            y_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n \n         if self._use_validation_data:\n+            if hasattr(self, 'classes_'):\n+                y_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\n             )\ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\nindex 1eebdefd5288d..86dcb582a23a0 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n@@ -415,3 +415,12 @@ def test_infinite_values_missing_values():\n \n     assert stump_clf.fit(X, y_isinf).score(X, y_isinf) == 1\n     assert stump_clf.fit(X, y_isnan).score(X, y_isnan) == 1\n+\n+\n+def test_string_target_early_stopping():\n+    # Regression tests for #14709 where the targets need to be encoded before\n+    # to compute the score\n+    X = np.random.randn(100, 10)\n+    y = np.array(['x'] * 50 + ['y'] * 50, dtype=object)\n+    gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)\n+    gbrt.fit(X, y)\n\nFrom f49864daa58e020aeabd5380c34440f5f74e8402 Mon Sep 17 00:00:00 2001\nFrom: Guillaume Lemaitre <g.lemaitre58@gmail.com>\nDate: Wed, 21 Aug 2019 18:30:56 +0200\nSubject: [PATCH 2/3] add line\n\n---\n sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex 3f7d20a1e919f..3170e4000ecc5 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -248,6 +248,7 @@ def fit(self, X, y):\n                     (X_binned_small_train,\n                      y_small_train) = self._get_small_trainset(\n                         X_binned_train, y_train, self._small_trainset_seed)\n+\n                     self._check_early_stopping_scorer(\n                         X_binned_small_train, y_small_train,\n                         X_binned_val, y_val,\n\nFrom 1e5a5cf9f4434abeea32535322ee01f7fc820add Mon Sep 17 00:00:00 2001\nFrom: Guillaume Lemaitre <g.lemaitre58@gmail.com>\nDate: Thu, 22 Aug 2019 10:25:28 +0200\nSubject: [PATCH 3/3] reviews\n\n---\n doc/whats_new/v0.22.rst                                   | 3 +--\n .../ensemble/_hist_gradient_boosting/gradient_boosting.py | 4 ++--\n .../tests/test_gradient_boosting.py                       | 8 +++++---\n 3 files changed, 8 insertions(+), 7 deletions(-)\n\ndiff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst\nindex e6185949ffd87..770b48b0cb69a 100644\n--- a/doc/whats_new/v0.22.rst\n+++ b/doc/whats_new/v0.22.rst\n@@ -132,8 +132,7 @@ Changelog\n     method for both estimators. :pr:`13769` by `Nicolas Hug`_.\n   - |Fix| Estimators now bin the training and validation data separately to\n     avoid any data leak. :pr:`13933` by `Nicolas Hug`_.\n-  - |Fix| Targets are encoded before to compute score when using early stopping\n-    to avoid inconsistent target data types.\n+  - |Fix| Fixed a bug where early stopping would break with string targets.\n     :pr:`14710` by :user:`Guillaume Lemaitre <glemaitre>`.\n \n   Note that pickles from 0.21 will not work in 0.22.\ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex 3170e4000ecc5..70a507d09c1c6 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -426,14 +426,14 @@ def _check_early_stopping_scorer(self, X_binned_small_train, y_small_train,\n \n         Scores are computed on validation data or on training data.\n         \"\"\"\n-        if hasattr(self, 'classes_'):\n+        if is_classifier(self):\n             y_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n \n         if self._use_validation_data:\n-            if hasattr(self, 'classes_'):\n+            if is_classifier(self):\n                 y_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\nindex 86dcb582a23a0..5de49ef740295 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n@@ -417,10 +417,12 @@ def test_infinite_values_missing_values():\n     assert stump_clf.fit(X, y_isnan).score(X, y_isnan) == 1\n \n \n-def test_string_target_early_stopping():\n+@pytest.mark.parametrize(\"scoring\", [None, 'loss'])\n+def test_string_target_early_stopping(scoring):\n     # Regression tests for #14709 where the targets need to be encoded before\n     # to compute the score\n-    X = np.random.randn(100, 10)\n+    rng = np.random.RandomState(42)\n+    X = rng.randn(100, 10)\n     y = np.array(['x'] * 50 + ['y'] * 50, dtype=object)\n-    gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)\n+    gbrt = HistGradientBoostingClassifier(n_iter_no_change=10, scoring=scoring)\n     gbrt.fit(X, y)\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/14710"}