{"instance_id": "scikit-learn__scikit-learn-11578", "score": "C", "diff": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex e4ea696ce..0e3dd63ae 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,13 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(penalty=penalty, dual=dual, tol=tol, C=1.,\n+                                 fit_intercept=fit_intercept,\n+                                 intercept_scaling=intercept_scaling,\n+                                 class_weight=class_weight,\n+                                 random_state=random_state, solver=solver,\n+                                 max_iter=max_iter, multi_class=multi_class,\n+                                 verbose=verbose)\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\ndiff --git a/test_comprehensive.py b/test_comprehensive.py\nnew file mode 100644\nindex 000000000..8879f48b3\n--- /dev/null\n+++ b/test_comprehensive.py\n@@ -0,0 +1,117 @@\n+import numpy as np\n+from sklearn import preprocessing, linear_model, utils\n+from sklearn.model_selection import train_test_split\n+from sklearn.metrics import log_loss\n+\n+def test_log_reg_scoring_path_multinomial():\n+    \"\"\"Test that _log_reg_scoring_path respects multi_class parameter\"\"\"\n+    np.random.seed(42)\n+    \n+    # Generate multi-class data\n+    n_samples, n_features = 200, 5\n+    n_classes = 3\n+    X = np.random.randn(n_samples, n_features)\n+    y = np.random.choice(n_classes, size=n_samples)\n+    \n+    # Split data\n+    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n+    train_idx = np.arange(len(X_train))\n+    test_idx = np.arange(len(X_train), len(X_train) + len(X_test))\n+    \n+    # Concatenate back for the function\n+    X_full = np.vstack([X_train, X_test])\n+    y_full = np.hstack([y_train, y_test])\n+    \n+    # Test with multi_class='multinomial'\n+    coefs, Cs, scores, n_iter = linear_model.logistic._log_reg_scoring_path(\n+        X_full, y_full, train_idx, test_idx, \n+        scoring='neg_log_loss', \n+        multi_class='multinomial',\n+        solver='lbfgs',\n+        fit_intercept=True\n+    )\n+    \n+    # Manually calculate what the score should be\n+    # Use the first C value\n+    coef = coefs[0]\n+    \n+    # Create a LogisticRegression instance with multinomial\n+    lr = linear_model.LogisticRegression(\n+        multi_class='multinomial', \n+        solver='lbfgs',\n+        fit_intercept=True\n+    )\n+    lr.classes_ = np.unique(y_train)\n+    lr.coef_ = coef[:, :-1]\n+    lr.intercept_ = coef[:, -1]\n+    \n+    # Get probabilities using the multinomial approach\n+    y_pred_proba = lr.predict_proba(X_test)\n+    expected_score = -log_loss(y_test, y_pred_proba)\n+    \n+    actual_score = scores[0]\n+    \n+    print(f\"Expected score (multinomial): {expected_score}\")\n+    print(f\"Actual score from _log_reg_scoring_path: {actual_score}\")\n+    print(f\"Difference: {abs(expected_score - actual_score)}\")\n+    print(f\"Scores match: {np.allclose(expected_score, actual_score)}\")\n+    \n+    # Also test with multi_class='ovr' to show the difference\n+    coefs_ovr, Cs_ovr, scores_ovr, n_iter_ovr = linear_model.logistic._log_reg_scoring_path(\n+        X_full, y_full, train_idx, test_idx, \n+        scoring='neg_log_loss', \n+        multi_class='ovr',\n+        solver='lbfgs',\n+        fit_intercept=True\n+    )\n+    \n+    print(f\"\\nOvR score: {scores_ovr[0]}\")\n+    print(f\"Multinomial score: {scores[0]}\")\n+    print(f\"OvR and multinomial give different scores: {not np.allclose(scores[0], scores_ovr[0])}\")\n+\n+def test_other_parameters_passed():\n+    \"\"\"Test that other parameters are correctly passed to LogisticRegression\"\"\"\n+    np.random.seed(42)\n+    \n+    # Generate binary data\n+    n_samples, n_features = 100, 3\n+    X = np.random.randn(n_samples, n_features)\n+    y = np.random.choice([0, 1], size=n_samples)\n+    \n+    # Split data\n+    train_idx = np.arange(80)\n+    test_idx = np.arange(80, 100)\n+    \n+    # Test with various parameters\n+    params = {\n+        'penalty': 'l2',\n+        'dual': False,\n+        'tol': 1e-3,\n+        'solver': 'lbfgs',\n+        'max_iter': 50,\n+        'verbose': 0,\n+        'random_state': 42,\n+        'intercept_scaling': 2.0,\n+        'class_weight': {0: 1, 1: 2}\n+    }\n+    \n+    coefs, Cs, scores, n_iter = linear_model.logistic._log_reg_scoring_path(\n+        X, y, train_idx, test_idx, \n+        scoring=None,  # Use default accuracy scorer\n+        multi_class='ovr',\n+        fit_intercept=True,\n+        **params\n+    )\n+    \n+    print(\"\\nParameter passing test completed successfully!\")\n+    print(f\"Shape of coefficients: {coefs[0].shape}\")\n+    print(f\"Number of iterations: {n_iter[0]}\")\n+\n+if __name__ == \"__main__\":\n+    print(\"Testing multi_class parameter handling...\")\n+    test_log_reg_scoring_path_multinomial()\n+    \n+    print(\"\\n\" + \"=\"*60 + \"\\n\")\n+    \n+    print(\"Testing other parameters are passed correctly...\")\n+    test_other_parameters_passed()\ndiff --git a/test_fix.py b/test_fix.py\nnew file mode 100644\nindex 000000000..dbeeb468d\n--- /dev/null\n+++ b/test_fix.py\n@@ -0,0 +1,62 @@\n+import numpy as np\n+from sklearn import preprocessing, linear_model, utils\n+\n+def ovr_approach(decision_function):\n+    probs = 1. / (1. + np.exp(-decision_function))\n+    probs = probs / probs.sum(axis=1).reshape((probs.shape[0], -1))\n+    return probs\n+\n+def score_from_probs(probs, y_bin):\n+    return (y_bin*np.log(probs)).sum(axis=1).mean()\n+\n+np.random.seed(seed=1234)\n+\n+samples  = 200\n+features = 5\n+folds    = 10\n+\n+# Use a \"probabilistic\" scorer\n+scorer = 'neg_log_loss'\n+\n+x = np.random.random(size=(samples, features))\n+y = np.random.choice(['a', 'b', 'c'], size=samples)\n+\n+test  = np.random.choice(range(samples), size=int(samples/float(folds)), replace=False)\n+train = [idx for idx in range(samples) if idx not in test]\n+\n+# Binarize the labels for y[test]\n+lb = preprocessing.label.LabelBinarizer()\n+lb.fit(y[test])\n+y_bin = lb.transform(y[test])\n+\n+# What does _log_reg_scoring_path give us for the score?\n+coefs, _, scores, _ = linear_model.logistic._log_reg_scoring_path(x, y, train, test, fit_intercept=True, scoring=scorer, multi_class='multinomial')\n+\n+# Choose a single C to look at, for simplicity\n+c_index = 0\n+coefs = coefs[c_index]\n+scores = scores[c_index]\n+\n+# Initialise a LogisticRegression() instance with multi_class='multinomial'\n+log_reg = linear_model.LogisticRegression(fit_intercept=True, multi_class='multinomial')\n+log_reg.coef_      = coefs[:, :-1]\n+log_reg.intercept_ = coefs[:, -1]\n+log_reg.classes_ = np.unique(y[train])\n+\n+dec_fn = log_reg.decision_function(x[test])\n+probs_builtin = log_reg.predict_proba(x[test])\n+\n+# multinomial approach\n+probs_multi = utils.extmath.softmax(dec_fn)\n+\n+print('score returned by _log_reg_scoring_path')\n+print(scores)\n+\n+print('score calculated via multinomial method')\n+print(score_from_probs(probs_multi, y_bin))\n+\n+print('Difference between _log_reg_scoring_path score and multinomial score:')\n+print(abs(scores - score_from_probs(probs_multi, y_bin)))\n+\n+print('\\nAre the scores now equal (within floating point precision)?')\n+print(np.allclose(scores, score_from_probs(probs_multi, y_bin)))\ndiff --git a/test_issue.py b/test_issue.py\nnew file mode 100644\nindex 000000000..c45c14498\n--- /dev/null\n+++ b/test_issue.py\n@@ -0,0 +1,110 @@\n+import numpy as np\n+from sklearn import preprocessing, linear_model, utils\n+\n+def ovr_approach(decision_function):\n+    \n+    probs = 1. / (1. + np.exp(-decision_function))\n+    probs = probs / probs.sum(axis=1).reshape((probs.shape[0], -1))\n+    \n+    return probs\n+\n+def score_from_probs(probs, y_bin):\n+    \n+    return (y_bin*np.log(probs)).sum(axis=1).mean()\n+    \n+    \n+np.random.seed(seed=1234)\n+\n+samples  = 200\n+features = 5\n+folds    = 10\n+\n+# Use a \"probabilistic\" scorer\n+scorer = 'neg_log_loss'\n+\n+x = np.random.random(size=(samples, features))\n+y = np.random.choice(['a', 'b', 'c'], size=samples)\n+\n+test  = np.random.choice(range(samples), size=int(samples/float(folds)), replace=False)\n+train = [idx for idx in range(samples) if idx not in test]\n+\n+# Binarize the labels for y[test]\n+lb = preprocessing.label.LabelBinarizer()\n+lb.fit(y[test])\n+y_bin = lb.transform(y[test])\n+\n+# What does _log_reg_scoring_path give us for the score?\n+coefs, _, scores, _ = linear_model.logistic._log_reg_scoring_path(x, y, train, test, fit_intercept=True, scoring=scorer, multi_class='multinomial')\n+\n+# Choose a single C to look at, for simplicity\n+c_index = 0\n+coefs = coefs[c_index]\n+scores = scores[c_index]\n+\n+# Initialise a LogisticRegression() instance, as in \n+# https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/linear_model/logistic.py#L922\n+existing_log_reg = linear_model.LogisticRegression(fit_intercept=True)\n+existing_log_reg.coef_      = coefs[:, :-1]\n+existing_log_reg.intercept_ = coefs[:, -1]\n+\n+existing_dec_fn = existing_log_reg.decision_function(x[test])\n+\n+existing_probs_builtin = existing_log_reg.predict_proba(x[test])\n+\n+# OvR approach\n+existing_probs_ovr = ovr_approach(existing_dec_fn)\n+\n+# multinomial approach\n+existing_probs_multi = utils.extmath.softmax(existing_dec_fn)\n+\n+# If we initialise our LogisticRegression() instance, with multi_class='multinomial'\n+new_log_reg = linear_model.LogisticRegression(fit_intercept=True, multi_class='multinomial')\n+new_log_reg.coef_      = coefs[:, :-1]\n+new_log_reg.intercept_ = coefs[:, -1]\n+\n+new_dec_fn = new_log_reg.decision_function(x[test])\n+\n+new_probs_builtin = new_log_reg.predict_proba(x[test])\n+\n+# OvR approach\n+new_probs_ovr = ovr_approach(new_dec_fn)\n+\n+# multinomial approach\n+new_probs_multi = utils.extmath.softmax(new_dec_fn)\n+\n+print('score returned by _log_reg_scoring_path')\n+print(scores)\n+# -1.10566998\n+\n+print('OvR LR decision function == multinomial LR decision function?')\n+print((existing_dec_fn == new_dec_fn).all())\n+# True\n+\n+print('score calculated via OvR method (either decision function)')\n+print(score_from_probs(existing_probs_ovr, y_bin))\n+# -1.10566997908\n+\n+print('score calculated via multinomial method (either decision function)')\n+print(score_from_probs(existing_probs_multi, y_bin))\n+# -1.11426297223\n+\n+print('probs predicted by existing_log_reg.predict_proba() == probs generated via the OvR approach?')\n+print((existing_probs_builtin == existing_probs_ovr).all())\n+# True\n+\n+print('probs predicted by existing_log_reg.predict_proba() == probs generated via the multinomial approach?')\n+print((existing_probs_builtin == existing_probs_multi).any())\n+# False\n+\n+print('probs predicted by new_log_reg.predict_proba() == probs generated via the OvR approach?')\n+print((new_probs_builtin == new_probs_ovr).all())\n+# False\n+\n+print('probs predicted by new_log_reg.predict_proba() == probs generated via the multinomial approach?')\n+print((new_probs_builtin == new_probs_multi).any())\n+# True\n+\n+# So even though multi_class='multinomial' was specified in _log_reg_scoring_path(), \n+# the score it returned was the score calculated via OvR, not multinomial.\n+# We can see that log_reg.predict_proba() returns the OvR predicted probabilities,\n+# not the multinomial predicted probabilities.\ndiff --git a/test_neg_log_loss_multinomial.py b/test_neg_log_loss_multinomial.py\nnew file mode 100644\nindex 000000000..2a9d5aace\n--- /dev/null\n+++ b/test_neg_log_loss_multinomial.py\n@@ -0,0 +1,68 @@\n+import numpy as np\n+from sklearn.linear_model import LogisticRegressionCV\n+from sklearn.metrics import log_loss\n+from sklearn.model_selection import StratifiedKFold\n+\n+def test_logreg_cv_multinomial_scorer():\n+    \"\"\"Test that LogisticRegressionCV with scoring='neg_log_loss' and \n+    multi_class='multinomial' uses multinomial probabilities, not OvR\"\"\"\n+    \n+    # Generate multi-class data\n+    np.random.seed(42)\n+    n_samples, n_features, n_classes = 200, 5, 3\n+    X = np.random.randn(n_samples, n_features)\n+    y = np.random.choice(n_classes, size=n_samples)\n+    \n+    # Fit LogisticRegressionCV with multinomial\n+    lr_cv = LogisticRegressionCV(\n+        cv=3, \n+        multi_class='multinomial', \n+        solver='lbfgs',\n+        scoring='neg_log_loss',\n+        Cs=[1.0]  # Single C value for simplicity\n+    )\n+    lr_cv.fit(X, y)\n+    \n+    # Get the best score from CV\n+    cv_score = lr_cv.scores_[1].mean(axis=0)[0]  # class 1, mean over folds, first C\n+    \n+    # Manually compute what the score should be using multinomial\n+    # Use the same CV splits\n+    skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=None)\n+    manual_scores = []\n+    \n+    for train_idx, test_idx in skf.split(X, y):\n+        X_train, X_test = X[train_idx], X[test_idx]\n+        y_train, y_test = y[train_idx], y[test_idx]\n+        \n+        # Fit a regular LogisticRegression with same parameters\n+        from sklearn.linear_model import LogisticRegression\n+        lr = LogisticRegression(\n+            C=1.0,\n+            multi_class='multinomial',\n+            solver='lbfgs',\n+            random_state=None,\n+            max_iter=100\n+        )\n+        lr.fit(X_train, y_train)\n+        \n+        # Get multinomial probabilities\n+        y_pred_proba = lr.predict_proba(X_test)\n+        \n+        # Calculate neg_log_loss\n+        score = -log_loss(y_test, y_pred_proba)\n+        manual_scores.append(score)\n+    \n+    manual_score = np.mean(manual_scores)\n+    \n+    print(f\"CV score from LogisticRegressionCV: {cv_score}\")\n+    print(f\"Manual score using multinomial: {manual_score}\")\n+    print(f\"Difference: {abs(cv_score - manual_score)}\")\n+    \n+    # The scores should be close (allowing for some randomness in CV splits)\n+    assert abs(cv_score - manual_score) < 0.1, \\\n+        f\"LogisticRegressionCV score {cv_score} differs too much from expected {manual_score}\"\n+\n+if __name__ == \"__main__\":\n+    test_logreg_cv_multinomial_scorer()\n+    print(\"Test passed!\")\n", "gold_standard_diff": "From 748467f010249fe24b5178a7efeb2a39625b86ac Mon Sep 17 00:00:00 2001\nFrom: William de Vazelhes <william.de-vazelhes@inria.fr>\nDate: Tue, 17 Jul 2018 01:18:57 +0200\nSubject: [PATCH 1/4] FIX: fixes multinomial scoring for LogisticRegressionCV\n\n---\n sklearn/linear_model/logistic.py            |  2 +-\n sklearn/linear_model/tests/test_logistic.py | 34 ++++++++++++++++++++-\n 2 files changed, 34 insertions(+), 2 deletions(-)\n\ndiff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex e4ea696ce7146..a3afb06e449c4 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,7 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(multi_class=multi_class)\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\ndiff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex 56be87f71015a..53ab5a2aa277c 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -6,6 +6,7 @@\n \n from sklearn.datasets import load_iris, make_classification\n from sklearn.metrics import log_loss\n+from sklearn.metrics.scorer import get_scorer\n from sklearn.model_selection import StratifiedKFold\n from sklearn.preprocessing import LabelEncoder\n from sklearn.utils import compute_class_weight\n@@ -29,7 +30,7 @@\n     logistic_regression_path, LogisticRegressionCV,\n     _logistic_loss_and_grad, _logistic_grad_hess,\n     _multinomial_grad_hess, _logistic_loss,\n-)\n+    _log_reg_scoring_path)\n \n X = [[-1, 0], [0, 1], [1, 1]]\n X_sp = sp.csr_matrix(X)\n@@ -492,6 +493,37 @@ def test_logistic_cv():\n     assert_array_equal(scores.shape, (1, 3, 1))\n \n \n+@pytest.mark.parametrize('scoring', ['accuracy', 'f1', 'neg_log_loss',\n+                                     'precision', 'recall'])\n+def test_logistic_cv_multinomial_score(scoring):\n+    # test that LogisticRegressionCV uses the right score to compute its\n+    # cross-validation scores when using a multinomial scoring\n+    # see https://github.com/scikit-learn/scikit-learn/issues/8720\n+    X, y = make_classification(n_samples=100, random_state=0, n_classes=3,\n+                               n_informative=6)\n+    train, test = np.arange(80), np.arange(80, 100)\n+    lr = LogisticRegression(C=1., solver='lbfgs', multi_class='multinomial')\n+    # we use lbfgs to support multinomial\n+    params = lr.get_params()\n+    # we store the params to set them further in _log_reg_scoring_path\n+    for key in ['C', 'n_jobs', 'warm_start']:\n+        del(params[key])\n+    lr.fit(X[train], y[train])\n+    if scoring in ['f1', 'precision', 'recall']:\n+        for averaging in ['micro', 'macro', 'weighted']:\n+            scorer = get_scorer('{0}_{1}'.format(scoring, averaging))\n+            np.testing.assert_array_almost_equal(\n+                _log_reg_scoring_path(X, y, train, test, Cs=[1.], **params,\n+                                      scoring=scorer)[2][0],\n+                scorer(lr, X[test], y[test]))\n+    else:\n+        scorer = get_scorer(scoring)\n+        np.testing.assert_array_almost_equal(\n+            _log_reg_scoring_path(X, y, train, test, Cs=[1.], **params,\n+                                  scoring=scorer)[2][0],\n+            scorer(lr, X[test], y[test]))\n+\n+\n def test_multinomial_logistic_regression_string_inputs():\n     # Test with string labels for LogisticRegression(CV)\n     n_samples, n_features, n_classes = 50, 5, 3\n\nFrom e8a3180aed182fc9d47eb4494322b4e22111ad1d Mon Sep 17 00:00:00 2001\nFrom: William de Vazelhes <william.de-vazelhes@inria.fr>\nDate: Tue, 17 Jul 2018 16:21:14 +0200\nSubject: [PATCH 2/4] MAINT: changes according to review\n https://github.com/scikit-learn/scikit-learn/pull/11578#pullrequestreview-137785752\n\n---\n sklearn/linear_model/tests/test_logistic.py | 12 ++++++------\n 1 file changed, 6 insertions(+), 6 deletions(-)\n\ndiff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex 53ab5a2aa277c..c74cfd753d4af 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -512,15 +512,15 @@ def test_logistic_cv_multinomial_score(scoring):\n     if scoring in ['f1', 'precision', 'recall']:\n         for averaging in ['micro', 'macro', 'weighted']:\n             scorer = get_scorer('{0}_{1}'.format(scoring, averaging))\n-            np.testing.assert_array_almost_equal(\n-                _log_reg_scoring_path(X, y, train, test, Cs=[1.], **params,\n-                                      scoring=scorer)[2][0],\n+            assert_array_almost_equal(\n+                _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n+                                      scoring=scorer, **params)[2][0],\n                 scorer(lr, X[test], y[test]))\n     else:\n         scorer = get_scorer(scoring)\n-        np.testing.assert_array_almost_equal(\n-            _log_reg_scoring_path(X, y, train, test, Cs=[1.], **params,\n-                                  scoring=scorer)[2][0],\n+        assert_array_almost_equal(\n+            _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n+                                  scoring=scorer, **params)[2][0],\n             scorer(lr, X[test], y[test]))\n \n \n\nFrom 364f6a19b072f7a9467e48ec0192e80f9867dfa6 Mon Sep 17 00:00:00 2001\nFrom: William de Vazelhes <william.de-vazelhes@inria.fr>\nDate: Tue, 17 Jul 2018 16:37:21 +0200\nSubject: [PATCH 3/4] MAINT Add what s new entry\n\n---\n doc/whats_new/v0.20.rst | 6 ++++++\n 1 file changed, 6 insertions(+)\n\ndiff --git a/doc/whats_new/v0.20.rst b/doc/whats_new/v0.20.rst\nindex 0df0635d57c75..24f5219d83211 100644\n--- a/doc/whats_new/v0.20.rst\n+++ b/doc/whats_new/v0.20.rst\n@@ -71,6 +71,7 @@ random sampling procedures.\n - :class:`linear_model.PassiveAggressiveRegressor` (bug fix)\n - :class:`linear_model.Perceptron` (bug fix)\n - :class:`ensemble.gradient_boosting.GradientBoostingClassifier` (bug fix affecting feature importances)\n+- :class:`linear_model.LogisticRegressionCV` (bug fix)\n - The v0.19.0 release notes failed to mention a backwards incompatibility with\n   :class:`model_selection.StratifiedKFold` when ``shuffle=True`` due to\n   :issue:`7823`.\n@@ -442,6 +443,11 @@ Classifiers and regressors\n   the ``scoring`` parameter.\n   :issue:`10998` by :user:`Thomas Fan <thomasjpfan>`.\n \n+- Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the 'ovr'\n+  strategy was always used to compute cross-validation scores in the\n+  multiclass setting, even if 'multinomial' was set.\n+  :issue:`8720` by :user:`William de Vazelhes <wdevazelhes>`.\n+\n - Fixed a bug in :class:`linear_model.OrthogonalMatchingPursuit` that was\n   broken when setting ``normalize=False``.\n   :issue:`10071` by `Alexandre Gramfort`_.\n\nFrom 8ac2c65b6afb3d0cf8ac4f574339f7f2215ec20c Mon Sep 17 00:00:00 2001\nFrom: William de Vazelhes <william.de-vazelhes@inria.fr>\nDate: Wed, 18 Jul 2018 08:01:47 +0200\nSubject: [PATCH 4/4] MAINT: Adress comments from review\n https://github.com/scikit-learn/scikit-learn/pull/11578#pullrequestreview-138098118\n\n---\n sklearn/linear_model/tests/test_logistic.py | 28 +++++++++++----------\n 1 file changed, 15 insertions(+), 13 deletions(-)\n\ndiff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex c74cfd753d4af..343d8211b1ef4 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -493,9 +493,18 @@ def test_logistic_cv():\n     assert_array_equal(scores.shape, (1, 3, 1))\n \n \n-@pytest.mark.parametrize('scoring', ['accuracy', 'f1', 'neg_log_loss',\n-                                     'precision', 'recall'])\n-def test_logistic_cv_multinomial_score(scoring):\n+@pytest.mark.parametrize('scoring, multiclass_agg_list',\n+                         [('accuracy', ['']),\n+                          ('precision', ['_macro', '_weighted']),\n+                          # no need to test for micro averaging because it\n+                          # is the same as accuracy for f1, precision,\n+                          # and recall (see https://github.com/\n+                          # scikit-learn/scikit-learn/pull/\n+                          # 11578#discussion_r203250062)\n+                          ('f1', ['_macro', '_weighted']),\n+                          ('neg_log_loss', ['']),\n+                          ('recall', ['_macro', '_weighted'])])\n+def test_logistic_cv_multinomial_score(scoring, multiclass_agg_list):\n     # test that LogisticRegressionCV uses the right score to compute its\n     # cross-validation scores when using a multinomial scoring\n     # see https://github.com/scikit-learn/scikit-learn/issues/8720\n@@ -507,17 +516,10 @@ def test_logistic_cv_multinomial_score(scoring):\n     params = lr.get_params()\n     # we store the params to set them further in _log_reg_scoring_path\n     for key in ['C', 'n_jobs', 'warm_start']:\n-        del(params[key])\n+        del params[key]\n     lr.fit(X[train], y[train])\n-    if scoring in ['f1', 'precision', 'recall']:\n-        for averaging in ['micro', 'macro', 'weighted']:\n-            scorer = get_scorer('{0}_{1}'.format(scoring, averaging))\n-            assert_array_almost_equal(\n-                _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n-                                      scoring=scorer, **params)[2][0],\n-                scorer(lr, X[test], y[test]))\n-    else:\n-        scorer = get_scorer(scoring)\n+    for averaging in multiclass_agg_list:\n+        scorer = get_scorer(scoring + averaging)\n         assert_array_almost_equal(\n             _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n                                   scoring=scorer, **params)[2][0],\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/11578"}