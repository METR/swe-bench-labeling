{"instance_id": "scikit-learn__scikit-learn-15100", "score": "I", "diff": "", "gold_standard_diff": "From bb9e237a8dc6a469e7becc3af0b5ab1efd2d5be6 Mon Sep 17 00:00:00 2001\nFrom: Daniel Grady <d.grady@paritycomputing.com>\nDate: Thu, 26 Sep 2019 12:13:04 -0700\nSubject: [PATCH] Fix a bug in strip_accents_unicode; #15087\n\nstrip_accents_unicode contained a check to see if applying NFKD\nnormalization to the input string changed it. If the string was\nunchanged, then it would not attempt to remove accents. This meant\nthat if an input string was already in NFKD form and also contained\naccents, the accents were not removed.\n\nNow, strip_accents_unicode always filters out combining characters\nafter applying NFKD normalization.\n---\n doc/whats_new/v0.22.rst                       |  4 ++++\n sklearn/feature_extraction/tests/test_text.py | 15 +++++++++++++++\n sklearn/feature_extraction/text.py            |  9 ++++++---\n 3 files changed, 25 insertions(+), 3 deletions(-)\n\ndiff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst\nindex 24056ad94486a..088d418f184f8 100644\n--- a/doc/whats_new/v0.22.rst\n+++ b/doc/whats_new/v0.22.rst\n@@ -255,6 +255,10 @@ Changelog\n   removed in v0.24. :pr:`14520` by\n   :user:`Guillem G. Subies <guillemgsubies>`.\n \n+- |Fix| :func:`feature_extraction.text.strip_accents_unicode` now correctly\n+  removes accents from strings that are in NFKD normalized form. :pr:`15100` by\n+  :user:`Daniel Grady <DGrady>`.\n+\n :mod:`sklearn.feature_selection`\n ................................\n \ndiff --git a/sklearn/feature_extraction/tests/test_text.py b/sklearn/feature_extraction/tests/test_text.py\nindex 7b7697ff47fff..6ea91f90653b0 100644\n--- a/sklearn/feature_extraction/tests/test_text.py\n+++ b/sklearn/feature_extraction/tests/test_text.py\n@@ -97,6 +97,21 @@ def test_strip_accents():\n     expected = 'this is a test'\n     assert strip_accents_unicode(a) == expected\n \n+    # strings that are already decomposed\n+    a = \"o\\u0308\"  # o with diaresis\n+    expected = \"o\"\n+    assert strip_accents_unicode(a) == expected\n+\n+    # combining marks by themselves\n+    a = \"\\u0300\\u0301\\u0302\\u0303\"\n+    expected = \"\"\n+    assert strip_accents_unicode(a) == expected\n+\n+    # Multiple combining marks on one character\n+    a = \"o\\u0308\\u0304\"\n+    expected = \"o\"\n+    assert strip_accents_unicode(a) == expected\n+\n \n def test_to_ascii():\n     # check some classical latin accentuated symbols\ndiff --git a/sklearn/feature_extraction/text.py b/sklearn/feature_extraction/text.py\nindex bb5a9d646789c..d73bd94d74e0f 100644\n--- a/sklearn/feature_extraction/text.py\n+++ b/sklearn/feature_extraction/text.py\n@@ -129,10 +129,13 @@ def strip_accents_unicode(s):\n         Remove accentuated char for any unicode symbol that has a direct\n         ASCII equivalent.\n     \"\"\"\n-    normalized = unicodedata.normalize('NFKD', s)\n-    if normalized == s:\n+    try:\n+        # If `s` is ASCII-compatible, then it does not contain any accented\n+        # characters and we can avoid an expensive list comprehension\n+        s.encode(\"ASCII\", errors=\"strict\")\n         return s\n-    else:\n+    except UnicodeEncodeError:\n+        normalized = unicodedata.normalize('NFKD', s)\n         return ''.join([c for c in normalized if not unicodedata.combining(c)])\n \n \n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/15100"}