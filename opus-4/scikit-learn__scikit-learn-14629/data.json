{"instance_id": "scikit-learn__scikit-learn-14629", "score": "C", "diff": "diff --git a/final_test.py b/final_test.py\nnew file mode 100644\nindex 000000000..8b1378917\n--- /dev/null\n+++ b/final_test.py\n@@ -0,0 +1 @@\n+\ndiff --git a/reproduce_issue.py b/reproduce_issue.py\nnew file mode 100644\nindex 000000000..09e34336d\n--- /dev/null\n+++ b/reproduce_issue.py\n@@ -0,0 +1,16 @@\n+from sklearn.datasets import make_multilabel_classification\n+from sklearn.multioutput import MultiOutputClassifier\n+from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n+from sklearn.model_selection import cross_val_predict\n+\n+X, Y = make_multilabel_classification()\n+\n+mo_lda = MultiOutputClassifier(LinearDiscriminantAnalysis())\n+pred = cross_val_predict(mo_lda, X, Y, cv=5) # Works fine\n+print(\"Regular prediction works fine\")\n+\n+try:\n+    pred_proba = cross_val_predict(mo_lda, X, Y, cv=5, method='predict_proba') # Returns error\n+    print(\"predict_proba works!\")\n+except AttributeError as e:\n+    print(f\"Error encountered: {e}\")\ndiff --git a/sklearn/multioutput.py b/sklearn/multioutput.py\nindex 463b72d40..c798ae448 100644\n--- a/sklearn/multioutput.py\n+++ b/sklearn/multioutput.py\n@@ -320,11 +320,80 @@ class MultiOutputClassifier(MultiOutputEstimator, ClassifierMixin):\n     ----------\n     estimators_ : list of ``n_output`` estimators\n         Estimators used for predictions.\n+    \n+    classes_ : list of arrays\n+        A list of arrays of class labels, one for each output in the\n+        multi-output classification problem. The i-th element of the list\n+        is the array of class labels for the i-th output.\n     \"\"\"\n \n     def __init__(self, estimator, n_jobs=None):\n         super().__init__(estimator, n_jobs)\n \n+    def fit(self, X, y, sample_weight=None):\n+        \"\"\"Fit the model to data.\n+        \n+        Fit a separate model for each output variable.\n+\n+        Parameters\n+        ----------\n+        X : (sparse) array-like, shape (n_samples, n_features)\n+            Data.\n+\n+        y : (sparse) array-like, shape (n_samples, n_outputs)\n+            Multi-output targets. An indicator matrix turns on multilabel\n+            estimation.\n+\n+        sample_weight : array-like, shape = (n_samples) or None\n+            Sample weights. If None, then samples are equally weighted.\n+            Only supported if the underlying classifier supports sample\n+            weights.\n+\n+        Returns\n+        -------\n+        self : object\n+        \"\"\"\n+        super().fit(X, y, sample_weight)\n+        self.classes_ = [estimator.classes_ for estimator in self.estimators_]\n+        return self\n+\n+    @if_delegate_has_method('estimator')\n+    def partial_fit(self, X, y, classes=None, sample_weight=None):\n+        \"\"\"Incrementally fit the model to data.\n+        \n+        Fit a separate model for each output variable.\n+\n+        Parameters\n+        ----------\n+        X : (sparse) array-like, shape (n_samples, n_features)\n+            Data.\n+\n+        y : (sparse) array-like, shape (n_samples, n_outputs)\n+            Multi-output targets.\n+\n+        classes : list of numpy arrays, shape (n_outputs)\n+            Each array is unique classes for one output in str/int\n+            Can be obtained by via\n+            ``[np.unique(y[:, i]) for i in range(y.shape[1])]``, where y is the\n+            target matrix of the entire dataset.\n+            This argument is required for the first call to partial_fit\n+            and can be omitted in the subsequent calls.\n+            Note that y doesn't need to contain all labels in `classes`.\n+\n+        sample_weight : array-like, shape = (n_samples) or None\n+            Sample weights. If None, then samples are equally weighted.\n+            Only supported if the underlying classifier supports sample\n+            weights.\n+\n+        Returns\n+        -------\n+        self : object\n+        \"\"\"\n+        super().partial_fit(X, y, classes, sample_weight)\n+        if hasattr(self, 'estimators_'):\n+            self.classes_ = [estimator.classes_ for estimator in self.estimators_]\n+        return self\n+\n     def predict_proba(self, X):\n         \"\"\"Probability estimates.\n         Returns prediction probabilities for each class of each output.\ndiff --git a/sklearn/tests/test_multioutput.py b/sklearn/tests/test_multioutput.py\nindex e70048a7f..37a715517 100644\n--- a/sklearn/tests/test_multioutput.py\n+++ b/sklearn/tests/test_multioutput.py\n@@ -527,3 +527,65 @@ def test_base_chain_crossval_fit_and_predict():\n             assert jaccard_score(Y, Y_pred_cv, average='samples') > .4\n         else:\n             assert mean_squared_error(Y, Y_pred_cv) < .25\n+\n+\n+def test_multi_output_classifier_cross_val_predict_proba():\n+    \"\"\"Test that cross_val_predict works with predict_proba for MultiOutputClassifier.\"\"\"\n+    from sklearn.datasets import make_multilabel_classification\n+    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n+    from sklearn.tree import DecisionTreeClassifier\n+    from sklearn.model_selection import cross_val_predict\n+    \n+    # Generate sample data\n+    X, Y = make_multilabel_classification(n_samples=100, n_features=20, \n+                                          n_classes=3, n_labels=3, \n+                                          random_state=42)\n+    \n+    # Test with LinearDiscriminantAnalysis\n+    mo_lda = MultiOutputClassifier(LinearDiscriminantAnalysis())\n+    \n+    # Regular prediction should work\n+    pred = cross_val_predict(mo_lda, X, Y, cv=5)\n+    assert pred.shape == Y.shape\n+    \n+    # predict_proba should now work without AttributeError\n+    pred_proba = cross_val_predict(mo_lda, X, Y, cv=5, method='predict_proba')\n+    \n+    # Check output structure\n+    assert isinstance(pred_proba, list)\n+    assert len(pred_proba) == Y.shape[1]\n+    \n+    # Check each output's prediction shape\n+    for i, proba in enumerate(pred_proba):\n+        n_classes = len(np.unique(Y[:, i]))\n+        assert proba.shape == (X.shape[0], n_classes)\n+    \n+    # Test with DecisionTreeClassifier\n+    mo_dt = MultiOutputClassifier(DecisionTreeClassifier(random_state=42))\n+    pred_proba_dt = cross_val_predict(mo_dt, X, Y, cv=5, method='predict_proba')\n+    \n+    assert isinstance(pred_proba_dt, list)\n+    assert len(pred_proba_dt) == Y.shape[1]\n+\n+\n+def test_multi_output_classifier_classes_attribute():\n+    \"\"\"Test that MultiOutputClassifier has classes_ attribute after fitting.\"\"\"\n+    from sklearn.datasets import make_multilabel_classification\n+    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n+    \n+    X, Y = make_multilabel_classification(n_samples=100, n_features=20, \n+                                          n_classes=3, n_labels=3, \n+                                          random_state=42)\n+    \n+    mo_clf = MultiOutputClassifier(LinearDiscriminantAnalysis())\n+    mo_clf.fit(X, Y)\n+    \n+    # Check that classes_ attribute exists\n+    assert hasattr(mo_clf, 'classes_')\n+    assert isinstance(mo_clf.classes_, list)\n+    assert len(mo_clf.classes_) == Y.shape[1]\n+    \n+    # Check that each element is an array of classes\n+    for i, classes in enumerate(mo_clf.classes_):\n+        expected_classes = np.unique(Y[:, i])\n+        assert_array_equal(classes, expected_classes)\ndiff --git a/test_fix.py b/test_fix.py\nnew file mode 100644\nindex 000000000..06aebd3ef\n--- /dev/null\n+++ b/test_fix.py\n@@ -0,0 +1,59 @@\n+import numpy as np\n+from sklearn.datasets import make_multilabel_classification\n+from sklearn.multioutput import MultiOutputClassifier\n+from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n+from sklearn.model_selection import cross_val_predict\n+from sklearn.tree import DecisionTreeClassifier\n+\n+# Test 1: Basic functionality with LinearDiscriminantAnalysis\n+print(\"Test 1: Basic functionality with LinearDiscriminantAnalysis\")\n+X, Y = make_multilabel_classification(n_samples=100, n_features=20, n_classes=3, n_labels=3, random_state=42)\n+\n+mo_lda = MultiOutputClassifier(LinearDiscriminantAnalysis())\n+pred = cross_val_predict(mo_lda, X, Y, cv=5)\n+print(\"  Regular prediction: OK\")\n+\n+pred_proba = cross_val_predict(mo_lda, X, Y, cv=5, method='predict_proba')\n+print(\"  predict_proba: OK\")\n+print(\"  Shape of predictions:\", len(pred_proba), \"outputs, each with shape\", pred_proba[0].shape)\n+\n+# Test 2: Check that classes_ attribute is set correctly\n+print(\"\\nTest 2: Checking classes_ attribute\")\n+mo_lda_fitted = MultiOutputClassifier(LinearDiscriminantAnalysis())\n+mo_lda_fitted.fit(X, Y)\n+print(\"  Has classes_:\", hasattr(mo_lda_fitted, 'classes_'))\n+print(\"  Number of outputs:\", len(mo_lda_fitted.classes_))\n+for i, classes in enumerate(mo_lda_fitted.classes_):\n+    print(f\"  Output {i} classes: {classes}\")\n+\n+# Test 3: Test with DecisionTreeClassifier\n+print(\"\\nTest 3: Testing with DecisionTreeClassifier\")\n+mo_dt = MultiOutputClassifier(DecisionTreeClassifier(random_state=42))\n+pred = cross_val_predict(mo_dt, X, Y, cv=5)\n+print(\"  Regular prediction: OK\")\n+\n+pred_proba = cross_val_predict(mo_dt, X, Y, cv=5, method='predict_proba')\n+print(\"  predict_proba: OK\")\n+\n+# Test 4: Test with partial_fit (if supported)\n+print(\"\\nTest 4: Testing partial_fit\")\n+try:\n+    from sklearn.naive_bayes import MultinomialNB\n+    X_positive = np.abs(X)  # MultinomialNB requires non-negative features\n+    mo_nb = MultiOutputClassifier(MultinomialNB())\n+    \n+    # Get unique classes for each output\n+    classes_list = [np.unique(Y[:, i]) for i in range(Y.shape[1])]\n+    \n+    # Partial fit\n+    mo_nb.partial_fit(X_positive[:50], Y[:50], classes=classes_list)\n+    mo_nb.partial_fit(X_positive[50:], Y[50:])\n+    \n+    print(\"  partial_fit: OK\")\n+    print(\"  Has classes_ after partial_fit:\", hasattr(mo_nb, 'classes_'))\n+    if hasattr(mo_nb, 'classes_'):\n+        print(\"  Number of outputs:\", len(mo_nb.classes_))\n+except Exception as e:\n+    print(f\"  partial_fit test failed: {e}\")\n+\n+print(\"\\nAll tests completed successfully!\")\ndiff --git a/test_multioutput_cross_val_predict.py b/test_multioutput_cross_val_predict.py\nnew file mode 100644\nindex 000000000..1cfd3a926\n--- /dev/null\n+++ b/test_multioutput_cross_val_predict.py\n@@ -0,0 +1,68 @@\n+\"\"\"Test for MultiOutputClassifier cross_val_predict with predict_proba method.\"\"\"\n+\n+import numpy as np\n+from sklearn.datasets import make_multilabel_classification\n+from sklearn.multioutput import MultiOutputClassifier\n+from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n+from sklearn.tree import DecisionTreeClassifier\n+from sklearn.model_selection import cross_val_predict\n+\n+\n+def test_multi_output_classifier_cross_val_predict_proba():\n+    \"\"\"Test that cross_val_predict works with predict_proba for MultiOutputClassifier.\"\"\"\n+    # Generate sample data\n+    X, Y = make_multilabel_classification(n_samples=100, n_features=20, \n+                                          n_classes=3, n_labels=3, \n+                                          random_state=42)\n+    \n+    # Test with LinearDiscriminantAnalysis\n+    mo_lda = MultiOutputClassifier(LinearDiscriminantAnalysis())\n+    \n+    # Regular prediction should work\n+    pred = cross_val_predict(mo_lda, X, Y, cv=5)\n+    assert pred.shape == Y.shape\n+    \n+    # predict_proba should now work without AttributeError\n+    pred_proba = cross_val_predict(mo_lda, X, Y, cv=5, method='predict_proba')\n+    \n+    # Check output structure\n+    assert isinstance(pred_proba, list)\n+    assert len(pred_proba) == Y.shape[1]\n+    \n+    # Check each output's prediction shape\n+    for i, proba in enumerate(pred_proba):\n+        n_classes = len(np.unique(Y[:, i]))\n+        assert proba.shape == (X.shape[0], n_classes)\n+    \n+    # Test with DecisionTreeClassifier\n+    mo_dt = MultiOutputClassifier(DecisionTreeClassifier(random_state=42))\n+    pred_proba_dt = cross_val_predict(mo_dt, X, Y, cv=5, method='predict_proba')\n+    \n+    assert isinstance(pred_proba_dt, list)\n+    assert len(pred_proba_dt) == Y.shape[1]\n+\n+\n+def test_multi_output_classifier_classes_attribute():\n+    \"\"\"Test that MultiOutputClassifier has classes_ attribute after fitting.\"\"\"\n+    X, Y = make_multilabel_classification(n_samples=100, n_features=20, \n+                                          n_classes=3, n_labels=3, \n+                                          random_state=42)\n+    \n+    mo_clf = MultiOutputClassifier(LinearDiscriminantAnalysis())\n+    mo_clf.fit(X, Y)\n+    \n+    # Check that classes_ attribute exists\n+    assert hasattr(mo_clf, 'classes_')\n+    assert isinstance(mo_clf.classes_, list)\n+    assert len(mo_clf.classes_) == Y.shape[1]\n+    \n+    # Check that each element is an array of classes\n+    for i, classes in enumerate(mo_clf.classes_):\n+        expected_classes = np.unique(Y[:, i])\n+        np.testing.assert_array_equal(classes, expected_classes)\n+\n+\n+if __name__ == \"__main__\":\n+    test_multi_output_classifier_cross_val_predict_proba()\n+    test_multi_output_classifier_classes_attribute()\n+    print(\"All tests passed!\")\n", "gold_standard_diff": "diff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst\nindex fe19557df3cda..8476b6bd51228 100644\n--- a/doc/whats_new/v0.22.rst\n+++ b/doc/whats_new/v0.22.rst\n@@ -251,6 +251,12 @@ Changelog\n - |Enhancement| :class:`model_selection.RandomizedSearchCV` now accepts lists\n   of parameter distributions. :pr:`14549` by `Andreas M\u00fcller`_.\n \n+:mod:`sklearn.multioutput`\n+..........................\n+\n+- |Fix| :class:`multioutput.MultiOutputClassifier` now has attribute\n+  ``classes_``. :pr:`14629` by :user:`Agamemnon Krasoulis <agamemnonc>`.\n+\n :mod:`sklearn.pipeline`\n .......................\n \ndiff --git a/sklearn/multioutput.py b/sklearn/multioutput.py\nindex 463b72d40f47a..3b5a95349868e 100644\n--- a/sklearn/multioutput.py\n+++ b/sklearn/multioutput.py\n@@ -325,6 +325,28 @@ class MultiOutputClassifier(MultiOutputEstimator, ClassifierMixin):\n     def __init__(self, estimator, n_jobs=None):\n         super().__init__(estimator, n_jobs)\n \n+    def fit(self, X, Y, sample_weight=None):\n+        \"\"\"Fit the model to data matrix X and targets Y.\n+\n+        Parameters\n+        ----------\n+        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n+            The input data.\n+        Y : array-like of shape (n_samples, n_classes)\n+            The target values.\n+        sample_weight : array-like of shape (n_samples,) or None\n+            Sample weights. If None, then samples are equally weighted.\n+            Only supported if the underlying classifier supports sample\n+            weights.\n+\n+        Returns\n+        -------\n+        self : object\n+        \"\"\"\n+        super().fit(X, Y, sample_weight)\n+        self.classes_ = [estimator.classes_ for estimator in self.estimators_]\n+        return self\n+\n     def predict_proba(self, X):\n         \"\"\"Probability estimates.\n         Returns prediction probabilities for each class of each output.\n@@ -420,7 +442,7 @@ def fit(self, X, Y):\n             if self.order_ == 'random':\n                 self.order_ = random_state.permutation(Y.shape[1])\n         elif sorted(self.order_) != list(range(Y.shape[1])):\n-                raise ValueError(\"invalid order\")\n+            raise ValueError(\"invalid order\")\n \n         self.estimators_ = [clone(self.base_estimator)\n                             for _ in range(Y.shape[1])]\ndiff --git a/sklearn/tests/test_multioutput.py b/sklearn/tests/test_multioutput.py\nindex e70048a7fa257..e1d2433197b1c 100644\n--- a/sklearn/tests/test_multioutput.py\n+++ b/sklearn/tests/test_multioutput.py\n@@ -527,3 +527,20 @@ def test_base_chain_crossval_fit_and_predict():\n             assert jaccard_score(Y, Y_pred_cv, average='samples') > .4\n         else:\n             assert mean_squared_error(Y, Y_pred_cv) < .25\n+\n+\n+@pytest.mark.parametrize(\n+    'estimator',\n+    [RandomForestClassifier(n_estimators=2),\n+     MultiOutputClassifier(RandomForestClassifier(n_estimators=2)),\n+     ClassifierChain(RandomForestClassifier(n_estimators=2))]\n+)\n+def test_multi_output_classes_(estimator):\n+    # Tests classes_ attribute of multioutput classifiers\n+    # RandomForestClassifier supports multioutput out-of-the-box\n+    estimator.fit(X, y)\n+    assert isinstance(estimator.classes_, list)\n+    assert len(estimator.classes_) == n_outputs\n+    for estimator_classes, expected_classes in zip(classes,\n+                                                   estimator.classes_):\n+        assert_array_equal(estimator_classes, expected_classes)\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/14629"}