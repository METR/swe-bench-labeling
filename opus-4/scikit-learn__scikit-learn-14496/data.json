{"instance_id": "scikit-learn__scikit-learn-14496", "score": "C", "diff": "diff --git a/fix_optics.patch b/fix_optics.patch\nnew file mode 100644\nindex 000000000..dcbac1424\n--- /dev/null\n+++ b/fix_optics.patch\n@@ -0,0 +1,26 @@\n+--- a/sklearn/cluster/optics_.py\n++++ b/sklearn/cluster/optics_.py\n+@@ -437,7 +437,7 @@\n+     n_samples = X.shape[0]\n+     _validate_size(min_samples, n_samples, 'min_samples')\n+     if min_samples <= 1:\n+-        min_samples = max(2, min_samples * n_samples)\n++        min_samples = int(round(max(2, min_samples * n_samples)))\n+ \n+     # Start all points as 'unprocessed' ##\n+     reachability_ = np.empty(n_samples)\n+@@ -619,13 +619,13 @@\n+     n_samples = len(reachability)\n+     _validate_size(min_samples, n_samples, 'min_samples')\n+     if min_samples <= 1:\n+-        min_samples = max(2, min_samples * n_samples)\n++        min_samples = int(round(max(2, min_samples * n_samples)))\n+     if min_cluster_size is None:\n+         min_cluster_size = min_samples\n+     _validate_size(min_cluster_size, n_samples, 'min_cluster_size')\n+     if min_cluster_size <= 1:\n+-        min_cluster_size = max(2, min_cluster_size * n_samples)\n++        min_cluster_size = int(round(max(2, min_cluster_size * n_samples)))\n+ \n+     clusters = _xi_cluster(reachability[ordering], predecessor[ordering],\n+                            ordering, xi,\ndiff --git a/reproduce_exact_issue.py b/reproduce_exact_issue.py\nnew file mode 100644\nindex 000000000..5e10d01f9\n--- /dev/null\n+++ b/reproduce_exact_issue.py\n@@ -0,0 +1,15 @@\n+\"\"\"\n+Reproduce the exact issue as described in the bug report.\n+\"\"\"\n+import numpy as np\n+from sklearn.cluster import OPTICS\n+\n+# Create some test data (simulating load_some_data())\n+data = np.random.randn(100, 2)\n+\n+# This is the exact code from the issue that was failing\n+clust = OPTICS(metric='minkowski', n_jobs=-1, min_samples=0.1)\n+clust.fit(data)\n+\n+print(\"SUCCESS: The issue has been fixed!\")\n+print(\"OPTICS now accepts float min_samples without raising TypeError.\")\ndiff --git a/sklearn/cluster/optics_.py b/sklearn/cluster/optics_.py\nindex 4f7eb11ab..bd97d6357 100755\n--- a/sklearn/cluster/optics_.py\n+++ b/sklearn/cluster/optics_.py\n@@ -437,7 +437,7 @@ if metric=\u2019precomputed\u2019.\n     n_samples = X.shape[0]\n     _validate_size(min_samples, n_samples, 'min_samples')\n     if min_samples <= 1:\n-        min_samples = max(2, min_samples * n_samples)\n+        min_samples = int(round(max(2, min_samples * n_samples)))\n \n     # Start all points as 'unprocessed' ##\n     reachability_ = np.empty(n_samples)\n@@ -619,12 +619,12 @@ def cluster_optics_xi(reachability, predecessor, ordering, min_samples,\n     n_samples = len(reachability)\n     _validate_size(min_samples, n_samples, 'min_samples')\n     if min_samples <= 1:\n-        min_samples = max(2, min_samples * n_samples)\n+        min_samples = int(round(max(2, min_samples * n_samples)))\n     if min_cluster_size is None:\n         min_cluster_size = min_samples\n     _validate_size(min_cluster_size, n_samples, 'min_cluster_size')\n     if min_cluster_size <= 1:\n-        min_cluster_size = max(2, min_cluster_size * n_samples)\n+        min_cluster_size = int(round(max(2, min_cluster_size * n_samples)))\n \n     clusters = _xi_cluster(reachability[ordering], predecessor[ordering],\n                            ordering, xi,\ndiff --git a/sklearn/cluster/optics_.py.backup b/sklearn/cluster/optics_.py.backup\nnew file mode 100755\nindex 000000000..4f7eb11ab\n--- /dev/null\n+++ b/sklearn/cluster/optics_.py.backup\n@@ -0,0 +1,919 @@\n+# -*- coding: utf-8 -*-\n+\"\"\"Ordering Points To Identify the Clustering Structure (OPTICS)\n+\n+These routines execute the OPTICS algorithm, and implement various\n+cluster extraction methods of the ordered list.\n+\n+Authors: Shane Grigsby <refuge@rocktalus.com>\n+         Adrin Jalali <adrinjalali@gmail.com>\n+         Erich Schubert <erich@debian.org>\n+         Hanmin Qin <qinhanmin2005@sina.com>\n+License: BSD 3 clause\n+\"\"\"\n+\n+import warnings\n+import numpy as np\n+\n+from ..utils import check_array\n+from ..utils import gen_batches, get_chunk_n_rows\n+from ..neighbors import NearestNeighbors\n+from ..base import BaseEstimator, ClusterMixin\n+from ..metrics import pairwise_distances\n+\n+\n+class OPTICS(BaseEstimator, ClusterMixin):\n+    \"\"\"Estimate clustering structure from vector array\n+\n+    OPTICS (Ordering Points To Identify the Clustering Structure), closely\n+    related to DBSCAN, finds core sample of high density and expands clusters\n+    from them [1]_. Unlike DBSCAN, keeps cluster hierarchy for a variable\n+    neighborhood radius. Better suited for usage on large datasets than the\n+    current sklearn implementation of DBSCAN.\n+\n+    Clusters are then extracted using a DBSCAN-like method\n+    (cluster_method = 'dbscan') or an automatic\n+    technique proposed in [1]_ (cluster_method = 'xi').\n+\n+    This implementation deviates from the original OPTICS by first performing\n+    k-nearest-neighborhood searches on all points to identify core sizes, then\n+    computing only the distances to unprocessed points when constructing the\n+    cluster order. Note that we do not employ a heap to manage the expansion\n+    candidates, so the time complexity will be O(n^2).\n+\n+    Read more in the :ref:`User Guide <optics>`.\n+\n+    Parameters\n+    ----------\n+    min_samples : int > 1 or float between 0 and 1 (default=None)\n+        The number of samples in a neighborhood for a point to be considered as\n+        a core point. Also, up and down steep regions can't have more then\n+        ``min_samples`` consecutive non-steep points. Expressed as an absolute\n+        number or a fraction of the number of samples (rounded to be at least\n+        2).\n+\n+    max_eps : float, optional (default=np.inf)\n+        The maximum distance between two samples for one to be considered as\n+        in the neighborhood of the other. Default value of ``np.inf`` will\n+        identify clusters across all scales; reducing ``max_eps`` will result\n+        in shorter run times.\n+\n+    metric : string or callable, optional (default='minkowski')\n+        Metric to use for distance computation. Any metric from scikit-learn\n+        or scipy.spatial.distance can be used.\n+\n+        If metric is a callable function, it is called on each\n+        pair of instances (rows) and the resulting value recorded. The callable\n+        should take two arrays as input and return one value indicating the\n+        distance between them. This works for Scipy's metrics, but is less\n+        efficient than passing the metric name as a string. If metric is\n+        \"precomputed\", X is assumed to be a distance matrix and must be square.\n+\n+        Valid values for metric are:\n+\n+        - from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n+          'manhattan']\n+\n+        - from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n+          'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',\n+          'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',\n+          'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n+          'yule']\n+\n+        See the documentation for scipy.spatial.distance for details on these\n+        metrics.\n+\n+    p : integer, optional (default=2)\n+        Parameter for the Minkowski metric from\n+        :class:`sklearn.metrics.pairwise_distances`. When p = 1, this is\n+        equivalent to using manhattan_distance (l1), and euclidean_distance\n+        (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n+\n+    metric_params : dict, optional (default=None)\n+        Additional keyword arguments for the metric function.\n+\n+    cluster_method : string, optional (default='xi')\n+        The extraction method used to extract clusters using the calculated\n+        reachability and ordering. Possible values are \"xi\" and \"dbscan\".\n+\n+    eps : float, optional (default=None)\n+        The maximum distance between two samples for one to be considered as\n+        in the neighborhood of the other. By default it assumes the same value\n+        as ``max_eps``.\n+        Used only when ``cluster_method='dbscan'``.\n+\n+    xi : float, between 0 and 1, optional (default=0.05)\n+        Determines the minimum steepness on the reachability plot that\n+        constitutes a cluster boundary. For example, an upwards point in the\n+        reachability plot is defined by the ratio from one point to its\n+        successor being at most 1-xi.\n+        Used only when ``cluster_method='xi'``.\n+\n+    predecessor_correction : bool, optional (default=True)\n+        Correct clusters according to the predecessors calculated by OPTICS\n+        [2]_. This parameter has minimal effect on most datasets.\n+        Used only when ``cluster_method='xi'``.\n+\n+    min_cluster_size : int > 1 or float between 0 and 1 (default=None)\n+        Minimum number of samples in an OPTICS cluster, expressed as an\n+        absolute number or a fraction of the number of samples (rounded to be\n+        at least 2). If ``None``, the value of ``min_samples`` is used instead.\n+        Used only when ``cluster_method='xi'``.\n+\n+    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n+        Algorithm used to compute the nearest neighbors:\n+\n+        - 'ball_tree' will use :class:`BallTree`\n+        - 'kd_tree' will use :class:`KDTree`\n+        - 'brute' will use a brute-force search.\n+        - 'auto' will attempt to decide the most appropriate algorithm\n+          based on the values passed to :meth:`fit` method. (default)\n+\n+        Note: fitting on sparse input will override the setting of\n+        this parameter, using brute force.\n+\n+    leaf_size : int, optional (default=30)\n+        Leaf size passed to :class:`BallTree` or :class:`KDTree`. This can\n+        affect the speed of the construction and query, as well as the memory\n+        required to store the tree. The optimal value depends on the\n+        nature of the problem.\n+\n+    n_jobs : int or None, optional (default=None)\n+        The number of parallel jobs to run for neighbors search.\n+        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n+        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n+        for more details.\n+\n+    Attributes\n+    ----------\n+    labels_ : array, shape (n_samples,)\n+        Cluster labels for each point in the dataset given to fit().\n+        Noisy samples and points which are not included in a leaf cluster\n+        of ``cluster_hierarchy_`` are labeled as -1.\n+\n+    reachability_ : array, shape (n_samples,)\n+        Reachability distances per sample, indexed by object order. Use\n+        ``clust.reachability_[clust.ordering_]`` to access in cluster order.\n+\n+    ordering_ : array, shape (n_samples,)\n+        The cluster ordered list of sample indices.\n+\n+    core_distances_ : array, shape (n_samples,)\n+        Distance at which each sample becomes a core point, indexed by object\n+        order. Points which will never be core have a distance of inf. Use\n+        ``clust.core_distances_[clust.ordering_]`` to access in cluster order.\n+\n+    predecessor_ : array, shape (n_samples,)\n+        Point that a sample was reached from, indexed by object order.\n+        Seed points have a predecessor of -1.\n+\n+    cluster_hierarchy_ : array, shape (n_clusters, 2)\n+        The list of clusters in the form of ``[start, end]`` in each row, with\n+        all indices inclusive. The clusters are ordered according to\n+        ``(end, -start)`` (ascending) so that larger clusters encompassing\n+        smaller clusters come after those smaller ones. Since ``labels_`` does\n+        not reflect the hierarchy, usually\n+        ``len(cluster_hierarchy_) > np.unique(optics.labels_)``. Please also\n+        note that these indices are of the ``ordering_``, i.e.\n+        ``X[ordering_][start:end + 1]`` form a cluster.\n+        Only available when ``cluster_method='xi'``.\n+\n+    See also\n+    --------\n+    DBSCAN\n+        A similar clustering for a specified neighborhood radius (eps).\n+        Our implementation is optimized for runtime.\n+\n+    References\n+    ----------\n+    .. [1] Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel,\n+       and J\u00f6rg Sander. \"OPTICS: ordering points to identify the clustering\n+       structure.\" ACM SIGMOD Record 28, no. 2 (1999): 49-60.\n+\n+    .. [2] Schubert, Erich, Michael Gertz.\n+       \"Improving the Cluster Structure Extracted from OPTICS Plots.\" Proc. of\n+       the Conference \"Lernen, Wissen, Daten, Analysen\" (LWDA) (2018): 318-329.\n+    \"\"\"\n+\n+    def __init__(self, min_samples=5, max_eps=np.inf, metric='minkowski', p=2,\n+                 metric_params=None, cluster_method='xi', eps=None, xi=0.05,\n+                 predecessor_correction=True, min_cluster_size=None,\n+                 algorithm='auto', leaf_size=30, n_jobs=None):\n+        self.max_eps = max_eps\n+        self.min_samples = min_samples\n+        self.min_cluster_size = min_cluster_size\n+        self.algorithm = algorithm\n+        self.metric = metric\n+        self.metric_params = metric_params\n+        self.p = p\n+        self.leaf_size = leaf_size\n+        self.cluster_method = cluster_method\n+        self.eps = eps\n+        self.xi = xi\n+        self.predecessor_correction = predecessor_correction\n+        self.n_jobs = n_jobs\n+\n+    def fit(self, X, y=None):\n+        \"\"\"Perform OPTICS clustering\n+\n+        Extracts an ordered list of points and reachability distances, and\n+        performs initial clustering using ``max_eps`` distance specified at\n+        OPTICS object instantiation.\n+\n+        Parameters\n+        ----------\n+        X : array, shape (n_samples, n_features), or (n_samples, n_samples)  \\\n+if metric=\u2019precomputed\u2019.\n+            A feature array, or array of distances between samples if\n+            metric='precomputed'.\n+\n+        y : ignored\n+\n+        Returns\n+        -------\n+        self : instance of OPTICS\n+            The instance.\n+        \"\"\"\n+        X = check_array(X, dtype=np.float)\n+\n+        if self.cluster_method not in ['dbscan', 'xi']:\n+            raise ValueError(\"cluster_method should be one of\"\n+                             \" 'dbscan' or 'xi' but is %s\" %\n+                             self.cluster_method)\n+\n+        (self.ordering_, self.core_distances_, self.reachability_,\n+         self.predecessor_) = compute_optics_graph(\n+             X=X, min_samples=self.min_samples, algorithm=self.algorithm,\n+             leaf_size=self.leaf_size, metric=self.metric,\n+             metric_params=self.metric_params, p=self.p, n_jobs=self.n_jobs,\n+             max_eps=self.max_eps)\n+\n+        # Extract clusters from the calculated orders and reachability\n+        if self.cluster_method == 'xi':\n+            labels_, clusters_ = cluster_optics_xi(\n+                self.reachability_,\n+                self.predecessor_,\n+                self.ordering_,\n+                self.min_samples,\n+                self.min_cluster_size,\n+                self.xi,\n+                self.predecessor_correction)\n+            self.cluster_hierarchy_ = clusters_\n+        elif self.cluster_method == 'dbscan':\n+            if self.eps is None:\n+                eps = self.max_eps\n+            else:\n+                eps = self.eps\n+\n+            if eps > self.max_eps:\n+                raise ValueError('Specify an epsilon smaller than %s. Got %s.'\n+                                 % (self.max_eps, eps))\n+\n+            labels_ = cluster_optics_dbscan(self.reachability_,\n+                                            self.core_distances_,\n+                                            self.ordering_,\n+                                            eps)\n+\n+        self.labels_ = labels_\n+        return self\n+\n+\n+def _validate_size(size, n_samples, param_name):\n+    if size <= 0 or (size !=\n+                     int(size)\n+                     and size > 1):\n+        raise ValueError('%s must be a positive integer '\n+                         'or a float between 0 and 1. Got %r' %\n+                         (param_name, size))\n+    elif size > n_samples:\n+        raise ValueError('%s must be no greater than the'\n+                         ' number of samples (%d). Got %d' %\n+                         (param_name, n_samples, size))\n+\n+\n+# OPTICS helper functions\n+def _compute_core_distances_(X, neighbors, min_samples, working_memory):\n+    \"\"\"Compute the k-th nearest neighbor of each sample\n+\n+    Equivalent to neighbors.kneighbors(X, self.min_samples)[0][:, -1]\n+    but with more memory efficiency.\n+\n+    Parameters\n+    ----------\n+    X : array, shape (n_samples, n_features)\n+        The data.\n+    neighbors : NearestNeighbors instance\n+        The fitted nearest neighbors estimator.\n+    working_memory : int, optional\n+        The sought maximum memory for temporary distance matrix chunks.\n+        When None (default), the value of\n+        ``sklearn.get_config()['working_memory']`` is used.\n+\n+    Returns\n+    -------\n+    core_distances : array, shape (n_samples,)\n+        Distance at which each sample becomes a core point.\n+        Points which will never be core have a distance of inf.\n+    \"\"\"\n+    n_samples = X.shape[0]\n+    core_distances = np.empty(n_samples)\n+    core_distances.fill(np.nan)\n+\n+    chunk_n_rows = get_chunk_n_rows(row_bytes=16 * min_samples,\n+                                    max_n_rows=n_samples,\n+                                    working_memory=working_memory)\n+    slices = gen_batches(n_samples, chunk_n_rows)\n+    for sl in slices:\n+        core_distances[sl] = neighbors.kneighbors(\n+            X[sl], min_samples)[0][:, -1]\n+    return core_distances\n+\n+\n+def compute_optics_graph(X, min_samples, max_eps, metric, p, metric_params,\n+                         algorithm, leaf_size, n_jobs):\n+    \"\"\"Computes the OPTICS reachability graph.\n+\n+    Read more in the :ref:`User Guide <optics>`.\n+\n+    Parameters\n+    ----------\n+    X : array, shape (n_samples, n_features), or (n_samples, n_samples)  \\\n+if metric=\u2019precomputed\u2019.\n+        A feature array, or array of distances between samples if\n+        metric='precomputed'\n+\n+    min_samples : int (default=5)\n+        The number of samples in a neighborhood for a point to be considered\n+        as a core point. Expressed as an absolute number or a fraction of the\n+        number of samples (rounded to be at least 2).\n+\n+    max_eps : float, optional (default=np.inf)\n+        The maximum distance between two samples for one to be considered as\n+        in the neighborhood of the other. Default value of ``np.inf`` will\n+        identify clusters across all scales; reducing ``max_eps`` will result\n+        in shorter run times.\n+\n+    metric : string or callable, optional (default='minkowski')\n+        Metric to use for distance computation. Any metric from scikit-learn\n+        or scipy.spatial.distance can be used.\n+\n+        If metric is a callable function, it is called on each\n+        pair of instances (rows) and the resulting value recorded. The callable\n+        should take two arrays as input and return one value indicating the\n+        distance between them. This works for Scipy's metrics, but is less\n+        efficient than passing the metric name as a string. If metric is\n+        \"precomputed\", X is assumed to be a distance matrix and must be square.\n+\n+        Valid values for metric are:\n+\n+        - from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n+          'manhattan']\n+\n+        - from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n+          'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',\n+          'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',\n+          'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n+          'yule']\n+\n+        See the documentation for scipy.spatial.distance for details on these\n+        metrics.\n+\n+    p : integer, optional (default=2)\n+        Parameter for the Minkowski metric from\n+        :class:`sklearn.metrics.pairwise_distances`. When p = 1, this is\n+        equivalent to using manhattan_distance (l1), and euclidean_distance\n+        (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n+\n+    metric_params : dict, optional (default=None)\n+        Additional keyword arguments for the metric function.\n+\n+    algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n+        Algorithm used to compute the nearest neighbors:\n+\n+        - 'ball_tree' will use :class:`BallTree`\n+        - 'kd_tree' will use :class:`KDTree`\n+        - 'brute' will use a brute-force search.\n+        - 'auto' will attempt to decide the most appropriate algorithm\n+          based on the values passed to :meth:`fit` method. (default)\n+\n+        Note: fitting on sparse input will override the setting of\n+        this parameter, using brute force.\n+\n+    leaf_size : int, optional (default=30)\n+        Leaf size passed to :class:`BallTree` or :class:`KDTree`. This can\n+        affect the speed of the construction and query, as well as the memory\n+        required to store the tree. The optimal value depends on the\n+        nature of the problem.\n+\n+    n_jobs : int or None, optional (default=None)\n+        The number of parallel jobs to run for neighbors search.\n+        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n+        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n+        for more details.\n+\n+    Returns\n+    -------\n+    ordering_ : array, shape (n_samples,)\n+        The cluster ordered list of sample indices.\n+\n+    core_distances_ : array, shape (n_samples,)\n+        Distance at which each sample becomes a core point, indexed by object\n+        order. Points which will never be core have a distance of inf. Use\n+        ``clust.core_distances_[clust.ordering_]`` to access in cluster order.\n+\n+    reachability_ : array, shape (n_samples,)\n+        Reachability distances per sample, indexed by object order. Use\n+        ``clust.reachability_[clust.ordering_]`` to access in cluster order.\n+\n+    predecessor_ : array, shape (n_samples,)\n+        Point that a sample was reached from, indexed by object order.\n+        Seed points have a predecessor of -1.\n+\n+    References\n+    ----------\n+    .. [1] Ankerst, Mihael, Markus M. Breunig, Hans-Peter Kriegel,\n+       and J\u00f6rg Sander. \"OPTICS: ordering points to identify the clustering\n+       structure.\" ACM SIGMOD Record 28, no. 2 (1999): 49-60.\n+    \"\"\"\n+    n_samples = X.shape[0]\n+    _validate_size(min_samples, n_samples, 'min_samples')\n+    if min_samples <= 1:\n+        min_samples = max(2, min_samples * n_samples)\n+\n+    # Start all points as 'unprocessed' ##\n+    reachability_ = np.empty(n_samples)\n+    reachability_.fill(np.inf)\n+    predecessor_ = np.empty(n_samples, dtype=int)\n+    predecessor_.fill(-1)\n+\n+    nbrs = NearestNeighbors(n_neighbors=min_samples,\n+                            algorithm=algorithm,\n+                            leaf_size=leaf_size,\n+                            metric=metric,\n+                            metric_params=metric_params,\n+                            p=p,\n+                            n_jobs=n_jobs)\n+\n+    nbrs.fit(X)\n+    # Here we first do a kNN query for each point, this differs from\n+    # the original OPTICS that only used epsilon range queries.\n+    # TODO: handle working_memory somehow?\n+    core_distances_ = _compute_core_distances_(X=X, neighbors=nbrs,\n+                                               min_samples=min_samples,\n+                                               working_memory=None)\n+    # OPTICS puts an upper limit on these, use inf for undefined.\n+    core_distances_[core_distances_ > max_eps] = np.inf\n+\n+    # Main OPTICS loop. Not parallelizable. The order that entries are\n+    # written to the 'ordering_' list is important!\n+    # Note that this implementation is O(n^2) theoretically, but\n+    # supposedly with very low constant factors.\n+    processed = np.zeros(X.shape[0], dtype=bool)\n+    ordering = np.zeros(X.shape[0], dtype=int)\n+    for ordering_idx in range(X.shape[0]):\n+        # Choose next based on smallest reachability distance\n+        # (And prefer smaller ids on ties, possibly np.inf!)\n+        index = np.where(processed == 0)[0]\n+        point = index[np.argmin(reachability_[index])]\n+\n+        processed[point] = True\n+        ordering[ordering_idx] = point\n+        if core_distances_[point] != np.inf:\n+            _set_reach_dist(core_distances_=core_distances_,\n+                            reachability_=reachability_,\n+                            predecessor_=predecessor_,\n+                            point_index=point,\n+                            processed=processed, X=X, nbrs=nbrs,\n+                            metric=metric, metric_params=metric_params,\n+                            p=p, max_eps=max_eps)\n+    if np.all(np.isinf(reachability_)):\n+        warnings.warn(\"All reachability values are inf. Set a larger\"\n+                      \" max_eps or all data will be considered outliers.\",\n+                      UserWarning)\n+    return ordering, core_distances_, reachability_, predecessor_\n+\n+\n+def _set_reach_dist(core_distances_, reachability_, predecessor_,\n+                    point_index, processed, X, nbrs, metric, metric_params,\n+                    p, max_eps):\n+    P = X[point_index:point_index + 1]\n+    # Assume that radius_neighbors is faster without distances\n+    # and we don't need all distances, nevertheless, this means\n+    # we may be doing some work twice.\n+    indices = nbrs.radius_neighbors(P, radius=max_eps,\n+                                    return_distance=False)[0]\n+\n+    # Getting indices of neighbors that have not been processed\n+    unproc = np.compress(~np.take(processed, indices), indices)\n+    # Neighbors of current point are already processed.\n+    if not unproc.size:\n+        return\n+\n+    # Only compute distances to unprocessed neighbors:\n+    if metric == 'precomputed':\n+        dists = X[point_index, unproc]\n+    else:\n+        _params = dict() if metric_params is None else metric_params.copy()\n+        if metric == 'minkowski' and 'p' not in _params:\n+            # the same logic as neighbors, p is ignored if explicitly set\n+            # in the dict params\n+            _params['p'] = p\n+        dists = pairwise_distances(P, np.take(X, unproc, axis=0),\n+                                   metric, n_jobs=None,\n+                                   **_params).ravel()\n+\n+    rdists = np.maximum(dists, core_distances_[point_index])\n+    improved = np.where(rdists < np.take(reachability_, unproc))\n+    reachability_[unproc[improved]] = rdists[improved]\n+    predecessor_[unproc[improved]] = point_index\n+\n+\n+def cluster_optics_dbscan(reachability, core_distances, ordering, eps):\n+    \"\"\"Performs DBSCAN extraction for an arbitrary epsilon.\n+\n+    Extracting the clusters runs in linear time. Note that this results in\n+    ``labels_`` which are close to a `DBSCAN` with similar settings and\n+    ``eps``, only if ``eps`` is close to ``max_eps``.\n+\n+    Parameters\n+    ----------\n+    reachability : array, shape (n_samples,)\n+        Reachability distances calculated by OPTICS (``reachability_``)\n+\n+    core_distances : array, shape (n_samples,)\n+        Distances at which points become core (``core_distances_``)\n+\n+    ordering : array, shape (n_samples,)\n+        OPTICS ordered point indices (``ordering_``)\n+\n+    eps : float\n+        DBSCAN ``eps`` parameter. Must be set to < ``max_eps``. Results\n+        will be close to DBSCAN algorithm if ``eps`` and ``max_eps`` are close\n+        to one another.\n+\n+    Returns\n+    -------\n+    labels_ : array, shape (n_samples,)\n+        The estimated labels.\n+\n+    \"\"\"\n+    n_samples = len(core_distances)\n+    labels = np.zeros(n_samples, dtype=int)\n+\n+    far_reach = reachability > eps\n+    near_core = core_distances <= eps\n+    labels[ordering] = np.cumsum(far_reach[ordering] & near_core[ordering]) - 1\n+    labels[far_reach & ~near_core] = -1\n+    return labels\n+\n+\n+def cluster_optics_xi(reachability, predecessor, ordering, min_samples,\n+                      min_cluster_size=None, xi=0.05,\n+                      predecessor_correction=True):\n+    \"\"\"Automatically extract clusters according to the Xi-steep method.\n+\n+    Parameters\n+    ----------\n+    reachability : array, shape (n_samples,)\n+        Reachability distances calculated by OPTICS (`reachability_`)\n+\n+    predecessor : array, shape (n_samples,)\n+        Predecessors calculated by OPTICS.\n+\n+    ordering : array, shape (n_samples,)\n+        OPTICS ordered point indices (`ordering_`)\n+\n+    min_samples : int > 1 or float between 0 and 1 (default=None)\n+        The same as the min_samples given to OPTICS. Up and down steep regions\n+        can't have more then ``min_samples`` consecutive non-steep points.\n+        Expressed as an absolute number or a fraction of the number of samples\n+        (rounded to be at least 2).\n+\n+    min_cluster_size : int > 1 or float between 0 and 1 (default=None)\n+        Minimum number of samples in an OPTICS cluster, expressed as an\n+        absolute number or a fraction of the number of samples (rounded to be\n+        at least 2). If ``None``, the value of ``min_samples`` is used instead.\n+\n+    xi : float, between 0 and 1, optional (default=0.05)\n+        Determines the minimum steepness on the reachability plot that\n+        constitutes a cluster boundary. For example, an upwards point in the\n+        reachability plot is defined by the ratio from one point to its\n+        successor being at most 1-xi.\n+\n+    predecessor_correction : bool, optional (default=True)\n+        Correct clusters based on the calculated predecessors.\n+\n+    Returns\n+    -------\n+    labels : array, shape (n_samples)\n+        The labels assigned to samples. Points which are not included\n+        in any cluster are labeled as -1.\n+\n+    clusters : array, shape (n_clusters, 2)\n+        The list of clusters in the form of ``[start, end]`` in each row, with\n+        all indices inclusive. The clusters are ordered according to ``(end,\n+        -start)`` (ascending) so that larger clusters encompassing smaller\n+        clusters come after such nested smaller clusters. Since ``labels`` does\n+        not reflect the hierarchy, usually ``len(clusters) >\n+        np.unique(labels)``.\n+    \"\"\"\n+    n_samples = len(reachability)\n+    _validate_size(min_samples, n_samples, 'min_samples')\n+    if min_samples <= 1:\n+        min_samples = max(2, min_samples * n_samples)\n+    if min_cluster_size is None:\n+        min_cluster_size = min_samples\n+    _validate_size(min_cluster_size, n_samples, 'min_cluster_size')\n+    if min_cluster_size <= 1:\n+        min_cluster_size = max(2, min_cluster_size * n_samples)\n+\n+    clusters = _xi_cluster(reachability[ordering], predecessor[ordering],\n+                           ordering, xi,\n+                           min_samples, min_cluster_size,\n+                           predecessor_correction)\n+    labels = _extract_xi_labels(ordering, clusters)\n+    return labels, clusters\n+\n+\n+def _extend_region(steep_point, xward_point, start, min_samples):\n+    \"\"\"Extend the area until it's maximal.\n+\n+    It's the same function for both upward and downward reagions, depending on\n+    the given input parameters. Assuming:\n+\n+        - steep_{upward/downward}: bool array indicating whether a point is a\n+          steep {upward/downward};\n+        - upward/downward: bool array indicating whether a point is\n+          upward/downward;\n+\n+    To extend an upward reagion, ``steep_point=steep_upward`` and\n+    ``xward_point=downward`` are expected, and to extend a downward region,\n+    ``steep_point=steep_downward`` and ``xward_point=upward``.\n+\n+    Parameters\n+    ----------\n+    steep_point : bool array, shape (n_samples)\n+        True if the point is steep downward (upward).\n+\n+    xward_point : bool array, shape (n_samples)\n+        True if the point is an upward (respectively downward) point.\n+\n+    start : integer\n+        The start of the xward region.\n+\n+    min_samples : integer\n+       The same as the min_samples given to OPTICS. Up and down steep\n+       regions can't have more then ``min_samples`` consecutive non-steep\n+       points.\n+\n+    Returns\n+    -------\n+    index : integer\n+        The current index iterating over all the samples, i.e. where we are up\n+        to in our search.\n+\n+    end : integer\n+        The end of the region, which can be behind the index. The region\n+        includes the ``end`` index.\n+    \"\"\"\n+    n_samples = len(steep_point)\n+    non_xward_points = 0\n+    index = start\n+    end = start\n+    # find a maximal area\n+    while index < n_samples:\n+        if steep_point[index]:\n+            non_xward_points = 0\n+            end = index\n+        elif not xward_point[index]:\n+            # it's not a steep point, but still goes up.\n+            non_xward_points += 1\n+            # region should include no more than min_samples consecutive\n+            # non steep xward points.\n+            if non_xward_points > min_samples:\n+                break\n+        else:\n+            return end\n+        index += 1\n+    return end\n+\n+\n+def _update_filter_sdas(sdas, mib, xi_complement, reachability_plot):\n+    \"\"\"Update steep down areas (SDAs) using the new maximum in between (mib)\n+    value, and the given complement of xi, i.e. ``1 - xi``.\n+    \"\"\"\n+    if np.isinf(mib):\n+        return []\n+    res = [sda for sda in sdas\n+           if mib <= reachability_plot[sda['start']] * xi_complement]\n+    for sda in res:\n+        sda['mib'] = max(sda['mib'], mib)\n+    return res\n+\n+\n+def _correct_predecessor(reachability_plot, predecessor_plot, ordering, s, e):\n+    \"\"\"Correct for predecessors.\n+\n+    Applies Algorithm 2 of [1]_.\n+\n+    Input parameters are ordered by the computer OPTICS ordering.\n+\n+    .. [1] Schubert, Erich, Michael Gertz.\n+       \"Improving the Cluster Structure Extracted from OPTICS Plots.\" Proc. of\n+       the Conference \"Lernen, Wissen, Daten, Analysen\" (LWDA) (2018): 318-329.\n+    \"\"\"\n+    while s < e:\n+        if reachability_plot[s] > reachability_plot[e]:\n+            return s, e\n+        p_e = ordering[predecessor_plot[e]]\n+        for i in range(s, e):\n+            if p_e == ordering[i]:\n+                return s, e\n+        e -= 1\n+    return None, None\n+\n+\n+def _xi_cluster(reachability_plot, predecessor_plot, ordering, xi, min_samples,\n+                min_cluster_size, predecessor_correction):\n+    \"\"\"Automatically extract clusters according to the Xi-steep method.\n+\n+    This is rouphly an implementation of Figure 19 of the OPTICS paper.\n+\n+    Parameters\n+    ----------\n+    reachability_plot : array, shape (n_samples)\n+        The reachability plot, i.e. reachability ordered according to\n+        the calculated ordering, all computed by OPTICS.\n+\n+    predecessor_plot : array, shape (n_samples)\n+        Predecessors ordered according to the calculated ordering.\n+\n+    xi : float, between 0 and 1\n+        Determines the minimum steepness on the reachability plot that\n+        constitutes a cluster boundary. For example, an upwards point in the\n+        reachability plot is defined by the ratio from one point to its\n+        successor being at most 1-xi.\n+\n+    min_samples : int > 1 or float between 0 and 1 (default=None)\n+        The same as the min_samples given to OPTICS. Up and down steep regions\n+        can't have more then ``min_samples`` consecutive non-steep points.\n+        Expressed as an absolute number or a fraction of the number of samples\n+        (rounded to be at least 2).\n+\n+    min_cluster_size : int > 1 or float between 0 and 1\n+        Minimum number of samples in an OPTICS cluster, expressed as an\n+        absolute number or a fraction of the number of samples (rounded\n+        to be at least 2).\n+\n+    predecessor_correction : bool\n+        Correct clusters based on the calculated predecessors.\n+\n+    Returns\n+    -------\n+    clusters : array, shape (n_clusters, 2)\n+        The list of clusters in the form of [start, end] in each row, with all\n+        indices inclusive. The clusters are ordered in a way that larger\n+        clusters encompassing smaller clusters come after those smaller\n+        clusters.\n+    \"\"\"\n+\n+    # Our implementation adds an inf to the end of reachability plot\n+    # this helps to find potential clusters at the end of the\n+    # reachability plot even if there's no upward region at the end of it.\n+    reachability_plot = np.hstack((reachability_plot, np.inf))\n+\n+    xi_complement = 1 - xi\n+    sdas = []  # steep down areas, introduced in section 4.3.2 of the paper\n+    clusters = []\n+    index = 0\n+    mib = 0.  # maximum in between, section 4.3.2\n+\n+    # Our implementation corrects a mistake in the original\n+    # paper, i.e., in Definition 9 steep downward point,\n+    # r(p) * (1 - x1) <= r(p + 1) should be\n+    # r(p) * (1 - x1) >= r(p + 1)\n+    with np.errstate(invalid='ignore'):\n+        ratio = reachability_plot[:-1] / reachability_plot[1:]\n+        steep_upward = ratio <= xi_complement\n+        steep_downward = ratio >= 1 / xi_complement\n+        downward = ratio > 1\n+        upward = ratio < 1\n+\n+    # the following loop is is almost exactly as Figure 19 of the paper.\n+    # it jumps over the areas which are not either steep down or up areas\n+    for steep_index in iter(np.flatnonzero(steep_upward | steep_downward)):\n+        # just continue if steep_index has been a part of a discovered xward\n+        # area.\n+        if steep_index < index:\n+            continue\n+\n+        mib = max(mib, np.max(reachability_plot[index:steep_index + 1]))\n+\n+        # steep downward areas\n+        if steep_downward[steep_index]:\n+            sdas = _update_filter_sdas(sdas, mib, xi_complement,\n+                                       reachability_plot)\n+            D_start = steep_index\n+            D_end = _extend_region(steep_downward, upward,\n+                                   D_start, min_samples)\n+            D = {'start': D_start, 'end': D_end, 'mib': 0.}\n+            sdas.append(D)\n+            index = D_end + 1\n+            mib = reachability_plot[index]\n+\n+        # steep upward areas\n+        else:\n+            sdas = _update_filter_sdas(sdas, mib, xi_complement,\n+                                       reachability_plot)\n+            U_start = steep_index\n+            U_end = _extend_region(steep_upward, downward, U_start,\n+                                   min_samples)\n+            index = U_end + 1\n+            mib = reachability_plot[index]\n+\n+            U_clusters = []\n+            for D in sdas:\n+                c_start = D['start']\n+                c_end = U_end\n+\n+                # line (**), sc2*\n+                if reachability_plot[c_end + 1] * xi_complement < D['mib']:\n+                    continue\n+\n+                # Definition 11: criterion 4\n+                D_max = reachability_plot[D['start']]\n+                if D_max * xi_complement >= reachability_plot[c_end + 1]:\n+                    # Find the first index from the left side which is almost\n+                    # at the same level as the end of the detected cluster.\n+                    while (reachability_plot[c_start + 1] >\n+                           reachability_plot[c_end + 1]\n+                           and c_start < D['end']):\n+                        c_start += 1\n+                elif reachability_plot[c_end + 1] * xi_complement >= D_max:\n+                    # Find the first index from the right side which is almost\n+                    # at the same level as the beginning of the detected\n+                    # cluster.\n+                    # Our implementation corrects a mistake in the original\n+                    # paper, i.e., in Definition 11 4c, r(x) < r(sD) should be\n+                    # r(x) > r(sD).\n+                    while (reachability_plot[c_end - 1] > D_max\n+                           and c_end > U_start):\n+                        c_end -= 1\n+\n+                # predecessor correction\n+                if predecessor_correction:\n+                    c_start, c_end = _correct_predecessor(reachability_plot,\n+                                                          predecessor_plot,\n+                                                          ordering,\n+                                                          c_start,\n+                                                          c_end)\n+                if c_start is None:\n+                    continue\n+\n+                # Definition 11: criterion 3.a\n+                if c_end - c_start + 1 < min_cluster_size:\n+                    continue\n+\n+                # Definition 11: criterion 1\n+                if c_start > D['end']:\n+                    continue\n+\n+                # Definition 11: criterion 2\n+                if c_end < U_start:\n+                    continue\n+\n+                U_clusters.append((c_start, c_end))\n+\n+            # add smaller clusters first.\n+            U_clusters.reverse()\n+            clusters.extend(U_clusters)\n+\n+    return np.array(clusters)\n+\n+\n+def _extract_xi_labels(ordering, clusters):\n+    \"\"\"Extracts the labels from the clusters returned by `_xi_cluster`.\n+    We rely on the fact that clusters are stored\n+    with the smaller clusters coming before the larger ones.\n+\n+    Parameters\n+    ----------\n+    ordering : array, shape (n_samples)\n+        The ordering of points calculated by OPTICS\n+\n+    clusters : array, shape (n_clusters, 2)\n+        List of clusters i.e. (start, end) tuples,\n+        as returned by `_xi_cluster`.\n+\n+    Returns\n+    -------\n+    labels : array, shape (n_samples)\n+    \"\"\"\n+\n+    labels = np.full(len(ordering), -1, dtype=int)\n+    label = 0\n+    for c in clusters:\n+        if not np.any(labels[c[0]:(c[1] + 1)] != -1):\n+            labels[c[0]:(c[1] + 1)] = label\n+            label += 1\n+    labels[ordering] = labels.copy()\n+    return labels\ndiff --git a/test_float_regression.py b/test_float_regression.py\nnew file mode 100644\nindex 000000000..5c17c5f77\n--- /dev/null\n+++ b/test_float_regression.py\n@@ -0,0 +1,53 @@\n+\"\"\"\n+Regression test for the float min_samples bug in OPTICS.\n+This test verifies that the bug described in the issue is fixed.\n+\"\"\"\n+import numpy as np\n+from sklearn.cluster import OPTICS\n+\n+def test_optics_float_min_samples():\n+    \"\"\"Test that OPTICS accepts float min_samples without TypeError.\"\"\"\n+    # Create test data as specified in the issue\n+    np.random.seed(42)\n+    data = np.random.randn(100, 2)\n+    \n+    # This was failing before the fix with:\n+    # TypeError: n_neighbors does not take <class 'numpy.float64'> value, enter integer value\n+    clust = OPTICS(metric='minkowski', n_jobs=-1, min_samples=0.1)\n+    clust.fit(data)\n+    \n+    # Verify it computed something reasonable\n+    assert hasattr(clust, 'labels_')\n+    assert hasattr(clust, 'reachability_')\n+    assert hasattr(clust, 'ordering_')\n+    assert hasattr(clust, 'core_distances_')\n+    assert hasattr(clust, 'predecessor_')\n+    \n+    # The min_samples should have been converted to int(round(max(2, 0.1 * 100))) = 10\n+    # We can't directly check this as it's internal, but we can verify no error occurred\n+    \n+    print(\"[OK] OPTICS with float min_samples=0.1 works correctly\")\n+    \n+    # Test edge cases\n+    test_cases = [\n+        (0.01, \"very small float\"),\n+        (0.5, \"medium float\"),\n+        (0.99, \"large float < 1\"),\n+        (1.0, \"exactly 1.0\"),\n+    ]\n+    \n+    for min_samples, desc in test_cases:\n+        clust = OPTICS(min_samples=min_samples)\n+        clust.fit(data)\n+        print(f\"[OK] OPTICS with min_samples={min_samples} ({desc}) works correctly\")\n+    \n+    # Test with small dataset where min_samples * n < 2\n+    small_data = np.random.randn(10, 2)\n+    clust = OPTICS(min_samples=0.1)  # 0.1 * 10 = 1, should become 2\n+    clust.fit(small_data)\n+    print(\"[OK] OPTICS with min_samples=0.1 on small dataset (n=10) works correctly\")\n+    \n+    print(\"\\nAll regression tests passed! The float min_samples bug is fixed.\")\n+\n+if __name__ == \"__main__\":\n+    test_optics_float_min_samples()\ndiff --git a/test_optics_bug.py b/test_optics_bug.py\nnew file mode 100644\nindex 000000000..fe275b6b9\n--- /dev/null\n+++ b/test_optics_bug.py\n@@ -0,0 +1,21 @@\n+import numpy as np\n+from sklearn.cluster import OPTICS\n+\n+# Create some test data\n+np.random.seed(42)\n+X = np.random.randn(100, 2)\n+\n+# This should fail with the current implementation\n+print(\"Testing OPTICS with float min_samples...\")\n+try:\n+    clust = OPTICS(metric='minkowski', n_jobs=-1, min_samples=0.1)\n+    clust.fit(X)\n+    print(\"Success! No error occurred.\")\n+except TypeError as e:\n+    print(f\"Error occurred as expected: {e}\")\n+    \n+# Test with integer min_samples (should work)\n+print(\"\\nTesting OPTICS with integer min_samples...\")\n+clust = OPTICS(metric='minkowski', n_jobs=-1, min_samples=10)\n+clust.fit(X)\n+print(\"Success with integer min_samples!\")\ndiff --git a/test_optics_comprehensive.py b/test_optics_comprehensive.py\nnew file mode 100644\nindex 000000000..0e266fd3f\n--- /dev/null\n+++ b/test_optics_comprehensive.py\n@@ -0,0 +1,74 @@\n+import numpy as np\n+from sklearn.cluster import OPTICS\n+\n+# Create test data\n+np.random.seed(42)\n+X = np.random.randn(100, 2)\n+\n+# Test various float min_samples values\n+float_values = [0.01, 0.1, 0.5, 0.99]\n+\n+print(\"Testing OPTICS with various float min_samples values...\")\n+for val in float_values:\n+    try:\n+        clust = OPTICS(min_samples=val)\n+        clust.fit(X)\n+        # Calculate what the actual min_samples should be\n+        expected = int(round(max(2, val * 100)))\n+        print(f\"min_samples={val} -> Success! (converted to {expected})\")\n+    except Exception as e:\n+        print(f\"min_samples={val} -> Failed: {e}\")\n+\n+# Test edge case where min_samples * n_samples < 2\n+print(\"\\nTesting edge case where min_samples * n_samples < 2...\")\n+X_small = np.random.randn(10, 2)\n+try:\n+    clust = OPTICS(min_samples=0.1)  # 0.1 * 10 = 1, should become 2\n+    clust.fit(X_small)\n+    print(\"Success! min_samples=0.1 with n_samples=10 works (converts to 2)\")\n+except Exception as e:\n+    print(f\"Failed: {e}\")\n+\n+# Test extract_xi with float parameters\n+print(\"\\nTesting extract_xi with float min_samples...\")\n+clust = OPTICS(min_samples=5)  # Use integer for fitting\n+clust.fit(X)\n+try:\n+    # extract_xi also accepts min_samples as float\n+    labels = clust.extract_xi(min_samples=0.1)\n+    print(\"Success! extract_xi with float min_samples works\")\n+except Exception as e:\n+    print(f\"Failed: {e}\")\n+\n+# Test extract_xi with float min_cluster_size\n+print(\"\\nTesting extract_xi with float min_cluster_size...\")\n+try:\n+    labels = clust.extract_xi(min_samples=5, min_cluster_size=0.1)\n+    print(\"Success! extract_xi with float min_cluster_size works\")\n+except Exception as e:\n+    print(f\"Failed: {e}\")\n+\n+# Test boundary conditions\n+print(\"\\nTesting boundary conditions...\")\n+# Test exactly 1.0\n+try:\n+    clust = OPTICS(min_samples=1.0)\n+    clust.fit(X)\n+    print(\"Success! min_samples=1.0 works\")\n+except Exception as e:\n+    print(f\"Failed with min_samples=1.0: {e}\")\n+\n+# Test Python 2 style round() behavior\n+print(\"\\nVerifying rounding behavior...\")\n+test_vals = [(0.025, 100, 2),  # 0.025 * 100 = 2.5 -> rounds to 2\n+              (0.026, 100, 3),  # 0.026 * 100 = 2.6 -> rounds to 3  \n+              (0.035, 100, 4),  # 0.035 * 100 = 3.5 -> rounds to 4\n+              (0.045, 100, 4)]  # 0.045 * 100 = 4.5 -> rounds to 4\n+              \n+for min_samp, n_samp, expected in test_vals:\n+    actual = int(round(max(2, min_samp * n_samp)))\n+    print(f\"min_samples={min_samp}, n_samples={n_samp}: \"\n+          f\"{min_samp * n_samp} -> {actual} (expected {expected})\")\n+    assert actual == expected, f\"Rounding error: got {actual}, expected {expected}\"\n+\n+print(\"\\nAll tests passed!\")\ndiff --git a/test_optics_xi.py b/test_optics_xi.py\nnew file mode 100644\nindex 000000000..87bb91acf\n--- /dev/null\n+++ b/test_optics_xi.py\n@@ -0,0 +1,58 @@\n+import numpy as np\n+from sklearn.cluster import OPTICS\n+from sklearn.cluster.optics_ import cluster_optics_xi\n+\n+# Create test data\n+np.random.seed(42)\n+X = np.random.randn(100, 2)\n+\n+# Fit OPTICS first\n+print(\"Fitting OPTICS...\")\n+clust = OPTICS(min_samples=5)\n+clust.fit(X)\n+\n+# Now test cluster_optics_xi with float parameters\n+print(\"\\nTesting cluster_optics_xi with float min_samples...\")\n+try:\n+    labels, clusters = cluster_optics_xi(\n+        clust.reachability_,\n+        clust.predecessor_,\n+        clust.ordering_,\n+        min_samples=0.1,  # This should be converted to int\n+        xi=0.05\n+    )\n+    print(\"Success! cluster_optics_xi with float min_samples works\")\n+except Exception as e:\n+    print(f\"Failed: {e}\")\n+\n+# Test with float min_cluster_size\n+print(\"\\nTesting cluster_optics_xi with float min_cluster_size...\")\n+try:\n+    labels, clusters = cluster_optics_xi(\n+        clust.reachability_,\n+        clust.predecessor_,\n+        clust.ordering_,\n+        min_samples=5,\n+        min_cluster_size=0.1,  # This should be converted to int\n+        xi=0.05\n+    )\n+    print(\"Success! cluster_optics_xi with float min_cluster_size works\")\n+except Exception as e:\n+    print(f\"Failed: {e}\")\n+\n+# Test with both as floats\n+print(\"\\nTesting cluster_optics_xi with both parameters as floats...\")\n+try:\n+    labels, clusters = cluster_optics_xi(\n+        clust.reachability_,\n+        clust.predecessor_,\n+        clust.ordering_,\n+        min_samples=0.1,  # This should be converted to int\n+        min_cluster_size=0.1,  # This should be converted to int\n+        xi=0.05\n+    )\n+    print(\"Success! cluster_optics_xi with both float parameters works\")\n+except Exception as e:\n+    print(f\"Failed: {e}\")\n+\n+print(\"\\nAll tests completed!\")\n", "gold_standard_diff": "From 4fba93f90bb303157026fab371cdc9d3102f6a5b Mon Sep 17 00:00:00 2001\nFrom: Hanmin Qin <qinhanmin2005@sina.com>\nDate: Sun, 28 Jul 2019 21:44:57 +0800\nSubject: [PATCH 1/5] FIX Support float min_samples and min_cluster_size in\n OPTICS\n\n---\n doc/whats_new/v0.21.rst              |  4 ++++\n sklearn/cluster/optics_.py           | 22 +++++++++-------------\n sklearn/cluster/tests/test_optics.py |  6 ++++++\n 3 files changed, 19 insertions(+), 13 deletions(-)\n\ndiff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst\nindex d2b274ca3d8ed..7bb89f851207d 100644\n--- a/doc/whats_new/v0.21.rst\n+++ b/doc/whats_new/v0.21.rst\n@@ -33,6 +33,10 @@ Changelog\n   threaded when `n_jobs > 1` or `n_jobs = -1`.\n   :issue:`12949` by :user:`Prabakaran Kumaresshan <nixphix>`.\n \n+- |Fix| fixed a bug in :class:`cluster.OPTICS` where users were unable to\n+  use float `min_samples` and `min_cluster_size`.\n+  :pr:`14496` by :user:`Fabian Klopfer <someusername1>`\n+\n :mod:`sklearn.inspection`\n .....................\n \ndiff --git a/sklearn/cluster/optics_.py b/sklearn/cluster/optics_.py\nindex 4f7eb11ab2f72..c9615870a431f 100755\n--- a/sklearn/cluster/optics_.py\n+++ b/sklearn/cluster/optics_.py\n@@ -44,7 +44,7 @@ class OPTICS(BaseEstimator, ClusterMixin):\n \n     Parameters\n     ----------\n-    min_samples : int > 1 or float between 0 and 1 (default=None)\n+    min_samples : int > 1 or float between 0 and 1 (default=5)\n         The number of samples in a neighborhood for a point to be considered as\n         a core point. Also, up and down steep regions can't have more then\n         ``min_samples`` consecutive non-steep points. Expressed as an absolute\n@@ -341,7 +341,7 @@ def compute_optics_graph(X, min_samples, max_eps, metric, p, metric_params,\n         A feature array, or array of distances between samples if\n         metric='precomputed'\n \n-    min_samples : int (default=5)\n+    min_samples : int > 1 or float between 0 and 1 (default=5)\n         The number of samples in a neighborhood for a point to be considered\n         as a core point. Expressed as an absolute number or a fraction of the\n         number of samples (rounded to be at least 2).\n@@ -437,7 +437,7 @@ def compute_optics_graph(X, min_samples, max_eps, metric, p, metric_params,\n     n_samples = X.shape[0]\n     _validate_size(min_samples, n_samples, 'min_samples')\n     if min_samples <= 1:\n-        min_samples = max(2, min_samples * n_samples)\n+        min_samples = max(2, int(min_samples * n_samples))\n \n     # Start all points as 'unprocessed' ##\n     reachability_ = np.empty(n_samples)\n@@ -582,7 +582,7 @@ def cluster_optics_xi(reachability, predecessor, ordering, min_samples,\n     ordering : array, shape (n_samples,)\n         OPTICS ordered point indices (`ordering_`)\n \n-    min_samples : int > 1 or float between 0 and 1 (default=None)\n+    min_samples : int > 1 or float between 0 and 1\n         The same as the min_samples given to OPTICS. Up and down steep regions\n         can't have more then ``min_samples`` consecutive non-steep points.\n         Expressed as an absolute number or a fraction of the number of samples\n@@ -619,12 +619,12 @@ def cluster_optics_xi(reachability, predecessor, ordering, min_samples,\n     n_samples = len(reachability)\n     _validate_size(min_samples, n_samples, 'min_samples')\n     if min_samples <= 1:\n-        min_samples = max(2, min_samples * n_samples)\n+        min_samples = max(2, int(min_samples * n_samples))\n     if min_cluster_size is None:\n         min_cluster_size = min_samples\n     _validate_size(min_cluster_size, n_samples, 'min_cluster_size')\n     if min_cluster_size <= 1:\n-        min_cluster_size = max(2, min_cluster_size * n_samples)\n+        min_cluster_size = max(2, int(min_cluster_size * n_samples))\n \n     clusters = _xi_cluster(reachability[ordering], predecessor[ordering],\n                            ordering, xi,\n@@ -753,16 +753,12 @@ def _xi_cluster(reachability_plot, predecessor_plot, ordering, xi, min_samples,\n         reachability plot is defined by the ratio from one point to its\n         successor being at most 1-xi.\n \n-    min_samples : int > 1 or float between 0 and 1 (default=None)\n+    min_samples : int > 1\n         The same as the min_samples given to OPTICS. Up and down steep regions\n         can't have more then ``min_samples`` consecutive non-steep points.\n-        Expressed as an absolute number or a fraction of the number of samples\n-        (rounded to be at least 2).\n \n-    min_cluster_size : int > 1 or float between 0 and 1\n-        Minimum number of samples in an OPTICS cluster, expressed as an\n-        absolute number or a fraction of the number of samples (rounded\n-        to be at least 2).\n+    min_cluster_size : int > 1\n+        Minimum number of samples in an OPTICS cluster.\n \n     predecessor_correction : bool\n         Correct clusters based on the calculated predecessors.\ndiff --git a/sklearn/cluster/tests/test_optics.py b/sklearn/cluster/tests/test_optics.py\nindex d5f4d62ea61b6..5ae8b3f898fcf 100644\n--- a/sklearn/cluster/tests/test_optics.py\n+++ b/sklearn/cluster/tests/test_optics.py\n@@ -101,6 +101,12 @@ def test_extract_xi():\n                    xi=0.4).fit(X)\n     assert_array_equal(clust.labels_, expected_labels)\n \n+    # check float min_samples and min_cluster_size\n+    clust = OPTICS(min_samples=0.1, min_cluster_size=0.08,\n+                   max_eps=20, cluster_method='xi',\n+                   xi=0.4).fit(X)\n+    assert_array_equal(clust.labels_, expected_labels)\n+\n     X = np.vstack((C1, C2, C3, C4, C5, np.array([[100, 100]] * 2), C6))\n     expected_labels = np.r_[[1] * 5, [3] * 5, [2] * 5, [0] * 5, [2] * 5,\n                             -1, -1, [4] * 5]\n\nFrom ab1380a49a9680b0e06d1409204603908af8c482 Mon Sep 17 00:00:00 2001\nFrom: Hanmin Qin <qinhanmin2005@sina.com>\nDate: Sun, 28 Jul 2019 21:47:50 +0800\nSubject: [PATCH 2/5] Update v0.21.rst\n\n---\n doc/whats_new/v0.21.rst | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst\nindex 7bb89f851207d..3cae76721214c 100644\n--- a/doc/whats_new/v0.21.rst\n+++ b/doc/whats_new/v0.21.rst\n@@ -34,7 +34,7 @@ Changelog\n   :issue:`12949` by :user:`Prabakaran Kumaresshan <nixphix>`.\n \n - |Fix| fixed a bug in :class:`cluster.OPTICS` where users were unable to\n-  use float `min_samples` and `min_cluster_size`.\n+  pass float `min_samples` and `min_cluster_size`.\n   :pr:`14496` by :user:`Fabian Klopfer <someusername1>`\n \n :mod:`sklearn.inspection`\n\nFrom bc1ca3cb9e53f55bc92fd3874979e12326c75ff7 Mon Sep 17 00:00:00 2001\nFrom: Hanmin Qin <qinhanmin2005@sina.com>\nDate: Sun, 28 Jul 2019 22:06:52 +0800\nSubject: [PATCH 3/5] adrin's comment\n\n---\n sklearn/cluster/optics_.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a/sklearn/cluster/optics_.py b/sklearn/cluster/optics_.py\nindex c9615870a431f..ecf5fa6a2bcc0 100755\n--- a/sklearn/cluster/optics_.py\n+++ b/sklearn/cluster/optics_.py\n@@ -341,7 +341,7 @@ def compute_optics_graph(X, min_samples, max_eps, metric, p, metric_params,\n         A feature array, or array of distances between samples if\n         metric='precomputed'\n \n-    min_samples : int > 1 or float between 0 and 1 (default=5)\n+    min_samples : int > 1 or float between 0 and 1\n         The number of samples in a neighborhood for a point to be considered\n         as a core point. Expressed as an absolute number or a fraction of the\n         number of samples (rounded to be at least 2).\n\nFrom b803462b2372ae7fcc26249db78d6f9c6133ff99 Mon Sep 17 00:00:00 2001\nFrom: Hanmin Qin <qinhanmin2005@sina.com>\nDate: Sun, 28 Jul 2019 22:15:27 +0800\nSubject: [PATCH 4/5] =?UTF-8?q?typo=20o(=E2=95=A5=EF=B9=8F=E2=95=A5)o?=\nMIME-Version: 1.0\nContent-Type: text/plain; charset=UTF-8\nContent-Transfer-Encoding: 8bit\n\n---\n doc/whats_new/v0.21.rst | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst\nindex b1f153af10adf..f63fa07952511 100644\n--- a/doc/whats_new/v0.21.rst\n+++ b/doc/whats_new/v0.21.rst\n@@ -33,7 +33,7 @@ Changelog\n   threaded when `n_jobs > 1` or `n_jobs = -1`.\n   :pr:`12955` by :user:`Prabakaran Kumaresshan <nixphix>`.\n \n-- |Fix| fixed a bug in :class:`cluster.OPTICS` where users were unable to\n+- |Fix| Fixed a bug in :class:`cluster.OPTICS` where users were unable to\n   pass float `min_samples` and `min_cluster_size`.\n   :pr:`14496` by :user:`Fabian Klopfer <someusername1>`\n \n\nFrom 8e8a34535f8f8743aedf88553d62e66423118423 Mon Sep 17 00:00:00 2001\nFrom: Hanmin Qin <qinhanmin2005@sina.com>\nDate: Mon, 29 Jul 2019 07:45:44 +0800\nSubject: [PATCH 5/5] Update v0.21.rst\n\n---\n doc/whats_new/v0.21.rst | 7 ++++---\n 1 file changed, 4 insertions(+), 3 deletions(-)\n\ndiff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst\nindex f63fa07952511..dab54162005d5 100644\n--- a/doc/whats_new/v0.21.rst\n+++ b/doc/whats_new/v0.21.rst\n@@ -33,9 +33,10 @@ Changelog\n   threaded when `n_jobs > 1` or `n_jobs = -1`.\n   :pr:`12955` by :user:`Prabakaran Kumaresshan <nixphix>`.\n \n-- |Fix| Fixed a bug in :class:`cluster.OPTICS` where users were unable to\n-  pass float `min_samples` and `min_cluster_size`.\n-  :pr:`14496` by :user:`Fabian Klopfer <someusername1>`\n+- |Fix| Fixed a bug in :class:`cluster.OPTICS` where users were unable to pass\n+  float `min_samples` and `min_cluster_size`. :pr:`14496` by\n+  :user:`Fabian Klopfer <someusername1>`\n+  and :user:`Hanmin Qin <qinhanmin2014>`.\n \n :mod:`sklearn.compose`\n .....................\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/14496"}