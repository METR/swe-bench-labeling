diff --git a/sklearn/feature_selection/_sequential.py b/sklearn/feature_selection/_sequential.py
index e983c55de..5d5947b48 100644
--- a/sklearn/feature_selection/_sequential.py
+++ b/sklearn/feature_selection/_sequential.py
@@ -14,7 +14,7 @@ from ..utils._param_validation import RealNotInt
 from ..utils._tags import _safe_tags
 from ..utils.validation import check_is_fitted
 from ..model_selection import cross_val_score
-from ..metrics import get_scorer_names
+from ..metrics import get_scorer_names, get_scorer
 
 
 class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator):
@@ -305,17 +305,35 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator
             if self.direction == "backward":
                 candidate_mask = ~candidate_mask
             X_new = X[:, candidate_mask]
-            scores[feature_idx] = cross_val_score(
-                estimator,
-                X_new,
-                y,
-                cv=self.cv,
-                scoring=self.scoring,
-                n_jobs=self.n_jobs,
-            ).mean()
+            if hasattr(self.cv, '__iter__'):
+                # If cv is an iterable of splits, use it directly
+                cv_splits = list(self.cv)
+                scores[feature_idx] = np.mean([
+                    self._score(estimator, X_new, y, train, test)
+                    for train, test in cv_splits
+                ])
+            else:
+                scores[feature_idx] = cross_val_score(
+                    estimator,
+                    X_new,
+                    y,
+                    cv=self.cv,
+                    scoring=self.scoring,
+                    n_jobs=self.n_jobs,
+                ).mean()
         new_feature_idx = max(scores, key=lambda feature_idx: scores[feature_idx])
         return new_feature_idx, scores[new_feature_idx]
 
+    def _score(self, estimator, X, y, train, test):
+        # Helper method to compute the score for a single split
+        X_train, X_test = X[train], X[test]
+        y_train, y_test = y[train], y[test]
+        estimator.fit(X_train, y_train)
+        if self.scoring is None:
+            return estimator.score(X_test, y_test)
+        scorer = get_scorer(self.scoring)
+        return scorer(estimator, X_test, y_test)
+
     def _get_support_mask(self):
         check_is_fitted(self)
         return self.support_
