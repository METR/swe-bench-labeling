{"instance_id": "scikit-learn__scikit-learn-14710", "score": "C", "diff": "diff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex ad6a5a8ca..3170e4000 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -426,11 +426,15 @@ class BaseHistGradientBoosting(BaseEstimator, ABC):\n \n         Scores are computed on validation data or on training data.\n         \"\"\"\n+        if hasattr(self, 'classes_'):\n+            y_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n \n         if self._use_validation_data:\n+            if hasattr(self, 'classes_'):\n+                y_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\n             )\ndiff --git a/test_comprehensive.py b/test_comprehensive.py\nnew file mode 100644\nindex 000000000..748fea1ee\n--- /dev/null\n+++ b/test_comprehensive.py\n@@ -0,0 +1,50 @@\n+import numpy as np\n+from sklearn.experimental import enable_hist_gradient_boosting\n+from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor\n+from sklearn.metrics import accuracy_score\n+\n+print(\"Testing HistGradientBoostingClassifier with early stopping and string labels...\")\n+\n+# Test 1: Binary classification with string labels\n+X = np.random.randn(200, 10)\n+y_string = np.array(['class_a'] * 100 + ['class_b'] * 100, dtype=object)\n+\n+# Test with early stopping and validation fraction\n+gbrt1 = HistGradientBoostingClassifier(n_iter_no_change=10, validation_fraction=0.2, random_state=42)\n+gbrt1.fit(X, y_string)\n+pred1 = gbrt1.predict(X)\n+acc1 = accuracy_score(y_string, pred1)\n+print(f\"Test 1 (binary string labels with validation): accuracy = {acc1:.3f}\")\n+\n+# Test 2: Multi-class classification with string labels\n+y_multiclass = np.array(['cat'] * 50 + ['dog'] * 50 + ['bird'] * 50 + ['fish'] * 50, dtype=object)\n+gbrt2 = HistGradientBoostingClassifier(n_iter_no_change=10, validation_fraction=0.2, random_state=42)\n+gbrt2.fit(X, y_multiclass)\n+pred2 = gbrt2.predict(X)\n+acc2 = accuracy_score(y_multiclass, pred2)\n+print(f\"Test 2 (multiclass string labels with validation): accuracy = {acc2:.3f}\")\n+\n+# Test 3: With early stopping but no validation (uses training set)\n+gbrt3 = HistGradientBoostingClassifier(n_iter_no_change=10, validation_fraction=None, random_state=42)\n+gbrt3.fit(X, y_string)\n+pred3 = gbrt3.predict(X)\n+acc3 = accuracy_score(y_string, pred3)\n+print(f\"Test 3 (string labels without validation): accuracy = {acc3:.3f}\")\n+\n+# Test 4: Ensure regression is not affected\n+print(\"\\nTesting HistGradientBoostingRegressor...\")\n+y_reg = np.random.randn(200)\n+gbrt_reg = HistGradientBoostingRegressor(n_iter_no_change=10, validation_fraction=0.2, random_state=42)\n+gbrt_reg.fit(X, y_reg)\n+print(\"Test 4 (regression): passed - no error\")\n+\n+# Test 5: Test with custom scoring function\n+from sklearn.metrics import f1_score, make_scorer\n+f1_scorer = make_scorer(f1_score, pos_label='class_b')\n+gbrt5 = HistGradientBoostingClassifier(n_iter_no_change=10, scoring=f1_scorer, validation_fraction=0.2, random_state=42)\n+gbrt5.fit(X, y_string)\n+pred5 = gbrt5.predict(X)\n+f1 = f1_score(y_string, pred5, pos_label='class_b')\n+print(f\"Test 5 (custom scorer with string labels): F1 score = {f1:.3f}\")\n+\n+print(\"\\nAll tests passed successfully!\")\ndiff --git a/test_issue.py b/test_issue.py\nnew file mode 100644\nindex 000000000..98c3c5977\n--- /dev/null\n+++ b/test_issue.py\n@@ -0,0 +1,22 @@\n+import numpy as np\n+from sklearn.experimental import enable_hist_gradient_boosting\n+from sklearn.ensemble import HistGradientBoostingClassifier\n+\n+# Test the issue\n+X = np.random.randn(100, 10)\n+y = np.array(['x'] * 50 + ['y'] * 50, dtype=object)\n+gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)\n+try:\n+    gbrt.fit(X, y)\n+    print(\"Test passed - no error\")\n+except Exception as e:\n+    print(f\"Error occurred: {type(e).__name__}: {e}\")\n+\n+# Test with numerical labels (this should work)\n+y_numeric = np.array([0] * 50 + [1] * 50)\n+gbrt2 = HistGradientBoostingClassifier(n_iter_no_change=10)\n+try:\n+    gbrt2.fit(X, y_numeric)\n+    print(\"Numeric labels test passed - no error\")\n+except Exception as e:\n+    print(f\"Numeric labels error: {type(e).__name__}: {e}\")\ndiff --git a/test_string_labels_early_stopping.py b/test_string_labels_early_stopping.py\nnew file mode 100644\nindex 000000000..acfcff9b8\n--- /dev/null\n+++ b/test_string_labels_early_stopping.py\n@@ -0,0 +1,88 @@\n+\"\"\"Test case for issue: HistGradientBoostingClassifier does not work with string \n+target when early stopping turned on\"\"\"\n+\n+import numpy as np\n+import pytest\n+from sklearn.experimental import enable_hist_gradient_boosting\n+from sklearn.ensemble import HistGradientBoostingClassifier\n+\n+\n+def test_string_labels_with_early_stopping():\n+    \"\"\"Test that HistGradientBoostingClassifier works with string labels and early stopping.\"\"\"\n+    X = np.random.RandomState(42).randn(100, 10)\n+    \n+    # Binary classification with string labels\n+    y_binary = np.array(['class_a'] * 50 + ['class_b'] * 50, dtype=object)\n+    \n+    # Test with validation fraction (most common case)\n+    clf = HistGradientBoostingClassifier(\n+        n_iter_no_change=10, \n+        validation_fraction=0.2, \n+        random_state=42,\n+        max_iter=50\n+    )\n+    clf.fit(X, y_binary)\n+    predictions = clf.predict(X)\n+    \n+    # Check that predictions are strings\n+    assert predictions.dtype == object\n+    assert set(predictions) <= {'class_a', 'class_b'}\n+    \n+    # Test without validation fraction (uses training set)\n+    clf2 = HistGradientBoostingClassifier(\n+        n_iter_no_change=10, \n+        validation_fraction=None, \n+        random_state=42,\n+        max_iter=50\n+    )\n+    clf2.fit(X, y_binary)\n+    predictions2 = clf2.predict(X)\n+    \n+    assert predictions2.dtype == object\n+    assert set(predictions2) <= {'class_a', 'class_b'}\n+    \n+    # Multiclass classification with string labels\n+    y_multiclass = np.array(['cat'] * 25 + ['dog'] * 25 + ['bird'] * 25 + ['fish'] * 25, dtype=object)\n+    \n+    clf3 = HistGradientBoostingClassifier(\n+        n_iter_no_change=10, \n+        validation_fraction=0.2, \n+        random_state=42,\n+        max_iter=50\n+    )\n+    clf3.fit(X, y_multiclass)\n+    predictions3 = clf3.predict(X)\n+    \n+    assert predictions3.dtype == object\n+    assert set(predictions3) <= {'cat', 'dog', 'bird', 'fish'}\n+\n+\n+def test_string_labels_with_custom_scorer():\n+    \"\"\"Test string labels work with custom scorers in early stopping.\"\"\"\n+    from sklearn.metrics import f1_score, make_scorer\n+    \n+    X = np.random.RandomState(42).randn(100, 10)\n+    y = np.array(['positive'] * 60 + ['negative'] * 40, dtype=object)\n+    \n+    f1_scorer = make_scorer(f1_score, pos_label='positive')\n+    \n+    clf = HistGradientBoostingClassifier(\n+        n_iter_no_change=10,\n+        scoring=f1_scorer,\n+        validation_fraction=0.2,\n+        random_state=42,\n+        max_iter=50\n+    )\n+    \n+    # This should work without errors\n+    clf.fit(X, y)\n+    predictions = clf.predict(X)\n+    \n+    assert predictions.dtype == object\n+    assert set(predictions) <= {'positive', 'negative'}\n+\n+\n+if __name__ == \"__main__\":\n+    test_string_labels_with_early_stopping()\n+    test_string_labels_with_custom_scorer()\n+    print(\"All tests passed!\")\ndiff --git a/test_warm_start_string_labels.py b/test_warm_start_string_labels.py\nnew file mode 100644\nindex 000000000..eba4873f6\n--- /dev/null\n+++ b/test_warm_start_string_labels.py\n@@ -0,0 +1,36 @@\n+import numpy as np\n+from sklearn.experimental import enable_hist_gradient_boosting\n+from sklearn.ensemble import HistGradientBoostingClassifier\n+\n+print(\"Testing warm start with string labels and early stopping...\")\n+\n+X = np.random.RandomState(42).randn(100, 10)\n+y = np.array(['class_a'] * 50 + ['class_b'] * 50, dtype=object)\n+\n+# Test warm start with early stopping\n+clf = HistGradientBoostingClassifier(\n+    n_iter_no_change=5,\n+    validation_fraction=0.2,\n+    warm_start=True,\n+    max_iter=10,\n+    random_state=42\n+)\n+\n+# First fit\n+clf.fit(X, y)\n+n_iter_1 = clf.n_iter_\n+print(f\"First fit: {n_iter_1} iterations\")\n+\n+# Continue training with warm start\n+clf.set_params(max_iter=20)\n+clf.fit(X, y)\n+n_iter_2 = clf.n_iter_\n+print(f\"Second fit: {n_iter_2} iterations\")\n+\n+assert n_iter_2 >= n_iter_1, \"Warm start should preserve or increase iterations\"\n+\n+predictions = clf.predict(X)\n+assert predictions.dtype == object\n+assert set(predictions) <= {'class_a', 'class_b'}\n+\n+print(\"Warm start test passed!\")\n", "gold_standard_diff": "From a0f6fa6267a0e7feee1ed21c77a9a41cbb79bca5 Mon Sep 17 00:00:00 2001\nFrom: Guillaume Lemaitre <g.lemaitre58@gmail.com>\nDate: Wed, 21 Aug 2019 18:28:57 +0200\nSubject: [PATCH 1/3] FIX encode target for scoring when using early stopping\n in HistGradientBoostingClassifier\n\n---\n doc/whats_new/v0.22.rst                                  | 3 +++\n .../_hist_gradient_boosting/gradient_boosting.py         | 5 ++++-\n .../tests/test_gradient_boosting.py                      | 9 +++++++++\n 3 files changed, 16 insertions(+), 1 deletion(-)\n\ndiff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst\nindex e1aa1cd8641f5..e6185949ffd87 100644\n--- a/doc/whats_new/v0.22.rst\n+++ b/doc/whats_new/v0.22.rst\n@@ -132,6 +132,9 @@ Changelog\n     method for both estimators. :pr:`13769` by `Nicolas Hug`_.\n   - |Fix| Estimators now bin the training and validation data separately to\n     avoid any data leak. :pr:`13933` by `Nicolas Hug`_.\n+  - |Fix| Targets are encoded before to compute score when using early stopping\n+    to avoid inconsistent target data types.\n+    :pr:`14710` by :user:`Guillaume Lemaitre <glemaitre>`.\n \n   Note that pickles from 0.21 will not work in 0.22.\n \ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex ad6a5a8ca381b..3f7d20a1e919f 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -248,7 +248,6 @@ def fit(self, X, y):\n                     (X_binned_small_train,\n                      y_small_train) = self._get_small_trainset(\n                         X_binned_train, y_train, self._small_trainset_seed)\n-\n                     self._check_early_stopping_scorer(\n                         X_binned_small_train, y_small_train,\n                         X_binned_val, y_val,\n@@ -426,11 +425,15 @@ def _check_early_stopping_scorer(self, X_binned_small_train, y_small_train,\n \n         Scores are computed on validation data or on training data.\n         \"\"\"\n+        if hasattr(self, 'classes_'):\n+            y_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n \n         if self._use_validation_data:\n+            if hasattr(self, 'classes_'):\n+                y_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\n             )\ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\nindex 1eebdefd5288d..86dcb582a23a0 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n@@ -415,3 +415,12 @@ def test_infinite_values_missing_values():\n \n     assert stump_clf.fit(X, y_isinf).score(X, y_isinf) == 1\n     assert stump_clf.fit(X, y_isnan).score(X, y_isnan) == 1\n+\n+\n+def test_string_target_early_stopping():\n+    # Regression tests for #14709 where the targets need to be encoded before\n+    # to compute the score\n+    X = np.random.randn(100, 10)\n+    y = np.array(['x'] * 50 + ['y'] * 50, dtype=object)\n+    gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)\n+    gbrt.fit(X, y)\n\nFrom f49864daa58e020aeabd5380c34440f5f74e8402 Mon Sep 17 00:00:00 2001\nFrom: Guillaume Lemaitre <g.lemaitre58@gmail.com>\nDate: Wed, 21 Aug 2019 18:30:56 +0200\nSubject: [PATCH 2/3] add line\n\n---\n sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py | 1 +\n 1 file changed, 1 insertion(+)\n\ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex 3f7d20a1e919f..3170e4000ecc5 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -248,6 +248,7 @@ def fit(self, X, y):\n                     (X_binned_small_train,\n                      y_small_train) = self._get_small_trainset(\n                         X_binned_train, y_train, self._small_trainset_seed)\n+\n                     self._check_early_stopping_scorer(\n                         X_binned_small_train, y_small_train,\n                         X_binned_val, y_val,\n\nFrom 1e5a5cf9f4434abeea32535322ee01f7fc820add Mon Sep 17 00:00:00 2001\nFrom: Guillaume Lemaitre <g.lemaitre58@gmail.com>\nDate: Thu, 22 Aug 2019 10:25:28 +0200\nSubject: [PATCH 3/3] reviews\n\n---\n doc/whats_new/v0.22.rst                                   | 3 +--\n .../ensemble/_hist_gradient_boosting/gradient_boosting.py | 4 ++--\n .../tests/test_gradient_boosting.py                       | 8 +++++---\n 3 files changed, 8 insertions(+), 7 deletions(-)\n\ndiff --git a/doc/whats_new/v0.22.rst b/doc/whats_new/v0.22.rst\nindex e6185949ffd87..770b48b0cb69a 100644\n--- a/doc/whats_new/v0.22.rst\n+++ b/doc/whats_new/v0.22.rst\n@@ -132,8 +132,7 @@ Changelog\n     method for both estimators. :pr:`13769` by `Nicolas Hug`_.\n   - |Fix| Estimators now bin the training and validation data separately to\n     avoid any data leak. :pr:`13933` by `Nicolas Hug`_.\n-  - |Fix| Targets are encoded before to compute score when using early stopping\n-    to avoid inconsistent target data types.\n+  - |Fix| Fixed a bug where early stopping would break with string targets.\n     :pr:`14710` by :user:`Guillaume Lemaitre <glemaitre>`.\n \n   Note that pickles from 0.21 will not work in 0.22.\ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\nindex 3170e4000ecc5..70a507d09c1c6 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py\n@@ -426,14 +426,14 @@ def _check_early_stopping_scorer(self, X_binned_small_train, y_small_train,\n \n         Scores are computed on validation data or on training data.\n         \"\"\"\n-        if hasattr(self, 'classes_'):\n+        if is_classifier(self):\n             y_small_train = self.classes_[y_small_train.astype(int)]\n         self.train_score_.append(\n             self.scorer_(self, X_binned_small_train, y_small_train)\n         )\n \n         if self._use_validation_data:\n-            if hasattr(self, 'classes_'):\n+            if is_classifier(self):\n                 y_val = self.classes_[y_val.astype(int)]\n             self.validation_score_.append(\n                 self.scorer_(self, X_binned_val, y_val)\ndiff --git a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\nindex 86dcb582a23a0..5de49ef740295 100644\n--- a/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n+++ b/sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n@@ -417,10 +417,12 @@ def test_infinite_values_missing_values():\n     assert stump_clf.fit(X, y_isnan).score(X, y_isnan) == 1\n \n \n-def test_string_target_early_stopping():\n+@pytest.mark.parametrize(\"scoring\", [None, 'loss'])\n+def test_string_target_early_stopping(scoring):\n     # Regression tests for #14709 where the targets need to be encoded before\n     # to compute the score\n-    X = np.random.randn(100, 10)\n+    rng = np.random.RandomState(42)\n+    X = rng.randn(100, 10)\n     y = np.array(['x'] * 50 + ['y'] * 50, dtype=object)\n-    gbrt = HistGradientBoostingClassifier(n_iter_no_change=10)\n+    gbrt = HistGradientBoostingClassifier(n_iter_no_change=10, scoring=scoring)\n     gbrt.fit(X, y)\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/14710"}