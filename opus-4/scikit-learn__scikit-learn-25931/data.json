{"instance_id": "scikit-learn__scikit-learn-25931", "score": "C", "diff": "diff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex 4d6c1c3f0..4a3b03f83 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -345,7 +345,10 @@ class IsolationForest(OutlierMixin, BaseBagging):\n             return self\n \n         # else, define offset_ wrt contamination parameter\n-        self.offset_ = np.percentile(self.score_samples(X), 100.0 * self.contamination)\n+        # Directly use _compute_chunked_score_samples to avoid re-validating X\n+        # since it was already validated at the beginning of fit()\n+        scores = -self._compute_chunked_score_samples(X)\n+        self.offset_ = np.percentile(scores, 100.0 * self.contamination)\n \n         return self\n \ndiff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex 5f046540f..da2d7eeb0 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -326,6 +326,39 @@ def test_iforest_with_n_jobs_does_not_segfault():\n     IsolationForest(n_estimators=10, max_samples=256, n_jobs=2).fit(X)\n \n \n+def test_iforest_dataframe_without_feature_warning():\n+    \"\"\"Test that IsolationForest does not warn when fitted with a DataFrame\n+    and contamination != 'auto'.\n+    \n+    Non-regression test for issue where fitting with a DataFrame and \n+    contamination != 'auto' would generate a warning about feature names.\n+    \"\"\"\n+    pd = pytest.importorskip(\"pandas\")\n+    \n+    # Test with DataFrame and contamination != \"auto\" - should not raise warning\n+    X_df = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\n+    \n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"error\", UserWarning)\n+        # This should not raise any warning\n+        clf = IsolationForest(random_state=0, contamination=0.05).fit(X_df)\n+        \n+    # Also test with multi-feature DataFrame\n+    X_multi = pd.DataFrame({\n+        \"feature1\": [1, 2, 3, 4, 5, 100],\n+        \"feature2\": [1, 2, 3, 4, 5, 100],\n+        \"feature3\": [1, 2, 3, 4, 5, 100]\n+    })\n+    \n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"error\", UserWarning)\n+        # This should not raise any warning\n+        clf = IsolationForest(random_state=0, contamination=0.1).fit(X_multi)\n+    \n+    # Make sure model still works correctly\n+    assert clf.predict([[1, 1, 1]]).shape == (1,)\n+\n+\n # TODO(1.4): remove in 1.4\n def test_base_estimator_property_deprecated():\n     X = np.array([[1, 2], [3, 4]])\ndiff --git a/test_comprehensive.py b/test_comprehensive.py\nnew file mode 100644\nindex 000000000..2031ebad0\n--- /dev/null\n+++ b/test_comprehensive.py\n@@ -0,0 +1,77 @@\n+from sklearn.ensemble import IsolationForest\n+import pandas as pd\n+import numpy as np\n+import warnings\n+\n+# Test 1: Original issue - DataFrame with contamination != \"auto\" should not raise warning\n+print(\"Test 1: DataFrame with contamination=0.05\")\n+with warnings.catch_warnings(record=True) as w:\n+    warnings.simplefilter(\"always\")\n+    X_df = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\n+    clf1 = IsolationForest(random_state=0, contamination=0.05).fit(X_df)\n+    \n+    if w:\n+        for warning in w:\n+            print(f\"  Warning: {warning.message}\")\n+    else:\n+        print(\"  No warnings - PASS\")\n+\n+# Test 2: DataFrame with contamination=\"auto\" should not raise warning\n+print(\"\\nTest 2: DataFrame with contamination='auto'\")\n+with warnings.catch_warnings(record=True) as w:\n+    warnings.simplefilter(\"always\")\n+    X_df = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\n+    clf2 = IsolationForest(random_state=0, contamination=\"auto\").fit(X_df)\n+    \n+    if w:\n+        for warning in w:\n+            print(f\"  Warning: {warning.message}\")\n+    else:\n+        print(\"  No warnings - PASS\")\n+\n+# Test 3: Numpy array should work fine\n+print(\"\\nTest 3: Numpy array with contamination=0.05\")\n+with warnings.catch_warnings(record=True) as w:\n+    warnings.simplefilter(\"always\")\n+    X_np = np.array([[-1.1], [0.3], [0.5], [100]])\n+    clf3 = IsolationForest(random_state=0, contamination=0.05).fit(X_np)\n+    \n+    if w:\n+        for warning in w:\n+            print(f\"  Warning: {warning.message}\")\n+    else:\n+        print(\"  No warnings - PASS\")\n+\n+# Test 4: Check that predictions are consistent\n+print(\"\\nTest 4: Check predictions are consistent\")\n+X_test = np.array([[0.5], [10], [-5], [100]])\n+pred1 = clf1.predict(X_test)\n+pred3 = clf3.predict(X_test)\n+print(f\"  Predictions with DataFrame: {pred1}\")\n+print(f\"  Predictions with NumPy:     {pred3}\")\n+print(f\"  Predictions match: {np.array_equal(pred1, pred3)} - {'PASS' if np.array_equal(pred1, pred3) else 'FAIL'}\")\n+\n+# Test 5: Check scores are computed correctly\n+print(\"\\nTest 5: Check decision function values\")\n+scores1 = clf1.decision_function(X_test)\n+scores3 = clf3.decision_function(X_test)\n+print(f\"  Scores with DataFrame: {scores1}\")\n+print(f\"  Scores with NumPy:     {scores3}\")\n+print(f\"  Scores match: {np.allclose(scores1, scores3)} - {'PASS' if np.allclose(scores1, scores3) else 'FAIL'}\")\n+\n+# Test 6: Multi-feature test\n+print(\"\\nTest 6: Multi-feature DataFrame with contamination=0.1\")\n+with warnings.catch_warnings(record=True) as w:\n+    warnings.simplefilter(\"always\")\n+    X_multi = pd.DataFrame({\n+        \"feature1\": [1, 2, 3, 4, 5, 100],\n+        \"feature2\": [1, 2, 3, 4, 5, 100],\n+        \"feature3\": [1, 2, 3, 4, 5, 100]\n+    })\n+    clf_multi = IsolationForest(random_state=0, contamination=0.1).fit(X_multi)\n+    \n+    if w:\n+        for warning in w:\n+            print(f\"  Warning: {warning.message}\")\n+    else:\n+        print(\"  No warnings - PASS\")\ndiff --git a/test_issue_auto.py b/test_issue_auto.py\nnew file mode 100644\nindex 000000000..da9903fc5\n--- /dev/null\n+++ b/test_issue_auto.py\n@@ -0,0 +1,16 @@\n+from sklearn.ensemble import IsolationForest\n+import pandas as pd\n+import warnings\n+\n+# Test with contamination=\"auto\" - should not raise warning\n+with warnings.catch_warnings(record=True) as w:\n+    warnings.simplefilter(\"always\")\n+    \n+    X = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\n+    clf = IsolationForest(random_state=0, contamination=\"auto\").fit(X)\n+    \n+    if w:\n+        for warning in w:\n+            print(f\"Warning: {warning.message}\")\n+    else:\n+        print(\"No warnings!\")\ndiff --git a/test_issue_reproduction.py b/test_issue_reproduction.py\nnew file mode 100644\nindex 000000000..b9c35654f\n--- /dev/null\n+++ b/test_issue_reproduction.py\n@@ -0,0 +1,16 @@\n+from sklearn.ensemble import IsolationForest\n+import pandas as pd\n+import warnings\n+\n+# Catch warnings to see them\n+with warnings.catch_warnings(record=True) as w:\n+    warnings.simplefilter(\"always\")\n+    \n+    X = pd.DataFrame({\"a\": [-1.1, 0.3, 0.5, 100]})\n+    clf = IsolationForest(random_state=0, contamination=0.05).fit(X)\n+    \n+    if w:\n+        for warning in w:\n+            print(f\"Warning: {warning.message}\")\n+    else:\n+        print(\"No warnings!\")\n", "gold_standard_diff": "From 07a2beee79475e3aaa9160378f1e595f306ebbd6 Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Wed, 22 Mar 2023 07:10:13 +0800\nSubject: [PATCH 1/5] added non-regression test for whether feature names are\n preserved by IsolationForest when contamination is not \"auto\"\n\n---\n sklearn/ensemble/tests/test_iforest.py | 17 +++++++++++++++++\n 1 file changed, 17 insertions(+)\n\ndiff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex 5f046540fffdc..e9fa1c954b018 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -339,3 +339,20 @@ def test_base_estimator_property_deprecated():\n     )\n     with pytest.warns(FutureWarning, match=warn_msg):\n         model.base_estimator_\n+    \n+def test_iforest_preserve_feature_names():\n+    \"\"\"Check that feature names are preserved when contamination is not \"auto\".\n+\n+    Feature names are required for consistency checks during scoring.\n+    \n+    Non-regression test for Issue #25844\n+    \"\"\"\n+    pd = pytest.importorskip(\"pandas\")\n+    rng = np.random.RandomState(0)\n+\n+    X = pd.DataFrame(data=rng.randn(4), columns=[\"a\"])\n+    model = IsolationForest(random_state=0, contamination=0.05)\n+\n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"error\", UserWarning)\n+        model.fit(X)\n\nFrom 13ab33dc76fcce3fa604ff088d33162ecdb8acfa Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Wed, 22 Mar 2023 08:10:20 +0800\nSubject: [PATCH 2/5] Fixed \"IsolationForest removes features when called with\n contamination not 'auto'\" Also see Issue #25844, now does not generate\n warnings\n\n---\n sklearn/ensemble/_iforest.py | 24 ++++++++++++++++--------\n 1 file changed, 16 insertions(+), 8 deletions(-)\n\ndiff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex 4d6c1c3f0b7f9..d7d2707b953d9 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -344,8 +344,10 @@ def fit(self, X, y=None, sample_weight=None):\n             self.offset_ = -0.5\n             return self\n \n-        # else, define offset_ wrt contamination parameter\n-        self.offset_ = np.percentile(self.score_samples(X), 100.0 * self.contamination)\n+        # Else, define offset_ wrt contamination parameter\n+        # Input validation would remove feature names, so we call private version\n+        # of score_sample that does not perform input validation\n+        self.offset_ = np.percentile(self._score_samples(X), 100.0 * self.contamination)\n \n         return self\n \n@@ -428,15 +430,21 @@ def score_samples(self, X):\n             The anomaly score of the input samples.\n             The lower, the more abnormal.\n         \"\"\"\n-        # code structure from ForestClassifier/predict_proba\n-\n-        check_is_fitted(self)\n-\n         # Check data\n         X = self._validate_data(X, accept_sparse=\"csr\", dtype=np.float32, reset=False)\n \n-        # Take the opposite of the scores as bigger is better (here less\n-        # abnormal)\n+        return self._score_samples(X)\n+    \n+    def _score_samples(self, X):\n+        \"\"\"Private version of score_samples without input validation.\n+        \n+        Input validation would remove feature names, so we disable it.\n+        \"\"\"\n+        # Code structure from ForestClassifier/predict_proba\n+\n+        check_is_fitted(self)\n+\n+        # Take the opposite of the scores as bigger is better (here less abnormal)\n         return -self._compute_chunked_score_samples(X)\n \n     def _compute_chunked_score_samples(self, X):\n\nFrom b630df0c3e287122be3217835bdc61722be0bb46 Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Wed, 22 Mar 2023 08:54:25 +0800\nSubject: [PATCH 3/5] added an entry to the changelog at v1.3.rst\n\n---\n doc/whats_new/v1.3.rst | 4 ++++\n 1 file changed, 4 insertions(+)\n\ndiff --git a/doc/whats_new/v1.3.rst b/doc/whats_new/v1.3.rst\nindex dac97146be221..87d42e1d79b44 100644\n--- a/doc/whats_new/v1.3.rst\n+++ b/doc/whats_new/v1.3.rst\n@@ -232,6 +232,10 @@ Changelog\n   when `max_samples` is a float and `round(n_samples * max_samples) < 1`.\n   :pr:`25601` by :user:`Jan Fidor <JanFidor>`.\n \n+- |Fix| :meth:`ensemble.IsolationForest.fit` no longer removes feature names\n+  or gives warnings when called with `contamination` not `\"auto\"`.\n+  :pr:`25931` by :user:`Yao Xiao <Charlie-XIAO>`.\n+\n :mod:`sklearn.exception`\n ........................\n - |Feature| Added :class:`exception.InconsistentVersionWarning` which is raised\n\nFrom 171fff5a976e0fa78f67b74aa82818d28ba34c2a Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Wed, 22 Mar 2023 09:04:16 +0800\nSubject: [PATCH 4/5] code style check, removed some leading spaces\n\n---\n sklearn/ensemble/_iforest.py           | 4 ++--\n sklearn/ensemble/tests/test_iforest.py | 5 +++--\n 2 files changed, 5 insertions(+), 4 deletions(-)\n\ndiff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex d7d2707b953d9..8858308c46988 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -434,10 +434,10 @@ def score_samples(self, X):\n         X = self._validate_data(X, accept_sparse=\"csr\", dtype=np.float32, reset=False)\n \n         return self._score_samples(X)\n-    \n+\n     def _score_samples(self, X):\n         \"\"\"Private version of score_samples without input validation.\n-        \n+\n         Input validation would remove feature names, so we disable it.\n         \"\"\"\n         # Code structure from ForestClassifier/predict_proba\ndiff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\nindex e9fa1c954b018..7650dd5c14ce4 100644\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -339,12 +339,13 @@ def test_base_estimator_property_deprecated():\n     )\n     with pytest.warns(FutureWarning, match=warn_msg):\n         model.base_estimator_\n-    \n+\n+\n def test_iforest_preserve_feature_names():\n     \"\"\"Check that feature names are preserved when contamination is not \"auto\".\n \n     Feature names are required for consistency checks during scoring.\n-    \n+\n     Non-regression test for Issue #25844\n     \"\"\"\n     pd = pytest.importorskip(\"pandas\")\n\nFrom f4eace5c5364aa3bb6e7b6eede03c3d78955aa49 Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Wed, 22 Mar 2023 20:18:53 +0800\nSubject: [PATCH 5/5] adopted changes @ogrisel @lesteve, resolved conversations\n\n---\n doc/whats_new/v1.3.rst       | 5 +++--\n sklearn/ensemble/_iforest.py | 4 ++--\n 2 files changed, 5 insertions(+), 4 deletions(-)\n\ndiff --git a/doc/whats_new/v1.3.rst b/doc/whats_new/v1.3.rst\nindex 87d42e1d79b44..99cbaadf9b76a 100644\n--- a/doc/whats_new/v1.3.rst\n+++ b/doc/whats_new/v1.3.rst\n@@ -232,8 +232,9 @@ Changelog\n   when `max_samples` is a float and `round(n_samples * max_samples) < 1`.\n   :pr:`25601` by :user:`Jan Fidor <JanFidor>`.\n \n-- |Fix| :meth:`ensemble.IsolationForest.fit` no longer removes feature names\n-  or gives warnings when called with `contamination` not `\"auto\"`.\n+- |Fix| :meth:`ensemble.IsolationForest.fit` no longer warns about missing\n+  feature names when called with `contamination` not `\"auto\"` on a pandas\n+  dataframe.\n   :pr:`25931` by :user:`Yao Xiao <Charlie-XIAO>`.\n \n :mod:`sklearn.exception`\ndiff --git a/sklearn/ensemble/_iforest.py b/sklearn/ensemble/_iforest.py\nindex 8858308c46988..cc0f3cf09dee7 100644\n--- a/sklearn/ensemble/_iforest.py\n+++ b/sklearn/ensemble/_iforest.py\n@@ -345,8 +345,8 @@ def fit(self, X, y=None, sample_weight=None):\n             return self\n \n         # Else, define offset_ wrt contamination parameter\n-        # Input validation would remove feature names, so we call private version\n-        # of score_sample that does not perform input validation\n+        # To avoid performing input validation a second time we call\n+        # _score_samples rather than score_samples\n         self.offset_ = np.percentile(self._score_samples(X), 100.0 * self.contamination)\n \n         return self\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/25931"}