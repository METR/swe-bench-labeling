{"instance_id": "pydata__xarray-4356", "score": "C", "diff": "diff --git a/debug_mincount.py b/debug_mincount.py\nnew file mode 100644\nindex 00000000..32d7d4fd\n--- /dev/null\n+++ b/debug_mincount.py\n@@ -0,0 +1,21 @@\n+import numpy as np\n+import xarray as xr\n+\n+# Let's trace through what's happening\n+da = xr.DataArray([[np.nan, np.nan], [np.nan, np.nan]])\n+print(\"All NaN array:\")\n+print(da.values)\n+\n+# The issue might be that when we sum all NaN values, numpy returns 0.0\n+# Let's check the mask\n+mask = np.isnan(da.values)\n+print(\"\\nMask (True = NaN):\")\n+print(mask)\n+\n+print(\"\\nSum of mask along axes (0,1):\", mask.sum((0,1)))\n+print(\"Total size along axes (0,1):\", np.take(mask.shape, (0,1)).prod())\n+print(\"Valid count:\", np.take(mask.shape, (0,1)).prod() - mask.sum((0,1)))\n+\n+# When doing sum with all NaN, what happens?\n+print(\"\\nNumPy sum of all NaN:\", np.sum(da.values))\n+print(\"NumPy nansum of all NaN:\", np.nansum(da.values))\ndiff --git a/debug_scalar.py b/debug_scalar.py\nnew file mode 100644\nindex 00000000..5ad9eadd\n--- /dev/null\n+++ b/debug_scalar.py\n@@ -0,0 +1,14 @@\n+import numpy as np\n+\n+# Test scalar result\n+result = np.array(0.0)  # This is what nansum returns for all NaN\n+print(\"Result:\", result)\n+print(\"Result type:\", type(result))\n+print(\"Result ndim:\", getattr(result, \"ndim\", False))\n+print(\"Is ndim > 0?\", getattr(result, \"ndim\", False))\n+\n+# numpy scalars have ndim = 0\n+print(\"\\nFor a numpy scalar:\")\n+scalar = np.float64(0.0)\n+print(\"Scalar ndim:\", scalar.ndim)\n+print(\"Scalar ndim bool:\", bool(scalar.ndim))\ndiff --git a/test_branch_flow.py b/test_branch_flow.py\nnew file mode 100644\nindex 00000000..d263fbb9\n--- /dev/null\n+++ b/test_branch_flow.py\n@@ -0,0 +1,40 @@\n+import numpy as np\n+from xarray.core import dtypes\n+\n+# Simulate the flow in _maybe_null_out\n+result = np.float64(0.0)  # scalar result\n+axis = (0, 1)  # multiple axes\n+mask = np.array([[True, True], [True, True]])  # all NaN\n+\n+print(\"Inputs:\")\n+print(f\"  result: {result}, type: {type(result)}\")\n+print(f\"  result.ndim: {result.ndim}\")\n+print(f\"  axis: {axis}\")\n+print(f\"  mask shape: {mask.shape}\")\n+print(f\"  mask sum: {mask.sum()}\")\n+\n+# First condition\n+first_cond = axis is not None and getattr(result, \"ndim\", False)\n+print(f\"\\nFirst condition (axis is not None and getattr(result, 'ndim', False)): {first_cond}\")\n+print(f\"  axis is not None: {axis is not None}\")\n+print(f\"  getattr(result, 'ndim', False): {getattr(result, 'ndim', False)}\")\n+print(f\"  result.ndim (actual): {result.ndim}\")\n+\n+# Since first condition is False (because ndim=0), go to elif\n+elif_cond = getattr(result, \"dtype\", None) not in dtypes.NAT_TYPES\n+print(f\"\\nElif condition (getattr(result, 'dtype', None) not in dtypes.NAT_TYPES): {elif_cond}\")\n+print(f\"  result.dtype: {result.dtype}\")\n+print(f\"  result.dtype in dtypes.NAT_TYPES: {result.dtype in dtypes.NAT_TYPES}\")\n+\n+# Inside elif block\n+if elif_cond:\n+    null_mask = mask.size - mask.sum()\n+    print(f\"\\nInside elif block:\")\n+    print(f\"  mask.size: {mask.size}\")\n+    print(f\"  mask.sum(): {mask.sum()}\")\n+    print(f\"  null_mask (valid count): {null_mask}\")\n+    print(f\"  min_count: 1\")\n+    print(f\"  null_mask < min_count: {null_mask < 1}\")\n+    \n+    if null_mask < 1:\n+        print(\"  Should set result = np.nan\")\ndiff --git a/test_detailed.py b/test_detailed.py\nnew file mode 100644\nindex 00000000..ca993539\n--- /dev/null\n+++ b/test_detailed.py\n@@ -0,0 +1,33 @@\n+import numpy as np\n+import xarray as xr\n+\n+# Test with NaN values\n+print(\"Test 1: Array with some NaN values\")\n+da = xr.DataArray([[1., 2, np.nan], [4, np.nan, 6]])\n+print(\"DataArray:\")\n+print(da)\n+print()\n+\n+# Sum along single dimension with min_count\n+print(\"Sum along dim_0 with min_count=1:\")\n+result = da.sum(\"dim_0\", min_count=1)\n+print(result)\n+print()\n+\n+print(\"Sum along dim_0 with min_count=2:\")\n+result = da.sum(\"dim_0\", min_count=2)\n+print(result)\n+print()\n+\n+# What we want to work: sum along multiple dimensions\n+print(\"Attempting sum along both dimensions with min_count=1:\")\n+try:\n+    result = da.sum([\"dim_0\", \"dim_1\"], min_count=1)\n+    print(result)\n+except ValueError as e:\n+    print(f\"Error: {e}\")\n+print()\n+\n+# Expected behavior: If there are at least min_count non-NaN values across all specified dimensions,\n+# return the sum. Otherwise, return NaN.\n+# In this case, we have 4 non-NaN values out of 6 total, so with min_count=1, it should return 13.0\ndiff --git a/test_dtype_check.py b/test_dtype_check.py\nnew file mode 100644\nindex 00000000..d45a7e79\n--- /dev/null\n+++ b/test_dtype_check.py\n@@ -0,0 +1,17 @@\n+import numpy as np\n+from xarray.core import dtypes\n+\n+result = np.float64(0.0)\n+print(\"Result:\", result)\n+print(\"Result dtype:\", result.dtype)\n+print(\"NAT_TYPES:\", dtypes.NAT_TYPES)\n+print(\"Is dtype in NAT_TYPES?\", result.dtype in dtypes.NAT_TYPES)\n+print(\"Check individual items:\")\n+for nat_type in dtypes.NAT_TYPES:\n+    print(f\"  {nat_type} == {result.dtype}: {nat_type == result.dtype}\")\n+\n+# I think the issue is with the comparison\n+print(\"\\nActual NAT dtypes:\")\n+for nat_type in dtypes.NAT_TYPES:\n+    print(f\"  Type: {type(nat_type)}, dtype: {nat_type.dtype if hasattr(nat_type, 'dtype') else 'N/A'}\")\n+print(\"Condition check:\", getattr(result, \"dtype\", None) not in dtypes.NAT_TYPES)\ndiff --git a/test_edge_cases.py b/test_edge_cases.py\nnew file mode 100644\nindex 00000000..9d5f9e8a\n--- /dev/null\n+++ b/test_edge_cases.py\n@@ -0,0 +1,51 @@\n+import numpy as np\n+import xarray as xr\n+\n+print(\"=== Test 1: All NaN array ===\")\n+da = xr.DataArray([[np.nan, np.nan], [np.nan, np.nan]])\n+print(\"DataArray:\", da.values)\n+result = da.sum([\"dim_0\", \"dim_1\"], min_count=1)\n+print(\"Sum with min_count=1:\", result.values)\n+print(\"Expected: nan (no valid values)\")\n+print()\n+\n+print(\"=== Test 2: Array with exactly min_count valid values ===\")\n+da = xr.DataArray([[1., np.nan], [np.nan, np.nan]])\n+print(\"DataArray:\", da.values)\n+result = da.sum([\"dim_0\", \"dim_1\"], min_count=1)\n+print(\"Sum with min_count=1:\", result.values)\n+print(\"Expected: 1.0 (exactly 1 valid value)\")\n+print()\n+\n+print(\"=== Test 3: Array with min_count > valid values ===\")\n+da = xr.DataArray([[1., 2.], [np.nan, np.nan]])\n+print(\"DataArray:\", da.values)\n+result = da.sum([\"dim_0\", \"dim_1\"], min_count=3)\n+print(\"Sum with min_count=3:\", result.values)\n+print(\"Expected: nan (only 2 valid values, need 3)\")\n+print()\n+\n+print(\"=== Test 4: 3D array with multiple axes ===\")\n+da = xr.DataArray([[[1., 2.], [3., np.nan]], [[5., np.nan], [np.nan, np.nan]]])\n+print(\"DataArray shape:\", da.shape)\n+print(\"Sum of non-NaN values:\", 1 + 2 + 3 + 5)\n+result = da.sum([\"dim_1\", \"dim_2\"], min_count=1)\n+print(\"Sum along dim_1 and dim_2 with min_count=1:\")\n+print(result.values)\n+print(\"Expected: [6., 5.] (sum along last two dims)\")\n+print()\n+\n+print(\"=== Test 5: Test with prod (nanprod) ===\") \n+da = xr.DataArray([[1., 2., np.nan], [4., np.nan, 6.]])\n+print(\"DataArray:\", da.values)\n+result = da.prod([\"dim_0\", \"dim_1\"], min_count=1)\n+print(\"Product with min_count=1:\", result.values)\n+print(\"Expected: 48.0 (1*2*4*6)\")\n+print()\n+\n+print(\"=== Test 6: Single axis (regression test) ===\")\n+da = xr.DataArray([[1., 2., np.nan], [4., np.nan, 6.]])\n+result = da.sum(\"dim_0\", min_count=1)\n+print(\"Sum along single axis with min_count=1:\")\n+print(result.values)\n+print(\"Expected: [5., 2., 6.]\")\ndiff --git a/test_issue.py b/test_issue.py\nnew file mode 100644\nindex 00000000..b0b9b05e\n--- /dev/null\n+++ b/test_issue.py\n@@ -0,0 +1,17 @@\n+import xarray as xr\n+import numpy as np\n+\n+# Test case from the issue\n+da = xr.DataArray([[1., 2, 3], [4, 5, 6]])\n+print(\"DataArray:\")\n+print(da)\n+print()\n+\n+# This should fail with the current implementation\n+try:\n+    result = da.sum([\"dim_0\", \"dim_1\"], min_count=1)\n+    print(\"Sum with min_count=1 on multiple dims:\")\n+    print(result)\n+except ValueError as e:\n+    print(f\"Error: {e}\")\n+    print(\"This is expected with the current implementation\")\ndiff --git a/test_nat_comparison.py b/test_nat_comparison.py\nnew file mode 100644\nindex 00000000..621b4d99\n--- /dev/null\n+++ b/test_nat_comparison.py\n@@ -0,0 +1,26 @@\n+import numpy as np\n+\n+# The issue is NAT_TYPES contains scalar values, not dtypes\n+nat1 = np.datetime64(\"NaT\")\n+nat2 = np.timedelta64(\"NaT\")\n+\n+print(\"NAT values:\")\n+print(f\"  nat1: {nat1}, type: {type(nat1)}\")\n+print(f\"  nat2: {nat2}, type: {type(nat2)}\")\n+\n+# When we do dtype in (nat1, nat2), it's comparing a dtype object to scalar values\n+dtype = np.dtype('float64')\n+print(f\"\\ndtype: {dtype}\")\n+print(f\"dtype in (nat1, nat2): {dtype in (nat1, nat2)}\")\n+\n+# The bug seems to be that numpy scalars have weird behavior with `in`\n+# Let's see what happens\n+print(f\"\\nWeird comparison behavior:\")\n+print(f\"nat1 == dtype: {nat1 == dtype}\")\n+print(f\"dtype == nat1: {dtype == nat1}\")\n+\n+# The real check should be comparing dtype to the dtype of NAT values\n+print(f\"\\nCorrect comparison:\")\n+print(f\"nat1.dtype: {nat1.dtype}\")\n+print(f\"nat2.dtype: {nat2.dtype}\")\n+print(f\"dtype in (nat1.dtype, nat2.dtype): {dtype in (nat1.dtype, nat2.dtype)}\")\ndiff --git a/test_understanding.py b/test_understanding.py\nnew file mode 100644\nindex 00000000..05af807e\n--- /dev/null\n+++ b/test_understanding.py\n@@ -0,0 +1,19 @@\n+import numpy as np\n+\n+# Let's understand what the fix should do\n+a = np.array([[1., 2, 3], [4, 5, 6]])\n+axis = (0, 1)  # Multiple dimensions\n+\n+print(\"Array shape:\", a.shape)\n+print(\"Axis:\", axis)\n+\n+# Current logic would use mask.shape[axis] but axis is a tuple, so it fails\n+# Instead, we need to get the product of sizes along the specified axes\n+\n+# Using np.take to get the shapes at the specified axes\n+shapes_at_axes = np.take(a.shape, axis)\n+print(\"Shapes at axes:\", shapes_at_axes)\n+print(\"Product of shapes:\", shapes_at_axes.prod())\n+\n+# This should give us the total number of elements along the specified axes\n+# For our 2x3 array with axis=(0,1), that's 2*3 = 6 elements total\ndiff --git a/trace_mincount.py b/trace_mincount.py\nnew file mode 100644\nindex 00000000..19ab8621\n--- /dev/null\n+++ b/trace_mincount.py\n@@ -0,0 +1,38 @@\n+import numpy as np\n+import xarray as xr\n+\n+# Directly test the _maybe_null_out function\n+from xarray.core.nanops import _maybe_null_out, _replace_nan\n+\n+# Case 1: All NaN\n+print(\"=== Case 1: All NaN ===\")\n+a = np.array([[np.nan, np.nan], [np.nan, np.nan]])\n+a_replaced, mask = _replace_nan(a, 0)\n+print(\"Original array:\", a)\n+print(\"Replaced array:\", a_replaced)\n+print(\"Mask:\", mask)\n+\n+# Simulate what happens in nansum\n+result = np.sum(a_replaced, axis=(0,1))  # This gives 0.0\n+print(\"Sum result:\", result)\n+print(\"Result type:\", type(result))\n+print(\"Result dtype:\", result.dtype)\n+print(\"Result ndim:\", result.ndim)\n+\n+# Now call _maybe_null_out\n+final_result = _maybe_null_out(result, axis=(0,1), mask=mask, min_count=1)\n+print(\"Final result after _maybe_null_out:\", final_result)\n+print()\n+\n+# Case 2: Insufficient valid values\n+print(\"=== Case 2: Insufficient valid values ===\")\n+a = np.array([[1., 2.], [np.nan, np.nan]])\n+a_replaced, mask = _replace_nan(a, 0)\n+print(\"Original array:\", a)\n+print(\"Mask:\", mask)\n+\n+result = np.sum(a_replaced, axis=(0,1))  # This gives 3.0\n+print(\"Sum result:\", result)\n+\n+final_result = _maybe_null_out(result, axis=(0,1), mask=mask, min_count=3)\n+print(\"Final result with min_count=3:\", final_result)\ndiff --git a/xarray/core/nanops.py b/xarray/core/nanops.py\nindex 41c8d258..1bf4d520 100644\n--- a/xarray/core/nanops.py\n+++ b/xarray/core/nanops.py\n@@ -26,19 +26,21 @@ def _maybe_null_out(result, axis, mask, min_count=1):\n     \"\"\"\n     xarray version of pandas.core.nanops._maybe_null_out\n     \"\"\"\n-    if hasattr(axis, \"__len__\"):  # if tuple or list\n-        raise ValueError(\n-            \"min_count is not available for reduction with more than one dimensions.\"\n-        )\n-\n     if axis is not None and getattr(result, \"ndim\", False):\n-        null_mask = (mask.shape[axis] - mask.sum(axis) - min_count) < 0\n+        # Handle single axis or multiple axes\n+        if hasattr(axis, \"__len__\"):  # if tuple or list (multiple axes)\n+            # For multiple axes, we need the product of sizes along those axes\n+            total_size = np.take(mask.shape, axis).prod()\n+            null_mask = (total_size - mask.sum(axis) - min_count) < 0\n+        else:  # single axis\n+            null_mask = (mask.shape[axis] - mask.sum(axis) - min_count) < 0\n+            \n         if null_mask.any():\n             dtype, fill_value = dtypes.maybe_promote(result.dtype)\n             result = result.astype(dtype)\n             result[null_mask] = fill_value\n \n-    elif getattr(result, \"dtype\", None) not in dtypes.NAT_TYPES:\n+    elif not dtypes.is_datetime_like(getattr(result, \"dtype\", np.dtype(\"O\"))):\n         null_mask = mask.size - mask.sum()\n         if null_mask < min_count:\n             result = np.nan\n", "gold_standard_diff": "From 94b5d13a8e7bb88e883b8a6e8ae0328f3b580f34 Mon Sep 17 00:00:00 2001\nFrom: Maximilian Roos <m@maxroos.com>\nDate: Wed, 19 Aug 2020 16:47:33 -0700\nSubject: [PATCH 1/2] Allow multiple dims to be passed with min_count\n\n---\n xarray/core/nanops.py               |  6 +-----\n xarray/tests/test_duck_array_ops.py | 25 ++++++++++++++++++++++---\n 2 files changed, 23 insertions(+), 8 deletions(-)\n\ndiff --git a/xarray/core/nanops.py b/xarray/core/nanops.py\nindex 41c8d258d7a..bc7dc510817 100644\n--- a/xarray/core/nanops.py\n+++ b/xarray/core/nanops.py\n@@ -26,13 +26,9 @@ def _maybe_null_out(result, axis, mask, min_count=1):\n     \"\"\"\n     xarray version of pandas.core.nanops._maybe_null_out\n     \"\"\"\n-    if hasattr(axis, \"__len__\"):  # if tuple or list\n-        raise ValueError(\n-            \"min_count is not available for reduction with more than one dimensions.\"\n-        )\n \n     if axis is not None and getattr(result, \"ndim\", False):\n-        null_mask = (mask.shape[axis] - mask.sum(axis) - min_count) < 0\n+        null_mask = (np.take(mask.shape, axis).prod() - mask.sum(axis) - min_count) < 0\n         if null_mask.any():\n             dtype, fill_value = dtypes.maybe_promote(result.dtype)\n             result = result.astype(dtype)\ndiff --git a/xarray/tests/test_duck_array_ops.py b/xarray/tests/test_duck_array_ops.py\nindex b542dad998b..6db0b6eef87 100644\n--- a/xarray/tests/test_duck_array_ops.py\n+++ b/xarray/tests/test_duck_array_ops.py\n@@ -595,6 +595,24 @@ def test_min_count(dim_num, dtype, dask, func, aggdim):\n     assert_dask_array(actual, dask)\n \n \n+@pytest.mark.parametrize(\"dtype\", [float, int, np.float32, np.bool_])\n+@pytest.mark.parametrize(\"dask\", [False, True])\n+@pytest.mark.parametrize(\"func\", [\"sum\", \"prod\"])\n+def test_min_count_nd(dtype, dask, func):\n+    if dask and not has_dask:\n+        pytest.skip(\"requires dask\")\n+\n+    min_count = 3\n+    dim_num = 3\n+    da = construct_dataarray(dim_num, dtype, contains_nan=True, dask=dask)\n+    actual = getattr(da, func)(dim=[\"x\", \"y\", \"z\"], skipna=True, min_count=min_count)\n+    # Supplying all dims is equivalent to supplying `...` or `None`\n+    expected = getattr(da, func)(dim=..., skipna=True, min_count=min_count)\n+\n+    assert_allclose(actual, expected)\n+    assert_dask_array(actual, dask)\n+\n+\n @pytest.mark.parametrize(\"func\", [\"sum\", \"prod\"])\n def test_min_count_dataset(func):\n     da = construct_dataarray(2, dtype=float, contains_nan=True, dask=False)\n@@ -606,14 +624,15 @@ def test_min_count_dataset(func):\n \n @pytest.mark.parametrize(\"dtype\", [float, int, np.float32, np.bool_])\n @pytest.mark.parametrize(\"dask\", [False, True])\n+@pytest.mark.parametrize(\"skipna\", [False, True])\n @pytest.mark.parametrize(\"func\", [\"sum\", \"prod\"])\n-def test_multiple_dims(dtype, dask, func):\n+def test_multiple_dims(dtype, dask, skipna, func):\n     if dask and not has_dask:\n         pytest.skip(\"requires dask\")\n     da = construct_dataarray(3, dtype, contains_nan=True, dask=dask)\n \n-    actual = getattr(da, func)((\"x\", \"y\"))\n-    expected = getattr(getattr(da, func)(\"x\"), func)(\"y\")\n+    actual = getattr(da, func)((\"x\", \"y\"), skipna=skipna)\n+    expected = getattr(getattr(da, func)(\"x\", skipna=skipna), func)(\"y\", skipna=skipna)\n     assert_allclose(actual, expected)\n \n \n\nFrom 5b84e4143fb399ce20e88573d000e020efeea10e Mon Sep 17 00:00:00 2001\nFrom: Maximilian Roos <m@maxroos.com>\nDate: Thu, 20 Aug 2020 09:21:37 -0700\nSubject: [PATCH 2/2] Add whatsnew\n\n---\n doc/whats-new.rst | 5 ++++-\n 1 file changed, 4 insertions(+), 1 deletion(-)\n\ndiff --git a/doc/whats-new.rst b/doc/whats-new.rst\nindex 2652af5d9fd..901e2f7f281 100644\n--- a/doc/whats-new.rst\n+++ b/doc/whats-new.rst\n@@ -28,8 +28,11 @@ New Features\n - Support multiple outputs in :py:func:`xarray.apply_ufunc` when using ``dask='parallelized'``. (:issue:`1815`, :pull:`4060`)\n   By `Kai M\u00fchlbauer <https://github.com/kmuehlbauer>`_.\n - :py:meth:`~xarray.DataArray.rolling` and :py:meth:`~xarray.Dataset.rolling`\n-  now accept more than 1 dimension.(:pull:`4219`)\n+  now accept more than 1 dimension. (:pull:`4219`)\n   By `Keisuke Fujii <https://github.com/fujiisoup>`_.\n+- ``min_count`` can be supplied to reductions such as ``.sum`` when specifying\n+  multiple dimension to reduce over. (:pull:`4356`) \n+  By `Maximilian Roos <https://github.com/max-sixty>`_.\n - Build ``CFTimeIndex.__repr__`` explicitly as :py:class:`pandas.Index`. Add ``calendar`` as a new\n   property for :py:class:`CFTimeIndex` and show ``calendar`` and ``length`` in\n   ``CFTimeIndex.__repr__`` (:issue:`2416`, :pull:`4092`)\n", "gold_standard_pr_link": "https://github.com/pydata/xarray/pull/4356"}