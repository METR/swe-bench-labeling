From 09578f6dfb757c55f107e30a85434cedeb47465a Mon Sep 17 00:00:00 2001
From: Ahmet Kucuk <ahmetkucuk92@gmail.com>
Date: Tue, 1 Oct 2019 13:13:19 -0400
Subject: [PATCH] Fixed #30827 -- Made batch_size arg of QuerySet.bulk_create()
 respect DatabaseOperations.bulk_batch_size().

Thanks Chetan Khanna for tests.
---
 django/db/models/query.py  | 3 ++-
 tests/bulk_create/tests.py | 9 +++++++++
 2 files changed, 11 insertions(+), 1 deletion(-)

diff --git a/django/db/models/query.py b/django/db/models/query.py
index 794e0faae7af..92349cd0c5bb 100644
--- a/django/db/models/query.py
+++ b/django/db/models/query.py
@@ -1209,7 +1209,8 @@ def _batched_insert(self, objs, fields, batch_size, ignore_conflicts=False):
         if ignore_conflicts and not connections[self.db].features.supports_ignore_conflicts:
             raise NotSupportedError('This database backend does not support ignoring conflicts.')
         ops = connections[self.db].ops
-        batch_size = (batch_size or max(ops.bulk_batch_size(fields, objs), 1))
+        max_batch_size = max(ops.bulk_batch_size(fields, objs), 1)
+        batch_size = min(batch_size, max_batch_size) if batch_size else max_batch_size
         inserted_rows = []
         bulk_return = connections[self.db].features.can_return_rows_from_bulk_insert
         for item in [objs[i:i + batch_size] for i in range(0, len(objs), batch_size)]:
diff --git a/tests/bulk_create/tests.py b/tests/bulk_create/tests.py
index 47aa7afcdc4d..3ccbfc19b331 100644
--- a/tests/bulk_create/tests.py
+++ b/tests/bulk_create/tests.py
@@ -1,3 +1,4 @@
+from math import ceil
 from operator import attrgetter
 
 from django.db import IntegrityError, NotSupportedError, connection
@@ -214,6 +215,14 @@ def test_explicit_batch_size_efficiency(self):
         with self.assertNumQueries(1):
             TwoFields.objects.bulk_create(objs, len(objs))
 
+    @skipUnlessDBFeature('has_bulk_insert')
+    def test_explicit_batch_size_respects_max_batch_size(self):
+        objs = [Country() for i in range(1000)]
+        fields = ['name', 'iso_two_letter', 'description']
+        max_batch_size = max(connection.ops.bulk_batch_size(fields, objs), 1)
+        with self.assertNumQueries(ceil(len(objs) / max_batch_size)):
+            Country.objects.bulk_create(objs, batch_size=max_batch_size + 1)
+
     @skipUnlessDBFeature('has_bulk_insert')
     def test_bulk_insert_expressions(self):
         Restaurant.objects.bulk_create([
