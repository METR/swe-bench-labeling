{"instance_id": "pydata__xarray-6721", "score": "C", "diff": "diff --git a/test.zarr/.zattrs b/test.zarr/.zattrs\nnew file mode 100644\nindex 00000000..9e26dfee\n--- /dev/null\n+++ b/test.zarr/.zattrs\n@@ -0,0 +1 @@\n+{}\n\\ No newline at end of file\ndiff --git a/test.zarr/.zgroup b/test.zarr/.zgroup\nnew file mode 100644\nindex 00000000..3b7daf22\n--- /dev/null\n+++ b/test.zarr/.zgroup\n@@ -0,0 +1,3 @@\n+{\n+    \"zarr_format\": 2\n+}\n\\ No newline at end of file\ndiff --git a/test.zarr/.zmetadata b/test.zarr/.zmetadata\nnew file mode 100644\nindex 00000000..48848931\n--- /dev/null\n+++ b/test.zarr/.zmetadata\n@@ -0,0 +1,37 @@\n+{\n+    \"metadata\": {\n+        \".zattrs\": {},\n+        \".zgroup\": {\n+            \"zarr_format\": 2\n+        },\n+        \"test/.zarray\": {\n+            \"chunks\": [\n+                10,\n+                20\n+            ],\n+            \"compressor\": {\n+                \"blocksize\": 0,\n+                \"clevel\": 5,\n+                \"cname\": \"lz4\",\n+                \"id\": \"blosc\",\n+                \"shuffle\": 1\n+            },\n+            \"dtype\": \"<f8\",\n+            \"fill_value\": \"NaN\",\n+            \"filters\": null,\n+            \"order\": \"C\",\n+            \"shape\": [\n+                10,\n+                20\n+            ],\n+            \"zarr_format\": 2\n+        },\n+        \"test/.zattrs\": {\n+            \"_ARRAY_DIMENSIONS\": [\n+                \"x\",\n+                \"y\"\n+            ]\n+        }\n+    },\n+    \"zarr_consolidated_format\": 1\n+}\n\\ No newline at end of file\ndiff --git a/test.zarr/test/.zarray b/test.zarr/test/.zarray\nnew file mode 100644\nindex 00000000..31af92cb\n--- /dev/null\n+++ b/test.zarr/test/.zarray\n@@ -0,0 +1,22 @@\n+{\n+    \"chunks\": [\n+        10,\n+        20\n+    ],\n+    \"compressor\": {\n+        \"blocksize\": 0,\n+        \"clevel\": 5,\n+        \"cname\": \"lz4\",\n+        \"id\": \"blosc\",\n+        \"shuffle\": 1\n+    },\n+    \"dtype\": \"<f8\",\n+    \"fill_value\": \"NaN\",\n+    \"filters\": null,\n+    \"order\": \"C\",\n+    \"shape\": [\n+        10,\n+        20\n+    ],\n+    \"zarr_format\": 2\n+}\n\\ No newline at end of file\ndiff --git a/test.zarr/test/.zattrs b/test.zarr/test/.zattrs\nnew file mode 100644\nindex 00000000..74ac71d9\n--- /dev/null\n+++ b/test.zarr/test/.zattrs\n@@ -0,0 +1,6 @@\n+{\n+    \"_ARRAY_DIMENSIONS\": [\n+        \"x\",\n+        \"y\"\n+    ]\n+}\n\\ No newline at end of file\ndiff --git a/test.zarr/test/0.0 b/test.zarr/test/0.0\nnew file mode 100644\nindex 00000000..79b16586\nBinary files /dev/null and b/test.zarr/test/0.0 differ\ndiff --git a/test_chunks_issue.py b/test_chunks_issue.py\nnew file mode 100644\nindex 00000000..d4d84550\n--- /dev/null\n+++ b/test_chunks_issue.py\n@@ -0,0 +1,39 @@\n+import xarray as xr\n+import numpy as np\n+import zarr\n+import tempfile\n+import os\n+\n+# Create a test to reproduce the issue\n+def test_zarr_chunks_does_not_load_data():\n+    \"\"\"Test that accessing chunks on zarr-backed arrays doesn't load data into memory.\"\"\"\n+    \n+    with tempfile.TemporaryDirectory() as tmpdir:\n+        zarr_path = os.path.join(tmpdir, 'test.zarr')\n+        \n+        # Create a large array that would be noticeable if loaded into memory\n+        data = xr.DataArray(np.zeros((1000, 1000)), dims=['x', 'y'])\n+        ds = xr.Dataset({'large_array': data})\n+        \n+        # Save to zarr with specific chunks\n+        ds.to_zarr(zarr_path, mode='w', encoding={'large_array': {'chunks': (100, 100)}})\n+        \n+        # Open the dataset\n+        ds_zarr = xr.open_dataset(zarr_path, engine='zarr')\n+        \n+        # Track if data is loaded by monitoring the _data attribute\n+        var = ds_zarr['large_array'].variable\n+        print(f\"Before accessing chunks - _in_memory: {var._in_memory}\")\n+        \n+        # This should NOT load data into memory\n+        chunks = ds_zarr.chunks\n+        print(f\"Chunks: {chunks}\")\n+        \n+        # Check if data was loaded\n+        print(f\"After accessing chunks - _in_memory: {var._in_memory}\")\n+        \n+        # The variable should still be lazy\n+        assert not var._in_memory, \"Data was loaded into memory when accessing chunks!\"\n+\n+if __name__ == \"__main__\":\n+    test_zarr_chunks_does_not_load_data()\ndiff --git a/test_zarr_chunks_regression.py b/test_zarr_chunks_regression.py\nnew file mode 100644\nindex 00000000..0ecc9915\n--- /dev/null\n+++ b/test_zarr_chunks_regression.py\n@@ -0,0 +1,98 @@\n+\"\"\"\n+Test for regression of zarr chunks loading issue.\n+https://github.com/pydata/xarray/issues/6534\n+\"\"\"\n+import pytest\n+import xarray as xr\n+import numpy as np\n+import tempfile\n+import os\n+\n+\n+def test_zarr_chunks_does_not_load_data():\n+    \"\"\"Test that accessing chunks on zarr-backed arrays doesn't load data into memory.\"\"\"\n+    \n+    with tempfile.TemporaryDirectory() as tmpdir:\n+        zarr_path = os.path.join(tmpdir, 'test.zarr')\n+        \n+        # Create a large array that would be noticeable if loaded into memory\n+        data = xr.DataArray(np.zeros((1000, 1000)), dims=['x', 'y'])\n+        ds = xr.Dataset({'large_array': data})\n+        \n+        # Save to zarr with specific chunks\n+        ds.to_zarr(zarr_path, mode='w', encoding={'large_array': {'chunks': (100, 100)}})\n+        \n+        # Open the dataset\n+        ds_zarr = xr.open_dataset(zarr_path, engine='zarr')\n+        \n+        # Track if data is loaded by monitoring the _in_memory attribute\n+        var = ds_zarr['large_array'].variable\n+        assert not var._in_memory, \"Data should not be in memory after opening\"\n+        \n+        # This should NOT load data into memory\n+        chunks = ds_zarr.chunks\n+        \n+        # Check if data was loaded\n+        assert not var._in_memory, \"Data was loaded into memory when accessing chunks!\"\n+        \n+        # Verify chunks are correct\n+        assert chunks == {'x': (100,), 'y': (100,)}, f\"Unexpected chunks: {chunks}\"\n+\n+\n+def test_zarr_chunks_from_encoding():\n+    \"\"\"Test that zarr chunks are read from encoding without loading data.\"\"\"\n+    \n+    with tempfile.TemporaryDirectory() as tmpdir:\n+        zarr_path = os.path.join(tmpdir, 'test.zarr')\n+        \n+        # Create dataset with multiple variables having different chunks\n+        data1 = xr.DataArray(np.zeros((1000, 2000)), dims=['x', 'y'], name='var1')\n+        data2 = xr.DataArray(np.zeros((1000, 2000)), dims=['x', 'y'], name='var2')\n+        ds = xr.Dataset({'var1': data1, 'var2': data2})\n+        \n+        # Save with specific chunks\n+        encoding = {\n+            'var1': {'chunks': (200, 400)},\n+            'var2': {'chunks': (200, 400)}\n+        }\n+        ds.to_zarr(zarr_path, mode='w', encoding=encoding)\n+        \n+        # Open and check chunks\n+        ds_zarr = xr.open_dataset(zarr_path, engine='zarr')\n+        \n+        # Verify encoding contains chunks\n+        assert 'chunks' in ds_zarr['var1'].encoding\n+        assert ds_zarr['var1'].encoding['chunks'] == (200, 400)\n+        \n+        # Check variable chunksizes (should use encoding)\n+        var1_chunksizes = ds_zarr['var1'].variable.chunksizes\n+        assert var1_chunksizes == {'x': (200,), 'y': (400,)}\n+        \n+        # Check dataset chunks\n+        ds_chunks = ds_zarr.chunks\n+        assert ds_chunks == {'x': (200,), 'y': (400,)}\n+        \n+        # Verify data wasn't loaded\n+        assert not ds_zarr['var1'].variable._in_memory\n+        assert not ds_zarr['var2'].variable._in_memory\n+\n+\n+def test_dask_chunks_still_work():\n+    \"\"\"Ensure dask arrays still report chunks correctly.\"\"\"\n+    import dask.array as da\n+    \n+    # Create dask arrays\n+    data = da.zeros((1000, 2000), chunks=(100, 200))\n+    arr = xr.DataArray(data, dims=['x', 'y'])\n+    ds = xr.Dataset({'var': arr})\n+    \n+    # Check chunks\n+    assert ds.chunks == {'x': (100,) * 10, 'y': (200,) * 10}\n+    assert arr.chunks == ((100,) * 10, (200,) * 10)\n+\n+\n+if __name__ == \"__main__\":\n+    test_zarr_chunks_does_not_load_data()\n+    test_zarr_chunks_from_encoding()\n+    test_dask_chunks_still_work()\n+    print(\"All tests passed!\")\ndiff --git a/xarray/core/common.py b/xarray/core/common.py\nindex 3c328f42..53717b2b 100644\n--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -2023,7 +2023,11 @@ def get_chunksizes(\n \n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, \"chunks\"):\n+        # First check encoding for chunk information (for zarr and other backends)\n+        # This avoids loading data into memory\n+        has_chunk_info = (\"chunks\" in v.encoding and v.encoding[\"chunks\"] is not None) or hasattr(v._data, \"chunks\")\n+        \n+        if has_chunk_info:\n             for dim, c in v.chunksizes.items():\n                 if dim in chunks and c != chunks[dim]:\n                     raise ValueError(\ndiff --git a/xarray/core/variable.py b/xarray/core/variable.py\nindex 2d115ff0..8e4fb697 100644\n--- a/xarray/core/variable.py\n+++ b/xarray/core/variable.py\n@@ -1014,8 +1014,18 @@ class Variable(AbstractArray, NdimSizeLenMixin, VariableArithmetic):\n         Variable.chunks\n         xarray.unify_chunks\n         \"\"\"\n+        # For zarr arrays and other lazy arrays that store chunk information in encoding\n+        if \"chunks\" in self.encoding and not hasattr(self._data, \"chunks\"):\n+            chunks = self.encoding[\"chunks\"]\n+            if chunks is not None:\n+                # Ensure chunks is a tuple\n+                if not isinstance(chunks, tuple):\n+                    chunks = tuple(chunks)\n+                return Frozen({dim: (size,) for dim, size in zip(self.dims, chunks)})\n+        \n+        # For dask arrays, access chunks directly from _data\n         if hasattr(self._data, \"chunks\"):\n-            return Frozen({dim: c for dim, c in zip(self.dims, self.data.chunks)})\n+            return Frozen({dim: c for dim, c in zip(self.dims, self._data.chunks)})\n         else:\n             return {}\n \n", "gold_standard_diff": "diff --git a/doc/whats-new.rst b/doc/whats-new.rst\nindex dc9a8adf4bc..dba4f1d3256 100644\n--- a/doc/whats-new.rst\n+++ b/doc/whats-new.rst\n@@ -197,6 +197,8 @@ Bug fixes\n - Fixed silent overflow issue when decoding times encoded with 32-bit and below\n   unsigned integer data types (:issue:`6589`, :pull:`6598`).\n   By `Spencer Clark <https://github.com/spencerkclark>`_.\n+- Fixed ``.chunks`` loading lazy data (:issue:`6538`).\n+  By `Deepak Cherian <https://github.com/dcherian>`_.\n \n Documentation\n ~~~~~~~~~~~~~\ndiff --git a/xarray/core/common.py b/xarray/core/common.py\nindex 3c328f42e98..a3636cbac66 100644\n--- a/xarray/core/common.py\n+++ b/xarray/core/common.py\n@@ -2023,7 +2023,7 @@ def get_chunksizes(\n \n     chunks: dict[Any, tuple[int, ...]] = {}\n     for v in variables:\n-        if hasattr(v.data, \"chunks\"):\n+        if hasattr(v._data, \"chunks\"):\n             for dim, c in v.chunksizes.items():\n                 if dim in chunks and c != chunks[dim]:\n                     raise ValueError(\ndiff --git a/xarray/tests/test_dataset.py b/xarray/tests/test_dataset.py\nindex e3ab430a833..bc5bf1c0f1c 100644\n--- a/xarray/tests/test_dataset.py\n+++ b/xarray/tests/test_dataset.py\n@@ -992,6 +992,13 @@ def test_attrs(self) -> None:\n         assert data.attrs[\"foobar\"], \"baz\"\n         assert isinstance(data.attrs, dict)\n \n+    def test_chunks_does_not_load_data(self) -> None:\n+        # regression test for GH6538\n+        store = InaccessibleVariableDataStore()\n+        create_test_data().dump_to_store(store)\n+        ds = open_dataset(store)\n+        assert ds.chunks == {}\n+\n     @requires_dask\n     def test_chunk(self) -> None:\n         data = create_test_data()\n", "gold_standard_pr_link": "https://github.com/pydata/xarray/pull/6721"}