{"instance_id": "scikit-learn__scikit-learn-14053", "score": "C", "diff": "diff --git a/debug_issue.py b/debug_issue.py\nnew file mode 100644\nindex 000000000..4277db991\n--- /dev/null\n+++ b/debug_issue.py\n@@ -0,0 +1,14 @@\n+from sklearn.tree import DecisionTreeClassifier\n+from sklearn.datasets import load_iris\n+import numpy as np\n+\n+X, y = load_iris(return_X_y=True)\n+X = X[:, 0].reshape(-1, 1)\n+\n+tree = DecisionTreeClassifier()\n+tree.fit(X, y)\n+\n+print(\"tree_.feature:\", tree.tree_.feature)\n+print(\"tree_.n_features:\", tree.tree_.n_features)\n+print(\"Number of feature names provided:\", 1)\n+print(\"Max feature index:\", np.max(tree.tree_.feature[tree.tree_.feature >= 0]) if any(tree.tree_.feature >= 0) else \"No features\")\ndiff --git a/sklearn/tree/export.py b/sklearn/tree/export.py\nindex 1fe11e596..fe06471d4 100644\n--- a/sklearn/tree/export.py\n+++ b/sklearn/tree/export.py\n@@ -889,11 +889,6 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n     else:\n         value_fmt = \"{}{} value: {}\\n\"\n \n-    if feature_names:\n-        feature_names_ = [feature_names[i] for i in tree_.feature]\n-    else:\n-        feature_names_ = [\"feature_{}\".format(i) for i in tree_.feature]\n-\n     export_text.report = \"\"\n \n     def _add_leaf(value, class_name, indent):\n@@ -928,7 +923,13 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n             info_fmt_right = info_fmt\n \n             if tree_.feature[node] != _tree.TREE_UNDEFINED:\n-                name = feature_names_[node]\n+                # Get the feature index for this node\n+                feature_idx = tree_.feature[node]\n+                # Get the feature name for this feature\n+                if feature_names:\n+                    name = feature_names[feature_idx]\n+                else:\n+                    name = \"feature_{}\".format(feature_idx)\n                 threshold = tree_.threshold[node]\n                 threshold = \"{1:.{0}f}\".format(decimals, threshold)\n                 export_text.report += right_child_fmt.format(indent,\ndiff --git a/sklearn/tree/tests/test_export.py b/sklearn/tree/tests/test_export.py\nindex 503431f45..89843ddf8 100644\n--- a/sklearn/tree/tests/test_export.py\n+++ b/sklearn/tree/tests/test_export.py\n@@ -397,6 +397,23 @@ def test_export_text():\n     assert export_text(reg, decimals=1, show_weights=True) == expected_report\n \n \n+def test_export_text_single_feature():\n+    # Test fix for issue: IndexError when tree only has one feature\n+    X_single = [[1], [2], [3], [4], [5], [6]]\n+    y_single = [0, 0, 0, 1, 1, 1]\n+    \n+    clf = DecisionTreeClassifier(max_depth=2)\n+    clf.fit(X_single, y_single)\n+    \n+    # Should not raise IndexError\n+    report_with_names = export_text(clf, feature_names=['feature_name'])\n+    assert 'feature_name' in report_with_names\n+    \n+    # Should also work without feature names\n+    report_without_names = export_text(clf)\n+    assert 'feature_0' in report_without_names\n+\n+\n def test_plot_tree_entropy(pyplot):\n     # mostly smoke tests\n     # Check correctness of export_graphviz for criterion = entropy\ndiff --git a/test_issue.py b/test_issue.py\nnew file mode 100644\nindex 000000000..deaac0eed\n--- /dev/null\n+++ b/test_issue.py\n@@ -0,0 +1,11 @@\n+from sklearn.tree import DecisionTreeClassifier\n+from sklearn.tree.export import export_text\n+from sklearn.datasets import load_iris\n+\n+X, y = load_iris(return_X_y=True)\n+X = X[:, 0].reshape(-1, 1)\n+\n+tree = DecisionTreeClassifier()\n+tree.fit(X, y)\n+tree_text = export_text(tree, feature_names=['sepal_length'])\n+print(tree_text)\ndiff --git a/test_multiple_features.py b/test_multiple_features.py\nnew file mode 100644\nindex 000000000..b22ec3cb8\n--- /dev/null\n+++ b/test_multiple_features.py\n@@ -0,0 +1,10 @@\n+from sklearn.tree import DecisionTreeClassifier\n+from sklearn.tree.export import export_text\n+from sklearn.datasets import load_iris\n+\n+X, y = load_iris(return_X_y=True)\n+\n+tree = DecisionTreeClassifier(max_depth=2)\n+tree.fit(X, y)\n+tree_text = export_text(tree, feature_names=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n+print(tree_text)\ndiff --git a/test_no_feature_names.py b/test_no_feature_names.py\nnew file mode 100644\nindex 000000000..6153ec22e\n--- /dev/null\n+++ b/test_no_feature_names.py\n@@ -0,0 +1,11 @@\n+from sklearn.tree import DecisionTreeClassifier\n+from sklearn.tree.export import export_text\n+from sklearn.datasets import load_iris\n+\n+X, y = load_iris(return_X_y=True)\n+X = X[:, 0].reshape(-1, 1)\n+\n+tree = DecisionTreeClassifier(max_depth=2)\n+tree.fit(X, y)\n+tree_text = export_text(tree)  # No feature names provided\n+print(tree_text)\ndiff --git a/test_regression_single_feature.py b/test_regression_single_feature.py\nnew file mode 100644\nindex 000000000..b39f689e7\n--- /dev/null\n+++ b/test_regression_single_feature.py\n@@ -0,0 +1,12 @@\n+from sklearn.tree import DecisionTreeRegressor\n+from sklearn.tree.export import export_text\n+import numpy as np\n+\n+# Test with regression tree\n+X = np.array([[1], [2], [3], [4], [5], [6]])\n+y = np.array([1.5, 2.5, 3.5, 4.5, 5.5, 6.5])\n+\n+tree = DecisionTreeRegressor(max_depth=2)\n+tree.fit(X, y)\n+tree_text = export_text(tree, feature_names=['single_feature'])\n+print(tree_text)\n", "gold_standard_diff": "diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst\nindex b945496953f36..44bbbc3ebf6a4 100644\n--- a/doc/whats_new/v0.21.rst\n+++ b/doc/whats_new/v0.21.rst\n@@ -19,6 +19,12 @@ Changelog\n   ``'penalty'`` parameters (regression introduced in 0.21). :pr:`14087` by\n   `Nicolas Hug`_.\n \n+:mod:`sklearn.tree`\n+...................\n+\n+- |Fix| Fixed bug in :func:`tree.export_text` when the tree has one feature and \n+  a single feature name is passed in. :pr:`14053` by `Thomas Fan`\n+\n .. _changes_0_21_2:\n \n Version 0.21.2\ndiff --git a/sklearn/tree/export.py b/sklearn/tree/export.py\nindex 1fe11e596a359..2c9d21b7bb5cc 100644\n--- a/sklearn/tree/export.py\n+++ b/sklearn/tree/export.py\n@@ -890,7 +890,8 @@ def export_text(decision_tree, feature_names=None, max_depth=10,\n         value_fmt = \"{}{} value: {}\\n\"\n \n     if feature_names:\n-        feature_names_ = [feature_names[i] for i in tree_.feature]\n+        feature_names_ = [feature_names[i] if i != _tree.TREE_UNDEFINED\n+                          else None for i in tree_.feature]\n     else:\n         feature_names_ = [\"feature_{}\".format(i) for i in tree_.feature]\n \ndiff --git a/sklearn/tree/tests/test_export.py b/sklearn/tree/tests/test_export.py\nindex 503431f456874..317a11ae25836 100644\n--- a/sklearn/tree/tests/test_export.py\n+++ b/sklearn/tree/tests/test_export.py\n@@ -396,6 +396,21 @@ def test_export_text():\n     assert export_text(reg, decimals=1) == expected_report\n     assert export_text(reg, decimals=1, show_weights=True) == expected_report\n \n+    X_single = [[-2], [-1], [-1], [1], [1], [2]]\n+    reg = DecisionTreeRegressor(max_depth=2, random_state=0)\n+    reg.fit(X_single, y_mo)\n+\n+    expected_report = dedent(\"\"\"\n+    |--- first <= 0.0\n+    |   |--- value: [-1.0, -1.0]\n+    |--- first >  0.0\n+    |   |--- value: [1.0, 1.0]\n+    \"\"\").lstrip()\n+    assert export_text(reg, decimals=1,\n+                       feature_names=['first']) == expected_report\n+    assert export_text(reg, decimals=1, show_weights=True,\n+                       feature_names=['first']) == expected_report\n+\n \n def test_plot_tree_entropy(pyplot):\n     # mostly smoke tests\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/14053"}