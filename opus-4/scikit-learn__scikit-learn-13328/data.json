{"instance_id": "scikit-learn__scikit-learn-13328", "score": "C", "diff": "diff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex 65c686400..d3606a09e 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -251,7 +251,7 @@ class HuberRegressor(LinearModel, RegressorMixin, BaseEstimator):\n         self : object\n         \"\"\"\n         X, y = check_X_y(\n-            X, y, copy=False, accept_sparse=['csr'], y_numeric=True)\n+            X, y, copy=False, accept_sparse=['csr'], y_numeric=True, dtype=np.float64)\n         if sample_weight is not None:\n             sample_weight = np.array(sample_weight)\n             check_consistent_length(y, sample_weight)\ndiff --git a/sklearn/linear_model/tests/test_huber.py b/sklearn/linear_model/tests/test_huber.py\nindex 6a8b26133..b1665233a 100644\n--- a/sklearn/linear_model/tests/test_huber.py\n+++ b/sklearn/linear_model/tests/test_huber.py\n@@ -199,3 +199,30 @@ def test_huber_better_r2_score():\n \n     # The huber model should also fit poorly on the outliers.\n     assert_greater(ridge_outlier_score, huber_outlier_score)\n+\n+\n+def test_huber_bool_input():\n+    # Test that HuberRegressor can handle boolean input\n+    X, y = make_regression_with_outliers(n_samples=200, n_features=2)\n+    X_bool = X > 0\n+    X_bool_as_float = X_bool.astype(float)\n+\n+    # Test with dense boolean array\n+    huber_bool = HuberRegressor()\n+    huber_bool.fit(X_bool, y)\n+    \n+    # Test with dense float array (converted from boolean)\n+    huber_float = HuberRegressor()\n+    huber_float.fit(X_bool_as_float, y)\n+    \n+    # Coefficients should be identical\n+    assert_array_almost_equal(huber_bool.coef_, huber_float.coef_)\n+    assert_almost_equal(huber_bool.intercept_, huber_float.intercept_)\n+    \n+    # Test with sparse boolean matrix\n+    X_bool_sparse = sparse.csr_matrix(X_bool)\n+    huber_sparse = HuberRegressor()\n+    huber_sparse.fit(X_bool_sparse, y)\n+    \n+    # Results with sparse boolean should also be close\n+    assert_array_almost_equal(huber_sparse.coef_, huber_float.coef_, decimal=5)\ndiff --git a/test_fix.py b/test_fix.py\nnew file mode 100644\nindex 000000000..604f7bdbb\n--- /dev/null\n+++ b/test_fix.py\n@@ -0,0 +1,37 @@\n+import numpy as np\n+from sklearn.datasets import make_regression\n+from sklearn.linear_model import HuberRegressor\n+\n+# Test various dtypes\n+print(\"Testing HuberRegressor with various dtypes...\")\n+\n+# Random data\n+X, y, coef = make_regression(n_samples=200, n_features=2, noise=4.0, coef=True, random_state=0)\n+\n+# Test with boolean\n+X_bool = X > 0\n+print(f\"\\nTesting with boolean dtype...\")\n+try:\n+    huber = HuberRegressor(random_state=0).fit(X_bool, y)\n+    print(f\"  Success!\")\n+except Exception as e:\n+    print(f\"  Failed: {e}\")\n+\n+# Test with int\n+print(f\"\\nTesting with int32 dtype...\")\n+X_int = X.astype(np.int32)\n+try:\n+    huber = HuberRegressor(random_state=0).fit(X_int, y)\n+    print(f\"  Success!\")\n+except Exception as e:\n+    print(f\"  Failed: {e}\")\n+\n+# Test sparse boolean\n+from scipy import sparse\n+X_bool_sparse = sparse.csr_matrix(X_bool)\n+print(f\"\\nTesting with sparse boolean...\")\n+try:\n+    huber = HuberRegressor(random_state=0).fit(X_bool_sparse, y)\n+    print(f\"  Success!\")\n+except Exception as e:\n+    print(f\"  Failed: {e}\")\ndiff --git a/test_fix2.py b/test_fix2.py\nnew file mode 100644\nindex 000000000..ca854a32f\n--- /dev/null\n+++ b/test_fix2.py\n@@ -0,0 +1,43 @@\n+import numpy as np\n+from sklearn.datasets import make_regression\n+from sklearn.linear_model import HuberRegressor\n+\n+# Test various dtypes\n+print(\"Testing HuberRegressor with various dtypes...\")\n+\n+# Random data\n+X, y, coef = make_regression(n_samples=200, n_features=2, noise=4.0, coef=True, random_state=0)\n+\n+# Test with boolean\n+X_bool = X > 0\n+print(f\"\\nTesting with boolean dtype...\")\n+try:\n+    huber = HuberRegressor().fit(X_bool, y)\n+    print(f\"  Success! Coef shape: {huber.coef_.shape}\")\n+except Exception as e:\n+    print(f\"  Failed: {e}\")\n+\n+# Test with int\n+print(f\"\\nTesting with int32 dtype...\")\n+X_int = X.astype(np.int32)\n+try:\n+    huber = HuberRegressor().fit(X_int, y)\n+    print(f\"  Success! Coef shape: {huber.coef_.shape}\")\n+except Exception as e:\n+    print(f\"  Failed: {e}\")\n+\n+# Test sparse boolean\n+from scipy import sparse\n+X_bool_sparse = sparse.csr_matrix(X_bool)\n+print(f\"\\nTesting with sparse boolean...\")\n+try:\n+    huber = HuberRegressor().fit(X_bool_sparse, y)\n+    print(f\"  Success! Coef shape: {huber.coef_.shape}\")\n+except Exception as e:\n+    print(f\"  Failed: {e}\")\n+\n+# Test that boolean conversion is consistent\n+X_bool_as_float = X_bool.astype(float)\n+huber_bool = HuberRegressor().fit(X_bool, y)\n+huber_float = HuberRegressor().fit(X_bool_as_float, y)\n+print(f\"\\nMax coefficient difference between bool and float: {np.max(np.abs(huber_bool.coef_ - huber_float.coef_))}\")\ndiff --git a/test_huber_bool.py b/test_huber_bool.py\nnew file mode 100644\nindex 000000000..00f7dfa6d\n--- /dev/null\n+++ b/test_huber_bool.py\n@@ -0,0 +1,26 @@\n+import numpy as np\n+from sklearn.datasets import make_regression\n+from sklearn.linear_model import HuberRegressor\n+\n+# Random data\n+X, y, coef = make_regression(n_samples=200, n_features=2, noise=4.0, coef=True, random_state=0)\n+X_bool = X > 0\n+X_bool_as_float = np.asarray(X_bool, dtype=float)\n+\n+# Works\n+print(\"Testing with float X...\")\n+huber = HuberRegressor().fit(X, y)\n+print(\"Success!\")\n+\n+# Should work but fails\n+print(\"\\nTesting with boolean X...\")\n+try:\n+    huber = HuberRegressor().fit(X_bool, y)\n+    print(\"Success!\")\n+except TypeError as e:\n+    print(f\"Failed with error: {e}\")\n+\n+# Also works\n+print(\"\\nTesting with boolean X converted to float...\")\n+huber = HuberRegressor().fit(X_bool_as_float, y)\n+print(\"Success!\")\ndiff --git a/test_huber_comprehensive.py b/test_huber_comprehensive.py\nnew file mode 100644\nindex 000000000..e69de29bb\ndiff --git a/test_huber_dtypes.py b/test_huber_dtypes.py\nnew file mode 100644\nindex 000000000..e69de29bb\ndiff --git a/test_linear_models_bool.py b/test_linear_models_bool.py\nnew file mode 100644\nindex 000000000..c533a950a\n--- /dev/null\n+++ b/test_linear_models_bool.py\n@@ -0,0 +1,22 @@\n+import numpy as np\n+from sklearn.datasets import make_regression\n+from sklearn.linear_model import LinearRegression, Ridge, Lasso, HuberRegressor\n+\n+# Test that various linear models handle boolean input\n+X, y = make_regression(n_samples=50, n_features=2, random_state=0)\n+X_bool = X > 0\n+\n+models = [\n+    (\"LinearRegression\", LinearRegression()),\n+    (\"Ridge\", Ridge()),\n+    (\"Lasso\", Lasso()),\n+    (\"HuberRegressor\", HuberRegressor())\n+]\n+\n+print(\"Testing linear models with boolean input:\")\n+for name, model in models:\n+    try:\n+        model.fit(X_bool, y)\n+        print(f\"\u2713 {name} - Success!\")\n+    except Exception as e:\n+        print(f\"\u2717 {name} - Failed: {e}\")\n", "gold_standard_diff": "From cff2c4f9ea5e8802b054fb47b58dc8ab2b489f41 Mon Sep 17 00:00:00 2001\nFrom: Alexandre Gramfort <alexandre.gramfort@m4x.org>\nDate: Thu, 28 Feb 2019 13:44:40 +0100\nSubject: [PATCH 1/5] make sure huber works with boolean X\n\n---\n sklearn/linear_model/huber.py            | 3 ++-\n sklearn/linear_model/tests/test_huber.py | 7 +++++++\n 2 files changed, 9 insertions(+), 1 deletion(-)\n\ndiff --git a/sklearn/linear_model/huber.py b/sklearn/linear_model/huber.py\nindex cd17b0fe33c00..676c5f02124dc 100644\n--- a/sklearn/linear_model/huber.py\n+++ b/sklearn/linear_model/huber.py\n@@ -251,7 +251,8 @@ def fit(self, X, y, sample_weight=None):\n         self : object\n         \"\"\"\n         X, y = check_X_y(\n-            X, y, copy=False, accept_sparse=['csr'], y_numeric=True)\n+            X, y, copy=False, accept_sparse=['csr'], y_numeric=True,\n+            dtype=[np.float64, np.float32])\n         if sample_weight is not None:\n             sample_weight = np.array(sample_weight)\n             check_consistent_length(y, sample_weight)\ndiff --git a/sklearn/linear_model/tests/test_huber.py b/sklearn/linear_model/tests/test_huber.py\nindex 6a8b26133d5ac..9d9955dd6153b 100644\n--- a/sklearn/linear_model/tests/test_huber.py\n+++ b/sklearn/linear_model/tests/test_huber.py\n@@ -199,3 +199,10 @@ def test_huber_better_r2_score():\n \n     # The huber model should also fit poorly on the outliers.\n     assert_greater(ridge_outlier_score, huber_outlier_score)\n+\n+\n+def test_huber_bool():\n+    # Test that it does not crash with bool data\n+    X, y = make_regression(n_samples=200, n_features=2, noise=4.0, random_state=0)\n+    X_bool = X > 0\n+    huber = HuberRegressor().fit(X_bool, y)\n\nFrom b4363abb9450943ce2a27ba1d37f994b4965c31c Mon Sep 17 00:00:00 2001\nFrom: Alexandre Gramfort <alexandre.gramfort@m4x.org>\nDate: Thu, 28 Feb 2019 13:46:48 +0100\nSubject: [PATCH 2/5] update what's new\n\n---\n doc/whats_new/v0.21.rst | 7 ++++++-\n 1 file changed, 6 insertions(+), 1 deletion(-)\n\ndiff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst\nindex e3e3ec9f88816..9518baf8816ea 100644\n--- a/doc/whats_new/v0.21.rst\n+++ b/doc/whats_new/v0.21.rst\n@@ -42,7 +42,7 @@ Support for Python 3.4 and below has been officially dropped.\n     See version doc/whats_new/v0.20.rst for structure. Entries should be\n     prefixed with one of the labels: |MajorFeature|, |Feature|, |Efficiency|,\n     |Enhancement|, |Fix| or |API|. They should be under a heading for the\n-    relevant module (or *Multiple Modules* or *Miscellaneous*), and within each\n+    relevant module (or *Mufltiple Modules* or *Miscellaneous*), and within each\n     section should be ordered according to the label ordering above. Entries\n     should end with: :issue:`123456` by :user:`Joe Bloggs <joeongithub>`.\n \n@@ -234,6 +234,11 @@ Support for Python 3.4 and below has been officially dropped.\n   now supports fitting the intercept (i.e. ``fit_intercept=True``) when\n   inputs are sparse . :issue:`13336` by :user:`Bartosz Telenczuk <btel>`\n \n+- |Fix| Fixed a bug in :class:`linear_model.HuberRegressor` that was\n+  broken when X was of dtype bool.\n+  :issue:`13314` by `Alexandre Gramfort`_.\n+\n+\n :mod:`sklearn.manifold`\n ............................\n \n\nFrom 48a7ccae3b477d036ab605e983d4a5efa71c3c6c Mon Sep 17 00:00:00 2001\nFrom: Alexandre Gramfort <alexandre.gramfort@m4x.org>\nDate: Thu, 28 Feb 2019 21:22:37 +0100\nSubject: [PATCH 3/5] lint\n\n---\n sklearn/linear_model/tests/test_huber.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a/sklearn/linear_model/tests/test_huber.py b/sklearn/linear_model/tests/test_huber.py\nindex 9d9955dd6153b..58f983cf75b3a 100644\n--- a/sklearn/linear_model/tests/test_huber.py\n+++ b/sklearn/linear_model/tests/test_huber.py\n@@ -205,4 +205,4 @@ def test_huber_bool():\n     # Test that it does not crash with bool data\n     X, y = make_regression(n_samples=200, n_features=2, noise=4.0, random_state=0)\n     X_bool = X > 0\n-    huber = HuberRegressor().fit(X_bool, y)\n+    HuberRegressor().fit(X_bool, y)\n\nFrom 83e134f4f776dc8ad1ad099c84f6ffa4e95fbe93 Mon Sep 17 00:00:00 2001\nFrom: Alexandre Gramfort <alexandre.gramfort@m4x.org>\nDate: Fri, 1 Mar 2019 16:35:17 +0100\nSubject: [PATCH 4/5] review\n\n---\n doc/whats_new/v0.21.rst | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst\nindex 9518baf8816ea..ed5f270d441b8 100644\n--- a/doc/whats_new/v0.21.rst\n+++ b/doc/whats_new/v0.21.rst\n@@ -42,7 +42,7 @@ Support for Python 3.4 and below has been officially dropped.\n     See version doc/whats_new/v0.20.rst for structure. Entries should be\n     prefixed with one of the labels: |MajorFeature|, |Feature|, |Efficiency|,\n     |Enhancement|, |Fix| or |API|. They should be under a heading for the\n-    relevant module (or *Mufltiple Modules* or *Miscellaneous*), and within each\n+    relevant module (or *Multiple Modules* or *Miscellaneous*), and within each\n     section should be ordered according to the label ordering above. Entries\n     should end with: :issue:`123456` by :user:`Joe Bloggs <joeongithub>`.\n \n@@ -236,7 +236,7 @@ Support for Python 3.4 and below has been officially dropped.\n \n - |Fix| Fixed a bug in :class:`linear_model.HuberRegressor` that was\n   broken when X was of dtype bool.\n-  :issue:`13314` by `Alexandre Gramfort`_.\n+  :issue:`13328` by `Alexandre Gramfort`_.\n \n \n :mod:`sklearn.manifold`\n\nFrom 07d1ac5798faa720cccba6c1fe84620d4115b0c3 Mon Sep 17 00:00:00 2001\nFrom: Alexandre Gramfort <alexandre.gramfort@m4x.org>\nDate: Sat, 2 Mar 2019 08:52:46 +0100\nSubject: [PATCH 5/5] pep8\n\n---\n sklearn/linear_model/tests/test_huber.py | 25 +++++++++++++++---------\n 1 file changed, 16 insertions(+), 9 deletions(-)\n\ndiff --git a/sklearn/linear_model/tests/test_huber.py b/sklearn/linear_model/tests/test_huber.py\nindex 58f983cf75b3a..156ac72958d01 100644\n--- a/sklearn/linear_model/tests/test_huber.py\n+++ b/sklearn/linear_model/tests/test_huber.py\n@@ -53,8 +53,12 @@ def test_huber_gradient():\n     rng = np.random.RandomState(1)\n     X, y = make_regression_with_outliers()\n     sample_weight = rng.randint(1, 3, (y.shape[0]))\n-    loss_func = lambda x, *args: _huber_loss_and_gradient(x, *args)[0]\n-    grad_func = lambda x, *args: _huber_loss_and_gradient(x, *args)[1]\n+\n+    def loss_func(x, *args):\n+        return _huber_loss_and_gradient(x, *args)[0]\n+\n+    def grad_func(x, *args):\n+        return _huber_loss_and_gradient(x, *args)[1]\n \n     # Check using optimize.check_grad that the gradients are equal.\n     for _ in range(5):\n@@ -76,10 +80,10 @@ def test_huber_sample_weights():\n     huber_coef = huber.coef_\n     huber_intercept = huber.intercept_\n \n-    # Rescale coefs before comparing with assert_array_almost_equal to make sure\n-    # that the number of decimal places used is somewhat insensitive to the\n-    # amplitude of the coefficients and therefore to the scale of the data\n-    # and the regularization parameter\n+    # Rescale coefs before comparing with assert_array_almost_equal to make\n+    # sure that the number of decimal places used is somewhat insensitive to\n+    # the amplitude of the coefficients and therefore to the scale of the\n+    # data and the regularization parameter\n     scale = max(np.mean(np.abs(huber.coef_)),\n                 np.mean(np.abs(huber.intercept_)))\n \n@@ -167,7 +171,8 @@ def test_huber_and_sgd_same_results():\n def test_huber_warm_start():\n     X, y = make_regression_with_outliers()\n     huber_warm = HuberRegressor(\n-        fit_intercept=True, alpha=1.0, max_iter=10000, warm_start=True, tol=1e-1)\n+        fit_intercept=True, alpha=1.0, max_iter=10000, warm_start=True,\n+        tol=1e-1)\n     huber_warm.fit(X, y)\n     huber_warm_coef = huber_warm.coef_.copy()\n     huber_warm.fit(X, y)\n@@ -190,7 +195,8 @@ def test_huber_better_r2_score():\n     huber_outlier_score = huber.score(X[~mask], y[~mask])\n \n     # The Ridge regressor should be influenced by the outliers and hence\n-    # give a worse score on the non-outliers as compared to the huber regressor.\n+    # give a worse score on the non-outliers as compared to the huber\n+    # regressor.\n     ridge = Ridge(fit_intercept=True, alpha=0.01)\n     ridge.fit(X, y)\n     ridge_score = ridge.score(X[mask], y[mask])\n@@ -203,6 +209,7 @@ def test_huber_better_r2_score():\n \n def test_huber_bool():\n     # Test that it does not crash with bool data\n-    X, y = make_regression(n_samples=200, n_features=2, noise=4.0, random_state=0)\n+    X, y = make_regression(n_samples=200, n_features=2, noise=4.0,\n+                           random_state=0)\n     X_bool = X > 0\n     HuberRegressor().fit(X_bool, y)\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/13328"}