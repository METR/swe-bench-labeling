{"instance_id": "scikit-learn__scikit-learn-11310", "score": "C", "diff": "diff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\nindex 99d6096af..e1df2f699 100644\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -764,12 +764,15 @@ class BaseSearchCV(six.with_metaclass(ABCMeta, BaseEstimator,\n                 self.best_index_]\n \n         if self.refit:\n+            import time\n             self.best_estimator_ = clone(base_estimator).set_params(\n                 **self.best_params_)\n+            refit_start_time = time.time()\n             if y is not None:\n                 self.best_estimator_.fit(X, y, **fit_params)\n             else:\n                 self.best_estimator_.fit(X, **fit_params)\n+            self.refit_time_ = time.time() - refit_start_time\n \n         # Store the only scorer not as a dict for single metric evaluation\n         self.scorer_ = scorers if self.multimetric_ else scorers['score']\n@@ -1076,6 +1079,11 @@ class GridSearchCV(BaseSearchCV):\n     n_splits_ : int\n         The number of cross-validation splits (folds/iterations).\n \n+    refit_time_ : float\n+        Seconds used for refitting the best model on the whole dataset.\n+\n+        This is present only if ``refit`` is not False.\n+\n     Notes\n     ------\n     The parameters selected are those that maximize the score of the left out\n@@ -1387,6 +1395,11 @@ class RandomizedSearchCV(BaseSearchCV):\n     n_splits_ : int\n         The number of cross-validation splits (folds/iterations).\n \n+    refit_time_ : float\n+        Seconds used for refitting the best model on the whole dataset.\n+\n+        This is present only if ``refit`` is not False.\n+\n     Notes\n     -----\n     The parameters selected are those that maximize the score of the held-out\ndiff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py\nindex f436c7b55..755a23128 100644\n--- a/sklearn/model_selection/tests/test_search.py\n+++ b/sklearn/model_selection/tests/test_search.py\n@@ -640,6 +640,54 @@ def test_refit():\n     clf.fit(X, y)\n \n \n+def test_refit_time():\n+    \"\"\"Test that refit_time_ attribute is available after fitting.\"\"\"\n+    X = np.arange(100).reshape(10, 10)\n+    y = np.array([0] * 5 + [1] * 5)\n+    \n+    # Test GridSearchCV with refit=True\n+    clf = GridSearchCV(MockClassifier(), {'foo_param': [1, 2, 3]}, refit=True)\n+    clf.fit(X, y)\n+    assert_true(hasattr(clf, 'refit_time_'))\n+    assert_true(isinstance(clf.refit_time_, float))\n+    assert_true(clf.refit_time_ > 0)\n+    \n+    # Test GridSearchCV with refit=False\n+    clf_no_refit = GridSearchCV(MockClassifier(), {'foo_param': [1, 2, 3]}, \n+                                refit=False)\n+    clf_no_refit.fit(X, y)\n+    assert_false(hasattr(clf_no_refit, 'refit_time_'))\n+    \n+    # Test RandomizedSearchCV with refit=True\n+    clf_random = RandomizedSearchCV(MockClassifier(), \n+                                    {'foo_param': [1, 2, 3, 4, 5]}, \n+                                    n_iter=3, refit=True)\n+    clf_random.fit(X, y)\n+    assert_true(hasattr(clf_random, 'refit_time_'))\n+    assert_true(isinstance(clf_random.refit_time_, float))\n+    assert_true(clf_random.refit_time_ > 0)\n+    \n+    # Test RandomizedSearchCV with refit=False\n+    clf_random_no_refit = RandomizedSearchCV(MockClassifier(), \n+                                             {'foo_param': [1, 2, 3, 4, 5]}, \n+                                             n_iter=3, refit=False)\n+    clf_random_no_refit.fit(X, y)\n+    assert_false(hasattr(clf_random_no_refit, 'refit_time_'))\n+    \n+    # Test with multiple metrics\n+    def custom_scorer(y_true, y_pred):\n+        return 1.0\n+    \n+    scoring = {'score1': make_scorer(custom_scorer), \n+               'score2': make_scorer(custom_scorer)}\n+    clf_multi = GridSearchCV(MockClassifier(), {'foo_param': [1, 2]}, \n+                             scoring=scoring, refit='score1')\n+    clf_multi.fit(X, y)\n+    assert_true(hasattr(clf_multi, 'refit_time_'))\n+    assert_true(isinstance(clf_multi.refit_time_, float))\n+    assert_true(clf_multi.refit_time_ > 0)\n+\n+\n def test_gridsearch_nd():\n     # Pass X as list in GridSearchCV\n     X_4d = np.arange(10 * 5 * 3 * 2).reshape(10, 5, 3, 2)\ndiff --git a/test_original_example.py b/test_original_example.py\nnew file mode 100644\nindex 000000000..2ff4b7947\n--- /dev/null\n+++ b/test_original_example.py\n@@ -0,0 +1,16 @@\n+import sklearn.datasets\n+import sklearn.model_selection\n+import sklearn.ensemble\n+\n+X, y = sklearn.datasets.load_iris(return_X_y=True)\n+\n+rs = sklearn.model_selection.GridSearchCV(\n+    estimator=sklearn.ensemble.RandomForestClassifier(),\n+    param_grid={'n_estimators': [2, 3, 4, 5]}\n+)\n+rs.fit(X, y)\n+print(rs.cv_results_['mean_fit_time'])\n+print(rs.cv_results_['mean_score_time'])\n+\n+# New attribute we added\n+print(f\"\\nRefit time: {rs.refit_time_} seconds\")\ndiff --git a/test_refit_time.py b/test_refit_time.py\nnew file mode 100644\nindex 000000000..b2bfa6f3f\n--- /dev/null\n+++ b/test_refit_time.py\n@@ -0,0 +1,59 @@\n+import sklearn.datasets\n+import sklearn.model_selection\n+import sklearn.ensemble\n+import numpy as np\n+\n+# Test GridSearchCV\n+print(\"Testing GridSearchCV with refit=True:\")\n+X, y = sklearn.datasets.load_iris(return_X_y=True)\n+\n+rs = sklearn.model_selection.GridSearchCV(\n+    estimator=sklearn.ensemble.RandomForestClassifier(),\n+    param_grid={'n_estimators': [2, 3, 4, 5]}\n+)\n+rs.fit(X, y)\n+\n+print(f\"Mean fit time for folds: {rs.cv_results_['mean_fit_time']}\")\n+print(f\"Mean score time for folds: {rs.cv_results_['mean_score_time']}\")\n+print(f\"Refit time: {rs.refit_time_:.6f} seconds\")\n+print(f\"Has refit_time_ attribute: {hasattr(rs, 'refit_time_')}\")\n+print()\n+\n+# Test GridSearchCV with refit=False\n+print(\"Testing GridSearchCV with refit=False:\")\n+rs_no_refit = sklearn.model_selection.GridSearchCV(\n+    estimator=sklearn.ensemble.RandomForestClassifier(),\n+    param_grid={'n_estimators': [2, 3, 4, 5]},\n+    refit=False\n+)\n+rs_no_refit.fit(X, y)\n+print(f\"Has refit_time_ attribute: {hasattr(rs_no_refit, 'refit_time_')}\")\n+print()\n+\n+# Test RandomizedSearchCV\n+print(\"Testing RandomizedSearchCV with refit=True:\")\n+rs_random = sklearn.model_selection.RandomizedSearchCV(\n+    estimator=sklearn.ensemble.RandomForestClassifier(),\n+    param_distributions={'n_estimators': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n+    n_iter=4\n+)\n+rs_random.fit(X, y)\n+print(f\"Refit time: {rs_random.refit_time_:.6f} seconds\")\n+print(f\"Has refit_time_ attribute: {hasattr(rs_random, 'refit_time_')}\")\n+print()\n+\n+# Test with n_jobs != 1\n+print(\"Testing GridSearchCV with n_jobs=2:\")\n+rs_parallel = sklearn.model_selection.GridSearchCV(\n+    estimator=sklearn.ensemble.RandomForestClassifier(),\n+    param_grid={'n_estimators': [2, 3, 4, 5]},\n+    n_jobs=2\n+)\n+rs_parallel.fit(X, y)\n+print(f\"Refit time with n_jobs=2: {rs_parallel.refit_time_:.6f} seconds\")\n+print()\n+\n+# Verify refit_time_ is reasonable\n+print(\"Sanity check - refit_time_ should be positive and reasonable:\")\n+print(f\"Refit time > 0: {rs.refit_time_ > 0}\")\n+print(f\"Refit time < 10 seconds (for small dataset): {rs.refit_time_ < 10}\")\ndiff --git a/test_refit_time_unit.py b/test_refit_time_unit.py\nnew file mode 100644\nindex 000000000..e69de29bb\ndiff --git a/test_simple.py b/test_simple.py\nnew file mode 100644\nindex 000000000..a102e6036\n--- /dev/null\n+++ b/test_simple.py\n@@ -0,0 +1,17 @@\n+from sklearn.datasets import make_classification\n+from sklearn.model_selection import GridSearchCV\n+from sklearn.svm import SVC\n+\n+X, y = make_classification(n_samples=50, n_features=5, random_state=42)\n+\n+gs = GridSearchCV(\n+    SVC(),\n+    param_grid={'C': [0.1, 1.0]},\n+    cv=2,\n+    refit=True\n+)\n+gs.fit(X, y)\n+\n+print(f\"Has refit_time_: {hasattr(gs, 'refit_time_')}\")\n+if hasattr(gs, 'refit_time_'):\n+    print(f\"Refit time: {gs.refit_time_}\")\n", "gold_standard_diff": "diff --git a/doc/whats_new/v0.20.rst b/doc/whats_new/v0.20.rst\nindex 32b4ef3098263..b5a43b0b8fc3b 100644\n--- a/doc/whats_new/v0.20.rst\n+++ b/doc/whats_new/v0.20.rst\n@@ -253,6 +253,13 @@ Model evaluation and meta-estimators\n   return estimators fitted on each split. :issue:`9686` by :user:`Aur\u00e9lien Bellet\n   <bellet>`.\n \n+- New ``refit_time_`` attribute will be stored in\n+  :class:`model_selection.GridSearchCV` and\n+  :class:`model_selection.RandomizedSearchCV` if ``refit`` is set to ``True``.\n+  This will allow measuring the complete time it takes to perform\n+  hyperparameter optimization and refitting the best model on the whole\n+  dataset. :issue:`11310` by :user:`Matthias Feurer <mfeurer>`.\n+\n Decomposition and manifold learning\n \n - Speed improvements for both 'exact' and 'barnes_hut' methods in\ndiff --git a/sklearn/model_selection/_search.py b/sklearn/model_selection/_search.py\nindex 99d6096af73db..a339b9b167634 100644\n--- a/sklearn/model_selection/_search.py\n+++ b/sklearn/model_selection/_search.py\n@@ -17,6 +17,7 @@\n from functools import partial, reduce\n from itertools import product\n import operator\n+import time\n import warnings\n \n import numpy as np\n@@ -766,10 +767,13 @@ def _store(key_name, array, weights=None, splits=False, rank=False):\n         if self.refit:\n             self.best_estimator_ = clone(base_estimator).set_params(\n                 **self.best_params_)\n+            refit_start_time = time.time()\n             if y is not None:\n                 self.best_estimator_.fit(X, y, **fit_params)\n             else:\n                 self.best_estimator_.fit(X, **fit_params)\n+            refit_end_time = time.time()\n+            self.refit_time_ = refit_end_time - refit_start_time\n \n         # Store the only scorer not as a dict for single metric evaluation\n         self.scorer_ = scorers if self.multimetric_ else scorers['score']\n@@ -1076,6 +1080,11 @@ class GridSearchCV(BaseSearchCV):\n     n_splits_ : int\n         The number of cross-validation splits (folds/iterations).\n \n+    refit_time_ : float\n+        Seconds used for refitting the best model on the whole dataset.\n+\n+        This is present only if ``refit`` is not False.\n+\n     Notes\n     ------\n     The parameters selected are those that maximize the score of the left out\n@@ -1387,6 +1396,11 @@ class RandomizedSearchCV(BaseSearchCV):\n     n_splits_ : int\n         The number of cross-validation splits (folds/iterations).\n \n+    refit_time_ : float\n+        Seconds used for refitting the best model on the whole dataset.\n+\n+        This is present only if ``refit`` is not False.\n+\n     Notes\n     -----\n     The parameters selected are those that maximize the score of the held-out\ndiff --git a/sklearn/model_selection/tests/test_search.py b/sklearn/model_selection/tests/test_search.py\nindex f436c7b55cf36..0b7b0338f9ada 100644\n--- a/sklearn/model_selection/tests/test_search.py\n+++ b/sklearn/model_selection/tests/test_search.py\n@@ -26,6 +26,7 @@\n from sklearn.utils.testing import assert_array_equal\n from sklearn.utils.testing import assert_array_almost_equal\n from sklearn.utils.testing import assert_almost_equal\n+from sklearn.utils.testing import assert_greater_equal\n from sklearn.utils.testing import ignore_warnings\n from sklearn.utils.mocking import CheckingClassifier, MockDataFrame\n \n@@ -1172,6 +1173,10 @@ def test_search_cv_timing():\n             assert_true(search.cv_results_[key][0] == 0.0)\n             assert_true(np.all(search.cv_results_[key] < 1))\n \n+        assert_true(hasattr(search, \"refit_time_\"))\n+        assert_true(isinstance(search.refit_time_, float))\n+        assert_greater_equal(search.refit_time_, 0)\n+\n \n def test_grid_search_correct_score_results():\n     # test that correct scores are used\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/11310"}