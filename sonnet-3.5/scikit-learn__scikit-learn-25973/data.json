{"instance_id": "scikit-learn__scikit-learn-25973", "score": "C", "diff": "diff --git a/sklearn/feature_selection/_sequential.py b/sklearn/feature_selection/_sequential.py\nindex e983c55de..5d5947b48 100644\n--- a/sklearn/feature_selection/_sequential.py\n+++ b/sklearn/feature_selection/_sequential.py\n@@ -14,7 +14,7 @@ from ..utils._param_validation import RealNotInt\n from ..utils._tags import _safe_tags\n from ..utils.validation import check_is_fitted\n from ..model_selection import cross_val_score\n-from ..metrics import get_scorer_names\n+from ..metrics import get_scorer_names, get_scorer\n \n \n class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator):\n@@ -305,17 +305,35 @@ class SequentialFeatureSelector(SelectorMixin, MetaEstimatorMixin, BaseEstimator\n             if self.direction == \"backward\":\n                 candidate_mask = ~candidate_mask\n             X_new = X[:, candidate_mask]\n-            scores[feature_idx] = cross_val_score(\n-                estimator,\n-                X_new,\n-                y,\n-                cv=self.cv,\n-                scoring=self.scoring,\n-                n_jobs=self.n_jobs,\n-            ).mean()\n+            if hasattr(self.cv, '__iter__'):\n+                # If cv is an iterable of splits, use it directly\n+                cv_splits = list(self.cv)\n+                scores[feature_idx] = np.mean([\n+                    self._score(estimator, X_new, y, train, test)\n+                    for train, test in cv_splits\n+                ])\n+            else:\n+                scores[feature_idx] = cross_val_score(\n+                    estimator,\n+                    X_new,\n+                    y,\n+                    cv=self.cv,\n+                    scoring=self.scoring,\n+                    n_jobs=self.n_jobs,\n+                ).mean()\n         new_feature_idx = max(scores, key=lambda feature_idx: scores[feature_idx])\n         return new_feature_idx, scores[new_feature_idx]\n \n+    def _score(self, estimator, X, y, train, test):\n+        # Helper method to compute the score for a single split\n+        X_train, X_test = X[train], X[test]\n+        y_train, y_test = y[train], y[test]\n+        estimator.fit(X_train, y_train)\n+        if self.scoring is None:\n+            return estimator.score(X_test, y_test)\n+        scorer = get_scorer(self.scoring)\n+        return scorer(estimator, X_test, y_test)\n+\n     def _get_support_mask(self):\n         check_is_fitted(self)\n         return self.support_\n", "gold_standard_diff": "From 9d4a3562b87e79f309b4f71fdc0d2b4ae9983372 Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Sat, 25 Mar 2023 20:39:21 +0800\nSubject: [PATCH 1/7] checked cv to make sure generators are supported\n\n---\n sklearn/feature_selection/_sequential.py      | 12 ++++----\n .../tests/test_sequential.py                  | 30 +++++++++++++++++--\n 2 files changed, 35 insertions(+), 7 deletions(-)\n\ndiff --git a/sklearn/feature_selection/_sequential.py b/sklearn/feature_selection/_sequential.py\nindex e983c55de7d25..2498cd53b39f6 100644\n--- a/sklearn/feature_selection/_sequential.py\n+++ b/sklearn/feature_selection/_sequential.py\n@@ -8,12 +8,12 @@\n import warnings\n \n from ._base import SelectorMixin\n-from ..base import BaseEstimator, MetaEstimatorMixin, clone\n+from ..base import BaseEstimator, MetaEstimatorMixin, clone, is_classifier\n from ..utils._param_validation import HasMethods, Hidden, Interval, StrOptions\n from ..utils._param_validation import RealNotInt\n from ..utils._tags import _safe_tags\n from ..utils.validation import check_is_fitted\n-from ..model_selection import cross_val_score\n+from ..model_selection import cross_val_score, check_cv\n from ..metrics import get_scorer_names\n \n \n@@ -259,6 +259,8 @@ def fit(self, X, y=None):\n         if self.tol is not None and self.tol < 0 and self.direction == \"forward\":\n             raise ValueError(\"tol must be positive when doing forward selection\")\n \n+        cv = check_cv(self.cv, y, classifier=is_classifier(self.estimator))\n+\n         cloned_estimator = clone(self.estimator)\n \n         # the current mask corresponds to the set of features:\n@@ -275,7 +277,7 @@ def fit(self, X, y=None):\n         is_auto_select = self.tol is not None and self.n_features_to_select == \"auto\"\n         for _ in range(n_iterations):\n             new_feature_idx, new_score = self._get_best_new_feature_score(\n-                cloned_estimator, X, y, current_mask\n+                cloned_estimator, X, y, cv, current_mask\n             )\n             if is_auto_select and ((new_score - old_score) < self.tol):\n                 break\n@@ -291,7 +293,7 @@ def fit(self, X, y=None):\n \n         return self\n \n-    def _get_best_new_feature_score(self, estimator, X, y, current_mask):\n+    def _get_best_new_feature_score(self, estimator, X, y, cv, current_mask):\n         # Return the best new feature and its score to add to the current_mask,\n         # i.e. return the best new feature and its score to add (resp. remove)\n         # when doing forward selection (resp. backward selection).\n@@ -309,7 +311,7 @@ def _get_best_new_feature_score(self, estimator, X, y, current_mask):\n                 estimator,\n                 X_new,\n                 y,\n-                cv=self.cv,\n+                cv=cv,\n                 scoring=self.scoring,\n                 n_jobs=self.n_jobs,\n             ).mean()\ndiff --git a/sklearn/feature_selection/tests/test_sequential.py b/sklearn/feature_selection/tests/test_sequential.py\nindex f6451a36005ac..e99d19d7b4b88 100644\n--- a/sklearn/feature_selection/tests/test_sequential.py\n+++ b/sklearn/feature_selection/tests/test_sequential.py\n@@ -6,11 +6,12 @@\n from sklearn.preprocessing import StandardScaler\n from sklearn.pipeline import make_pipeline\n from sklearn.feature_selection import SequentialFeatureSelector\n-from sklearn.datasets import make_regression, make_blobs\n+from sklearn.datasets import make_regression, make_blobs, make_classification\n from sklearn.linear_model import LinearRegression\n from sklearn.ensemble import HistGradientBoostingRegressor\n-from sklearn.model_selection import cross_val_score\n+from sklearn.model_selection import cross_val_score, LeaveOneGroupOut\n from sklearn.cluster import KMeans\n+from sklearn.neighbors import KNeighborsClassifier\n \n \n def test_bad_n_features_to_select():\n@@ -314,3 +315,28 @@ def test_backward_neg_tol():\n \n     assert 0 < sfs.get_support().sum() < X.shape[1]\n     assert new_score < initial_score\n+\n+\n+def test_cv_generator_support():\n+    \"\"\"Check that we support cv that is a generator.\n+\n+    non-regression test for #25957\n+    \"\"\"\n+    X, y = make_classification()\n+\n+    groups = np.zeros_like(y, dtype=int)\n+    groups[y.size // 2 :] = 1\n+\n+    cv = LeaveOneGroupOut()\n+    splits = cv.split(X, y, groups=groups)\n+\n+    knc = KNeighborsClassifier(n_neighbors=5)\n+\n+    sfs = SequentialFeatureSelector(\n+        knc, n_features_to_select=5, scoring=\"accuracy\", cv=splits\n+    )\n+\n+    try:\n+        sfs.fit(X, y)\n+    except Exception:\n+        pytest.fail(\"Failed to support cv that is a generator\")\n\nFrom c958c880a7e685a5d436d533aaea8529ca2988d5 Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Sat, 25 Mar 2023 21:31:50 +0800\nSubject: [PATCH 2/7] added changelog\n\n---\n doc/whats_new/v1.3.rst | 3 +++\n 1 file changed, 3 insertions(+)\n\ndiff --git a/doc/whats_new/v1.3.rst b/doc/whats_new/v1.3.rst\nindex 51b4214145216..6fd62e9dd1caf 100644\n--- a/doc/whats_new/v1.3.rst\n+++ b/doc/whats_new/v1.3.rst\n@@ -146,6 +146,9 @@ Changelog\n - |Enhancement| All selectors in :mod:`sklearn.feature_selection` will preserve\n   a DataFrame's dtype when transformed. :pr:`25102` by `Thomas Fan`_.\n \n+- |Fix| :class:`feature_selection.SequentialFeatureSelector` now does not throw\n+  IndexError when `cv` is a generator. :pr:`25973` by `Yao Xiao <Charlie-XIAO>`.\n+\n :mod:`sklearn.base`\n ...................\n \n\nFrom 4192f3ad1eb60f791d5f61353c2387d49d7e4c5d Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Sat, 25 Mar 2023 21:34:04 +0800\nSubject: [PATCH 3/7] modified regression test description and errmsg a bit\n\n---\n sklearn/feature_selection/tests/test_sequential.py | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a/sklearn/feature_selection/tests/test_sequential.py b/sklearn/feature_selection/tests/test_sequential.py\nindex e99d19d7b4b88..2568ae80b5053 100644\n--- a/sklearn/feature_selection/tests/test_sequential.py\n+++ b/sklearn/feature_selection/tests/test_sequential.py\n@@ -318,7 +318,7 @@ def test_backward_neg_tol():\n \n \n def test_cv_generator_support():\n-    \"\"\"Check that we support cv that is a generator.\n+    \"\"\"Check that we does not throw exception when cv is generator\n \n     non-regression test for #25957\n     \"\"\"\n@@ -339,4 +339,4 @@ def test_cv_generator_support():\n     try:\n         sfs.fit(X, y)\n     except Exception:\n-        pytest.fail(\"Failed to support cv that is a generator\")\n+        pytest.fail(\"Should not throw exception when cv is generator\")\n\nFrom 2141626813206987f7ea1dafab3e2103f158bcf9 Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Sat, 25 Mar 2023 22:43:04 +0800\nSubject: [PATCH 4/7] removed lines uncovered by test\n\n---\n sklearn/feature_selection/tests/test_sequential.py | 8 ++------\n 1 file changed, 2 insertions(+), 6 deletions(-)\n\ndiff --git a/sklearn/feature_selection/tests/test_sequential.py b/sklearn/feature_selection/tests/test_sequential.py\nindex 2568ae80b5053..02208731cb977 100644\n--- a/sklearn/feature_selection/tests/test_sequential.py\n+++ b/sklearn/feature_selection/tests/test_sequential.py\n@@ -318,7 +318,7 @@ def test_backward_neg_tol():\n \n \n def test_cv_generator_support():\n-    \"\"\"Check that we does not throw exception when cv is generator\n+    \"\"\"Check that no exception raised when cv is generator\n \n     non-regression test for #25957\n     \"\"\"\n@@ -335,8 +335,4 @@ def test_cv_generator_support():\n     sfs = SequentialFeatureSelector(\n         knc, n_features_to_select=5, scoring=\"accuracy\", cv=splits\n     )\n-\n-    try:\n-        sfs.fit(X, y)\n-    except Exception:\n-        pytest.fail(\"Should not throw exception when cv is generator\")\n+    sfs.fit(X, y)\n\nFrom 4515c23c71a77bd1de8683c1a8d36b523ff27bc9 Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Tue, 28 Mar 2023 23:33:12 +0800\nSubject: [PATCH 5/7] resolved conversations\n\n---\n sklearn/feature_selection/tests/test_sequential.py | 8 +++-----\n 1 file changed, 3 insertions(+), 5 deletions(-)\n\ndiff --git a/sklearn/feature_selection/tests/test_sequential.py b/sklearn/feature_selection/tests/test_sequential.py\nindex 02208731cb977..7c02d32696178 100644\n--- a/sklearn/feature_selection/tests/test_sequential.py\n+++ b/sklearn/feature_selection/tests/test_sequential.py\n@@ -322,7 +322,7 @@ def test_cv_generator_support():\n \n     non-regression test for #25957\n     \"\"\"\n-    X, y = make_classification()\n+    X, y = make_classification(random_state=0)\n \n     groups = np.zeros_like(y, dtype=int)\n     groups[y.size // 2 :] = 1\n@@ -330,9 +330,7 @@ def test_cv_generator_support():\n     cv = LeaveOneGroupOut()\n     splits = cv.split(X, y, groups=groups)\n \n-    knc = KNeighborsClassifier(n_neighbors=5)\n+    knc = KNeighborsClassifier(n_neighbors=5, random_state=0)\n \n-    sfs = SequentialFeatureSelector(\n-        knc, n_features_to_select=5, scoring=\"accuracy\", cv=splits\n-    )\n+    sfs = SequentialFeatureSelector(knc, n_features_to_select=5, cv=splits)\n     sfs.fit(X, y)\n\nFrom 591e19e711d1d2fbc4ac8ccb36210495fc75f7c0 Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Wed, 29 Mar 2023 01:29:48 +0800\nSubject: [PATCH 6/7] test random_state=0 removed: knc does not take random\n state\n\n---\n sklearn/feature_selection/tests/test_sequential.py | 2 +-\n 1 file changed, 1 insertion(+), 1 deletion(-)\n\ndiff --git a/sklearn/feature_selection/tests/test_sequential.py b/sklearn/feature_selection/tests/test_sequential.py\nindex 7c02d32696178..98134addc39e7 100644\n--- a/sklearn/feature_selection/tests/test_sequential.py\n+++ b/sklearn/feature_selection/tests/test_sequential.py\n@@ -330,7 +330,7 @@ def test_cv_generator_support():\n     cv = LeaveOneGroupOut()\n     splits = cv.split(X, y, groups=groups)\n \n-    knc = KNeighborsClassifier(n_neighbors=5, random_state=0)\n+    knc = KNeighborsClassifier(n_neighbors=5)\n \n     sfs = SequentialFeatureSelector(knc, n_features_to_select=5, cv=splits)\n     sfs.fit(X, y)\n\nFrom e6c6eea1872ee42ec6d0bc290ed7ae0bedd81b12 Mon Sep 17 00:00:00 2001\nFrom: Charlie-XIAO <yx2436@nyu.edu>\nDate: Wed, 29 Mar 2023 04:05:23 +0800\nSubject: [PATCH 7/7] modified changelog\n\n---\n doc/whats_new/v1.3.rst | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n\ndiff --git a/doc/whats_new/v1.3.rst b/doc/whats_new/v1.3.rst\nindex 6fd62e9dd1caf..add8f896dcb1a 100644\n--- a/doc/whats_new/v1.3.rst\n+++ b/doc/whats_new/v1.3.rst\n@@ -146,8 +146,8 @@ Changelog\n - |Enhancement| All selectors in :mod:`sklearn.feature_selection` will preserve\n   a DataFrame's dtype when transformed. :pr:`25102` by `Thomas Fan`_.\n \n-- |Fix| :class:`feature_selection.SequentialFeatureSelector` now does not throw\n-  IndexError when `cv` is a generator. :pr:`25973` by `Yao Xiao <Charlie-XIAO>`.\n+- |Fix| :class:`feature_selection.SequentialFeatureSelector`'s `cv` parameter\n+  now supports generators. :pr:`25973` by `Yao Xiao <Charlie-XIAO>`.\n \n :mod:`sklearn.base`\n ...................\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/25973"}