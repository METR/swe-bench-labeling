{"instance_id": "scikit-learn__scikit-learn-13779", "score": "C", "diff": "diff --git a/sklearn/ensemble/tests/test_voting.py b/sklearn/ensemble/tests/test_voting.py\nindex 2a19bc9a6..d5620535c 100644\n--- a/sklearn/ensemble/tests/test_voting.py\n+++ b/sklearn/ensemble/tests/test_voting.py\n@@ -507,3 +507,30 @@ def test_transform():\n             eclf3.transform(X).swapaxes(0, 1).reshape((4, 6)),\n             eclf2.transform(X)\n     )\n+\n+\n+@pytest.mark.filterwarnings(\"ignore: Default solver will be changed\")  # 0.22\n+@pytest.mark.filterwarnings(\"ignore: Default multi_class will\")  # 0.22\n+@pytest.mark.filterwarnings(\"ignore:The default value of n_estimators\")\n+def test_none_estimator_with_weights():\n+    \"\"\"Test that voting estimators can handle sample weights when an estimator is None.\"\"\"\n+    clf1 = LogisticRegression(random_state=123)\n+    clf2 = RandomForestClassifier(random_state=123)\n+    \n+    # Test VotingClassifier\n+    eclf = VotingClassifier(estimators=[(\"lr\", clf1), (\"rf\", clf2)], voting=\"soft\")\n+    eclf.fit(X, y, sample_weight=np.ones(y.shape))\n+    \n+    # Set one estimator to None and refit with weights\n+    eclf.set_params(lr=None)\n+    eclf.fit(X, y, sample_weight=np.ones(y.shape))  # Should not raise AttributeError\n+    \n+    # Test VotingRegressor\n+    reg1 = DummyRegressor(strategy=\"mean\")\n+    reg2 = DummyRegressor(strategy=\"median\")\n+    ereg = VotingRegressor(estimators=[(\"dr1\", reg1), (\"dr2\", reg2)])\n+    ereg.fit(X_r, y_r, sample_weight=np.ones(y_r.shape))\n+    \n+    # Set one estimator to None and refit with weights\n+    ereg.set_params(dr1=None)\n+    ereg.fit(X_r, y_r, sample_weight=np.ones(y_r.shape))  # Should not raise AttributeError\ndiff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180c..13accdcec 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,7 +78,7 @@ class _BaseVoting(_BaseComposition, TransformerMixin):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n-                if not has_fit_parameter(step, 'sample_weight'):\n+                if step is not None and not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n \n", "gold_standard_diff": "diff --git a/doc/whats_new/v0.21.rst b/doc/whats_new/v0.21.rst\nindex 473bbf91878d5..3dcb8b31773c7 100644\n--- a/doc/whats_new/v0.21.rst\n+++ b/doc/whats_new/v0.21.rst\n@@ -319,6 +319,11 @@ Support for Python 3.4 and below has been officially dropped.\n   :pr:`12599` by :user:`Trevor Stephens<trevorstephens>` and\n   :user:`Nicolas Hug<NicolasHug>`.\n \n+- |Fix| :class:`ensemble.VotingClassifier` and\n+  :class:`ensemble.VotingRegressor` were failing during ``fit`` in one\n+  of the estimators was set to ``None`` and ``sample_weight`` was not ``None``.\n+  :pr:`13779` by :user:`Guillaume Lemaitre <glemaitre>`.\n+\n :mod:`sklearn.externals`\n ........................\n \ndiff --git a/sklearn/ensemble/tests/test_voting.py b/sklearn/ensemble/tests/test_voting.py\nindex 2a19bc9a64dc0..0a4a9eab8c160 100644\n--- a/sklearn/ensemble/tests/test_voting.py\n+++ b/sklearn/ensemble/tests/test_voting.py\n@@ -8,9 +8,11 @@\n from sklearn.utils.testing import assert_equal\n from sklearn.utils.testing import assert_raise_message\n from sklearn.exceptions import NotFittedError\n+from sklearn.linear_model import LinearRegression\n from sklearn.linear_model import LogisticRegression\n from sklearn.naive_bayes import GaussianNB\n from sklearn.ensemble import RandomForestClassifier\n+from sklearn.ensemble import RandomForestRegressor\n from sklearn.ensemble import VotingClassifier, VotingRegressor\n from sklearn.model_selection import GridSearchCV\n from sklearn import datasets\n@@ -507,3 +509,25 @@ def test_transform():\n             eclf3.transform(X).swapaxes(0, 1).reshape((4, 6)),\n             eclf2.transform(X)\n     )\n+\n+\n+@pytest.mark.filterwarnings('ignore: Default solver will be changed')  # 0.22\n+@pytest.mark.filterwarnings('ignore: Default multi_class will')  # 0.22\n+@pytest.mark.parametrize(\n+    \"X, y, voter\",\n+    [(X, y, VotingClassifier(\n+        [('lr', LogisticRegression()),\n+         ('rf', RandomForestClassifier(n_estimators=5))])),\n+     (X_r, y_r, VotingRegressor(\n+         [('lr', LinearRegression()),\n+          ('rf', RandomForestRegressor(n_estimators=5))]))]\n+)\n+def test_none_estimator_with_weights(X, y, voter):\n+    # check that an estimator can be set to None and passing some weight\n+    # regression test for\n+    # https://github.com/scikit-learn/scikit-learn/issues/13777\n+    voter.fit(X, y, sample_weight=np.ones(y.shape))\n+    voter.set_params(lr=None)\n+    voter.fit(X, y, sample_weight=np.ones(y.shape))\n+    y_pred = voter.predict(X)\n+    assert y_pred.shape == y.shape\ndiff --git a/sklearn/ensemble/voting.py b/sklearn/ensemble/voting.py\nindex 7afa7180cc5f3..d8e14b152d3ab 100644\n--- a/sklearn/ensemble/voting.py\n+++ b/sklearn/ensemble/voting.py\n@@ -78,6 +78,8 @@ def fit(self, X, y, sample_weight=None):\n \n         if sample_weight is not None:\n             for name, step in self.estimators:\n+                if step is None:\n+                    continue\n                 if not has_fit_parameter(step, 'sample_weight'):\n                     raise ValueError('Underlying estimator \\'%s\\' does not'\n                                      ' support sample weights.' % name)\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/13779"}