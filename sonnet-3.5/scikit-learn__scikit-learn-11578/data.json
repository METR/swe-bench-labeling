{"instance_id": "scikit-learn__scikit-learn-11578", "score": "C", "diff": "diff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex e4ea696ce..f3d519ca7 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -775,7 +775,7 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n                           scoring=None, fit_intercept=False,\n                           max_iter=100, tol=1e-4, class_weight=None,\n                           verbose=0, solver='lbfgs', penalty='l2',\n-                          dual=False, intercept_scaling=1.,\n+                          dual=False, intercept_scaling=1.0,\n                           multi_class='ovr', random_state=None,\n                           max_squared_sum=None, sample_weight=None):\n     \"\"\"Computes scores across logistic_regression_path\n@@ -922,7 +922,7 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(fit_intercept=fit_intercept, multi_class=multi_class, penalty=penalty, dual=dual, tol=tol, C=1.0, intercept_scaling=intercept_scaling, class_weight=class_weight, random_state=random_state, solver=solver, max_iter=max_iter)\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\n", "gold_standard_diff": "From 748467f010249fe24b5178a7efeb2a39625b86ac Mon Sep 17 00:00:00 2001\nFrom: William de Vazelhes <william.de-vazelhes@inria.fr>\nDate: Tue, 17 Jul 2018 01:18:57 +0200\nSubject: [PATCH 1/4] FIX: fixes multinomial scoring for LogisticRegressionCV\n\n---\n sklearn/linear_model/logistic.py            |  2 +-\n sklearn/linear_model/tests/test_logistic.py | 34 ++++++++++++++++++++-\n 2 files changed, 34 insertions(+), 2 deletions(-)\n\ndiff --git a/sklearn/linear_model/logistic.py b/sklearn/linear_model/logistic.py\nindex e4ea696ce7146..a3afb06e449c4 100644\n--- a/sklearn/linear_model/logistic.py\n+++ b/sklearn/linear_model/logistic.py\n@@ -922,7 +922,7 @@ def _log_reg_scoring_path(X, y, train, test, pos_class=None, Cs=10,\n         check_input=False, max_squared_sum=max_squared_sum,\n         sample_weight=sample_weight)\n \n-    log_reg = LogisticRegression(fit_intercept=fit_intercept)\n+    log_reg = LogisticRegression(multi_class=multi_class)\n \n     # The score method of Logistic Regression has a classes_ attribute.\n     if multi_class == 'ovr':\ndiff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex 56be87f71015a..53ab5a2aa277c 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -6,6 +6,7 @@\n \n from sklearn.datasets import load_iris, make_classification\n from sklearn.metrics import log_loss\n+from sklearn.metrics.scorer import get_scorer\n from sklearn.model_selection import StratifiedKFold\n from sklearn.preprocessing import LabelEncoder\n from sklearn.utils import compute_class_weight\n@@ -29,7 +30,7 @@\n     logistic_regression_path, LogisticRegressionCV,\n     _logistic_loss_and_grad, _logistic_grad_hess,\n     _multinomial_grad_hess, _logistic_loss,\n-)\n+    _log_reg_scoring_path)\n \n X = [[-1, 0], [0, 1], [1, 1]]\n X_sp = sp.csr_matrix(X)\n@@ -492,6 +493,37 @@ def test_logistic_cv():\n     assert_array_equal(scores.shape, (1, 3, 1))\n \n \n+@pytest.mark.parametrize('scoring', ['accuracy', 'f1', 'neg_log_loss',\n+                                     'precision', 'recall'])\n+def test_logistic_cv_multinomial_score(scoring):\n+    # test that LogisticRegressionCV uses the right score to compute its\n+    # cross-validation scores when using a multinomial scoring\n+    # see https://github.com/scikit-learn/scikit-learn/issues/8720\n+    X, y = make_classification(n_samples=100, random_state=0, n_classes=3,\n+                               n_informative=6)\n+    train, test = np.arange(80), np.arange(80, 100)\n+    lr = LogisticRegression(C=1., solver='lbfgs', multi_class='multinomial')\n+    # we use lbfgs to support multinomial\n+    params = lr.get_params()\n+    # we store the params to set them further in _log_reg_scoring_path\n+    for key in ['C', 'n_jobs', 'warm_start']:\n+        del(params[key])\n+    lr.fit(X[train], y[train])\n+    if scoring in ['f1', 'precision', 'recall']:\n+        for averaging in ['micro', 'macro', 'weighted']:\n+            scorer = get_scorer('{0}_{1}'.format(scoring, averaging))\n+            np.testing.assert_array_almost_equal(\n+                _log_reg_scoring_path(X, y, train, test, Cs=[1.], **params,\n+                                      scoring=scorer)[2][0],\n+                scorer(lr, X[test], y[test]))\n+    else:\n+        scorer = get_scorer(scoring)\n+        np.testing.assert_array_almost_equal(\n+            _log_reg_scoring_path(X, y, train, test, Cs=[1.], **params,\n+                                  scoring=scorer)[2][0],\n+            scorer(lr, X[test], y[test]))\n+\n+\n def test_multinomial_logistic_regression_string_inputs():\n     # Test with string labels for LogisticRegression(CV)\n     n_samples, n_features, n_classes = 50, 5, 3\n\nFrom e8a3180aed182fc9d47eb4494322b4e22111ad1d Mon Sep 17 00:00:00 2001\nFrom: William de Vazelhes <william.de-vazelhes@inria.fr>\nDate: Tue, 17 Jul 2018 16:21:14 +0200\nSubject: [PATCH 2/4] MAINT: changes according to review\n https://github.com/scikit-learn/scikit-learn/pull/11578#pullrequestreview-137785752\n\n---\n sklearn/linear_model/tests/test_logistic.py | 12 ++++++------\n 1 file changed, 6 insertions(+), 6 deletions(-)\n\ndiff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex 53ab5a2aa277c..c74cfd753d4af 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -512,15 +512,15 @@ def test_logistic_cv_multinomial_score(scoring):\n     if scoring in ['f1', 'precision', 'recall']:\n         for averaging in ['micro', 'macro', 'weighted']:\n             scorer = get_scorer('{0}_{1}'.format(scoring, averaging))\n-            np.testing.assert_array_almost_equal(\n-                _log_reg_scoring_path(X, y, train, test, Cs=[1.], **params,\n-                                      scoring=scorer)[2][0],\n+            assert_array_almost_equal(\n+                _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n+                                      scoring=scorer, **params)[2][0],\n                 scorer(lr, X[test], y[test]))\n     else:\n         scorer = get_scorer(scoring)\n-        np.testing.assert_array_almost_equal(\n-            _log_reg_scoring_path(X, y, train, test, Cs=[1.], **params,\n-                                  scoring=scorer)[2][0],\n+        assert_array_almost_equal(\n+            _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n+                                  scoring=scorer, **params)[2][0],\n             scorer(lr, X[test], y[test]))\n \n \n\nFrom 364f6a19b072f7a9467e48ec0192e80f9867dfa6 Mon Sep 17 00:00:00 2001\nFrom: William de Vazelhes <william.de-vazelhes@inria.fr>\nDate: Tue, 17 Jul 2018 16:37:21 +0200\nSubject: [PATCH 3/4] MAINT Add what s new entry\n\n---\n doc/whats_new/v0.20.rst | 6 ++++++\n 1 file changed, 6 insertions(+)\n\ndiff --git a/doc/whats_new/v0.20.rst b/doc/whats_new/v0.20.rst\nindex 0df0635d57c75..24f5219d83211 100644\n--- a/doc/whats_new/v0.20.rst\n+++ b/doc/whats_new/v0.20.rst\n@@ -71,6 +71,7 @@ random sampling procedures.\n - :class:`linear_model.PassiveAggressiveRegressor` (bug fix)\n - :class:`linear_model.Perceptron` (bug fix)\n - :class:`ensemble.gradient_boosting.GradientBoostingClassifier` (bug fix affecting feature importances)\n+- :class:`linear_model.LogisticRegressionCV` (bug fix)\n - The v0.19.0 release notes failed to mention a backwards incompatibility with\n   :class:`model_selection.StratifiedKFold` when ``shuffle=True`` due to\n   :issue:`7823`.\n@@ -442,6 +443,11 @@ Classifiers and regressors\n   the ``scoring`` parameter.\n   :issue:`10998` by :user:`Thomas Fan <thomasjpfan>`.\n \n+- Fixed a bug in :class:`linear_model.LogisticRegressionCV` where the 'ovr'\n+  strategy was always used to compute cross-validation scores in the\n+  multiclass setting, even if 'multinomial' was set.\n+  :issue:`8720` by :user:`William de Vazelhes <wdevazelhes>`.\n+\n - Fixed a bug in :class:`linear_model.OrthogonalMatchingPursuit` that was\n   broken when setting ``normalize=False``.\n   :issue:`10071` by `Alexandre Gramfort`_.\n\nFrom 8ac2c65b6afb3d0cf8ac4f574339f7f2215ec20c Mon Sep 17 00:00:00 2001\nFrom: William de Vazelhes <william.de-vazelhes@inria.fr>\nDate: Wed, 18 Jul 2018 08:01:47 +0200\nSubject: [PATCH 4/4] MAINT: Adress comments from review\n https://github.com/scikit-learn/scikit-learn/pull/11578#pullrequestreview-138098118\n\n---\n sklearn/linear_model/tests/test_logistic.py | 28 +++++++++++----------\n 1 file changed, 15 insertions(+), 13 deletions(-)\n\ndiff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex c74cfd753d4af..343d8211b1ef4 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -493,9 +493,18 @@ def test_logistic_cv():\n     assert_array_equal(scores.shape, (1, 3, 1))\n \n \n-@pytest.mark.parametrize('scoring', ['accuracy', 'f1', 'neg_log_loss',\n-                                     'precision', 'recall'])\n-def test_logistic_cv_multinomial_score(scoring):\n+@pytest.mark.parametrize('scoring, multiclass_agg_list',\n+                         [('accuracy', ['']),\n+                          ('precision', ['_macro', '_weighted']),\n+                          # no need to test for micro averaging because it\n+                          # is the same as accuracy for f1, precision,\n+                          # and recall (see https://github.com/\n+                          # scikit-learn/scikit-learn/pull/\n+                          # 11578#discussion_r203250062)\n+                          ('f1', ['_macro', '_weighted']),\n+                          ('neg_log_loss', ['']),\n+                          ('recall', ['_macro', '_weighted'])])\n+def test_logistic_cv_multinomial_score(scoring, multiclass_agg_list):\n     # test that LogisticRegressionCV uses the right score to compute its\n     # cross-validation scores when using a multinomial scoring\n     # see https://github.com/scikit-learn/scikit-learn/issues/8720\n@@ -507,17 +516,10 @@ def test_logistic_cv_multinomial_score(scoring):\n     params = lr.get_params()\n     # we store the params to set them further in _log_reg_scoring_path\n     for key in ['C', 'n_jobs', 'warm_start']:\n-        del(params[key])\n+        del params[key]\n     lr.fit(X[train], y[train])\n-    if scoring in ['f1', 'precision', 'recall']:\n-        for averaging in ['micro', 'macro', 'weighted']:\n-            scorer = get_scorer('{0}_{1}'.format(scoring, averaging))\n-            assert_array_almost_equal(\n-                _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n-                                      scoring=scorer, **params)[2][0],\n-                scorer(lr, X[test], y[test]))\n-    else:\n-        scorer = get_scorer(scoring)\n+    for averaging in multiclass_agg_list:\n+        scorer = get_scorer(scoring + averaging)\n         assert_array_almost_equal(\n             _log_reg_scoring_path(X, y, train, test, Cs=[1.],\n                                   scoring=scorer, **params)[2][0],\n", "gold_standard_pr_link": "https://github.com/scikit-learn/scikit-learn/pull/11578"}